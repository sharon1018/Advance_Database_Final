[{"title": "Machine Learning", "course_info": "About this course: Machine learning is the science of getting computers to act without being explicitly programmed. In the past decade, machine learning has given us self-driving cars, practical speech recognition, effective web search, and a vastly improved understanding of the human genome. Machine learning is so pervasive today that you probably use it dozens of times a day without knowing it. Many researchers also think it is the best way to make progress towards human-level AI. In this class, you will learn about the most effective machine learning techniques, and gain practice implementing them and getting them to work for yourself. More importantly, you'll learn about not only the theoretical underpinnings of learning, but also gain the practical know-how needed to quickly and powerfully apply these techniques to new problems. Finally, you'll learn about some of Silicon Valley's best practices in innovation as it pertains to machine learning and AI.\n\nThis course provides a broad introduction to machine learning, datamining, and statistical pattern recognition. Topics include: (i) Supervised learning (parametric/non-parametric algorithms, support vector machines, kernels, neural networks). (ii) Unsupervised learning (clustering, dimensionality reduction, recommender systems, deep learning). (iii) Best practices in machine learning (bias/variance theory; innovation process in machine learning and AI). The course will also draw from numerous case studies and applications, so that you'll also learn how to apply learning algorithms to building smart robots (perception, control), text understanding (web search, anti-spam), computer vision, medical informatics, audio, database mining, and other areas.", "target_audience": null, "created_by": "Stanford University", "teach_by": [{"name": "Andrew Ng", "department": null}], "package_num": null, "package_name": null, "level": null, "rating": "4.9", "week_data": [{"title": "Introduction", "description": "Welcome to Machine Learning! In this module, we introduce the core idea of teaching a computer to learn concepts using data—without being explicitly programmed. The Course Wiki is under construction. Please visit the resources tab for the most complete and up-to-date information.", "video": ["Welcome to Machine Learning!", "Machine Learning Honor Code", "Welcome", "What is Machine Learning?", "What is Machine Learning?", "How to Use Discussion Forums", "Supervised Learning", "Supervised Learning", "Unsupervised Learning", "Unsupervised Learning", "Who are Mentors?", "Get to Know Your Classmates", "Frequently Asked Questions", "Lecture Slides", "Introduction"]}, {"title": "Linear Regression with One Variable", "description": "Linear regression predicts a real-valued output based on an input value. We discuss the application of linear regression to housing price prediction, present the notion of a cost function, and introduce the gradient descent method for learning.", "video": ["Model Representation", "Model Representation", "Cost Function", "Cost Function", "Cost Function - Intuition I", "Cost Function - Intuition I", "Cost Function - Intuition II", "Cost Function - Intuition II", "Gradient Descent", "Gradient Descent", "Gradient Descent Intuition", "Gradient Descent Intuition", "Gradient Descent For Linear Regression", "Gradient Descent For Linear Regression", "Lecture Slides", "Linear Regression with One Variable"]}, {"title": "Linear Algebra Review", "description": "This optional module provides a refresher on linear algebra concepts. Basic understanding of linear algebra is necessary for the rest of the course, especially as we begin to cover models with multiple variables.", "video": ["Matrices and Vectors", "Matrices and Vectors", "Addition and Scalar Multiplication", "Addition and Scalar Multiplication", "Matrix Vector Multiplication", "Matrix Vector Multiplication", "Matrix Matrix Multiplication", "Matrix Matrix Multiplication", "Matrix Multiplication Properties", "Matrix Multiplication Properties", "Inverse and Transpose", "Inverse and Transpose", "Lecture Slides", "Linear Algebra"]}, {"title": "Linear Regression with Multiple Variables", "description": "\nWhat if your input has more than one value? In this module, we show how linear regression can be extended to accommodate multiple input features. We also discuss best practices for implementing linear regression.", "video": ["Setting Up Your Programming Assignment Environment", "Installing MATLAB", "Installing Octave on Windows", "Installing Octave on Mac OS X (10.10 Yosemite and 10.9 Mavericks and Later)", "Installing Octave on Mac OS X (10.8 Mountain Lion and Earlier)", "Installing Octave on GNU/Linux", "More Octave/MATLAB resources", "Multiple Features", "Multiple Features", "Gradient Descent for Multiple Variables", "Gradient Descent For Multiple Variables", "Gradient Descent in Practice I - Feature Scaling", "Gradient Descent in Practice I - Feature Scaling", "Gradient Descent in Practice II - Learning Rate", "Gradient Descent in Practice II - Learning Rate", "Features and Polynomial Regression", "Features and Polynomial Regression", "Normal Equation", "Normal Equation", "Normal Equation Noninvertibility", "Normal Equation Noninvertibility", "Working on and Submitting Programming Assignments", "Programming tips from Mentors", "Lecture Slides", "Linear Regression with Multiple Variables"]}, {"title": "Octave/Matlab Tutorial", "description": "This course includes programming assignments designed to help you understand how to implement the learning algorithms in practice. To complete the programming assignments, you will need to use Octave or MATLAB. This module introduces Octave/Matlab and shows you how to submit an assignment.", "video": ["Basic Operations", "Moving Data Around", "Computing on Data", "Plotting Data", "Control Statements: for, while, if statement", "Vectorization", "Lecture Slides", "Linear Regression", "Octave/Matlab Tutorial"]}, {"title": "Logistic Regression", "description": "Logistic regression is a method for classifying data into discrete outcomes. For example, we might use logistic regression to classify an email  as spam or not spam. In this module, we introduce the notion of classification, the cost function for logistic regression, and the application of logistic regression to multi-class classification.\n", "video": ["Classification", "Classification", "Hypothesis Representation", "Hypothesis Representation", "Decision Boundary", "Decision Boundary", "Cost Function", "Cost Function", "Simplified Cost Function and Gradient Descent", "Simplified Cost Function and Gradient Descent", "Advanced Optimization", "Advanced Optimization", "Multiclass Classification: One-vs-all", "Multiclass Classification: One-vs-all", "Lecture Slides", "Logistic Regression"]}, {"title": "Regularization", "description": "Machine learning models need to generalize well to new examples that the model has not seen in practice. In this module, we introduce regularization, which helps prevent models from overfitting the training data. ", "video": ["The Problem of Overfitting", "The Problem of Overfitting", "Cost Function", "Cost Function", "Regularized Linear Regression", "Regularized Linear Regression", "Regularized Logistic Regression", "Regularized Logistic Regression", "Lecture Slides", "Logistic Regression", "Regularization"]}, {"title": "Neural Networks: Representation", "description": "Neural networks is a model inspired by how the brain works. It is widely used today in many applications: when your phone interprets and understand your voice commands, it is likely that a neural network is helping to understand your speech; when you cash a check, the machines that automatically read the digits also use neural networks. ", "video": ["Non-linear Hypotheses", "Neurons and the Brain", "Model Representation I", "Model Representation I", "Model Representation II", "Model Representation II", "Examples and Intuitions I", "Examples and Intuitions I", "Examples and Intuitions II", "Examples and Intuitions II", "Multiclass Classification", "Multiclass Classification", "Lecture Slides", "Multi-class Classification and Neural Networks", "Neural Networks: Representation"]}, {"title": "Neural Networks: Learning", "description": "In this module, we introduce the backpropagation algorithm that is used to help learn parameters for a neural network. At the end of this module, you will be implementing your own neural network for digit recognition.\n", "video": ["Cost Function", "Cost Function", "Backpropagation Algorithm", "Backpropagation Algorithm", "Backpropagation Intuition", "Backpropagation Intuition", "Implementation Note: Unrolling Parameters", "Implementation Note: Unrolling Parameters", "Gradient Checking", "Gradient Checking", "Random Initialization", "Random Initialization", "Putting It Together", "Putting It Together", "Autonomous Driving", "Lecture Slides", "Neural Network Learning", "Neural Networks: Learning"]}, {"title": "Advice for Applying Machine Learning", "description": "Applying machine learning in practice is not always straightforward. In this module, we share best practices for applying machine learning in practice, and discuss the best ways to evaluate performance of the learned models.\n", "video": ["Deciding What to Try Next", "Evaluating a Hypothesis", "Evaluating a Hypothesis", "Model Selection and Train/Validation/Test Sets", "Model Selection and Train/Validation/Test Sets", "Diagnosing Bias vs. Variance", "Diagnosing Bias vs. Variance", "Regularization and Bias/Variance", "Regularization and Bias/Variance", "Learning Curves", "Learning Curves", "Deciding What to Do Next Revisited", "Deciding What to do Next Revisited", "Lecture Slides", "Regularized Linear Regression and Bias/Variance", "Advice for Applying Machine Learning"]}, {"title": "Machine Learning System Design", "description": "To optimize a machine learning algorithm, you’ll need to first understand where the biggest improvements can be made. In this module, we discuss how to understand the performance of a machine learning system with multiple parts, and also how to deal with skewed data.\n", "video": ["Prioritizing What to Work On", "Prioritizing What to Work On", "Error Analysis", "Error Analysis", "Error Metrics for Skewed Classes", "Trading Off Precision and Recall", "Data For Machine Learning", "Lecture Slides", "Machine Learning System Design"]}, {"title": "Support Vector Machines", "description": "Support vector machines, or SVMs, is a machine learning algorithm for classification. We introduce the idea and intuitions behind SVMs and discuss how to use it in practice.\n", "video": ["Optimization Objective", "Large Margin Intuition", "Mathematics Behind Large Margin Classification", "Kernels I", "Kernels II", "Using An SVM", "Lecture Slides", "Support Vector Machines", "Support Vector Machines"]}, {"title": "Unsupervised Learning", "description": "We use unsupervised learning to build models that help us understand our data better. We discuss the k-Means algorithm for clustering that enable us to learn groupings of unlabeled data points.", "video": ["Unsupervised Learning: Introduction", "K-Means Algorithm", "Optimization Objective", "Random Initialization", "Choosing the Number of Clusters", "Lecture Slides", "Unsupervised Learning"]}, {"title": "Dimensionality Reduction", "description": "In this module, we introduce Principal Components Analysis, and show how it can be used for data compression to speed up learning algorithms as well as for visualizations of complex datasets.\n", "video": ["Motivation I: Data Compression", "Motivation II: Visualization", "Principal Component Analysis Problem Formulation", "Principal Component Analysis Algorithm", "Reconstruction from Compressed Representation", "Choosing the Number of Principal Components", "Advice for Applying PCA", "Lecture Slides", "K-Means Clustering and PCA", "Principal Component Analysis"]}, {"title": "Anomaly Detection", "description": "Given a large number of data points, we may sometimes want to figure out which ones vary significantly from the average. For example, in manufacturing, we may want to detect defects or anomalies. We show how a dataset can be modeled using a Gaussian distribution, and how the model can be used for anomaly detection.\n", "video": ["Problem Motivation", "Gaussian Distribution", "Algorithm", "Developing and Evaluating an Anomaly Detection System", "Anomaly Detection vs. Supervised Learning", "Choosing What Features to Use", "Multivariate Gaussian Distribution", "Anomaly Detection using the Multivariate Gaussian Distribution", "Lecture Slides", "Anomaly Detection"]}, {"title": "Recommender Systems", "description": "When you buy a product online, most websites automatically recommend other products that you may like. Recommender systems look at patterns of activities between different users and different products to produce these recommendations. In this module, we introduce recommender algorithms such as the collaborative filtering algorithm and low-rank matrix factorization.", "video": ["Problem Formulation", "Content Based Recommendations", "Collaborative Filtering", "Collaborative Filtering Algorithm", "Vectorization: Low Rank Matrix Factorization", "Implementational Detail: Mean Normalization", "Lecture Slides", "Anomaly Detection and Recommender Systems", "Recommender Systems"]}, {"title": "Large Scale Machine Learning", "description": "Machine learning works best when there is an abundance of data to leverage for training. In this module, we discuss how to apply the machine learning algorithms with large datasets.", "video": ["Learning With Large Datasets", "Stochastic Gradient Descent", "Mini-Batch Gradient Descent", "Stochastic Gradient Descent Convergence", "Online Learning", "Map Reduce and Data Parallelism", "Lecture Slides", "Large Scale Machine Learning"]}, {"title": "Application Example: Photo OCR", "description": "Identifying and recognizing objects, words, and digits in an image is a challenging task. We discuss how a pipeline can be built to tackle this problem and how to analyze and improve the performance of such a system.\n", "video": ["Problem Description and Pipeline", "Sliding Windows", "Getting Lots of Data and Artificial Data", "Ceiling Analysis: What Part of the Pipeline to Work on Next", "Lecture Slides", "Summary and Thank You", "Application: Photo OCR"]}]}, {"title": "Neural Networks and Deep Learning", "course_info": "About this course: If you want to break into cutting-edge AI, this course will help you do so. Deep learning engineers are highly sought after, and mastering deep learning will give you numerous new career opportunities. Deep learning is also a new \"superpower\" that will let you build AI systems that just weren't possible a few years ago. \n\nIn this course, you will learn the foundations of deep learning. When you finish this class, you will:\n- Understand the major technology trends driving Deep Learning\n- Be able to build, train and apply fully connected deep neural networks \n- Know how to implement efficient (vectorized) neural networks \n- Understand the key parameters in a neural network's architecture \n\nThis course also teaches you how Deep Learning actually works, rather than presenting only a cursory or surface-level description. So after completing it, you will be able to apply deep learning to a your own applications. If you are looking for a job in AI, after this course you will also be able to answer basic interview questions. \n\nThis is the first course of the Deep Learning Specialization.", "target_audience": "Who is this class for: Prerequisites: \n\nExpected:\n- Programming: Basic Python programming skills, with the capability to work effectively with data structures.  \n\nRecommended:\n- Mathematics: Matrix vector operations and notation.\n- Machine Learning: Understanding how to frame a machine learning problem, including how data is represented will be beneficial. If you have taken my Machine Learning Course here, you have much more than the needed level of knowledge. ", "created_by": "deeplearning.ai", "teach_by": [{"name": "Andrew Ng", "department": null}, {"name": "Head Teaching Assistant - Kian Katanforoosh", "department": null}, {"name": "Teaching Assistant - Younes Bensouda Mourri", "department": null}], "package_num": "1", "package_name": "Deep Learning Specialization ", "level": "Intermediate", "rating": "4.9", "week_data": [{"title": "Introduction to deep learning", "description": "Be able to explain the major trends driving the rise of deep learning, and understand where and how it is applied today.  ", "video": ["Welcome", "What is a neural network?", "Supervised Learning with Neural Networks", "Why is Deep Learning taking off?", "About this Course", "Frequently Asked Questions", "Course Resources", "How to use Discussion Forums", "Geoffrey Hinton interview", "Introduction to deep learning"]}, {"title": "Neural Networks Basics", "description": "Learn to set up a machine learning problem with a neural network mindset. Learn to use vectorization to speed up your models. ", "video": ["Binary Classification", "Logistic Regression", "Logistic Regression Cost Function", "Gradient Descent", "Derivatives", "More Derivative Examples", "Computation graph", "Derivatives with a Computation Graph", "Logistic Regression Gradient Descent", "Gradient Descent on m Examples", "Vectorization", "More Vectorization Examples", "Vectorizing Logistic Regression", "Vectorizing Logistic Regression's Gradient Output", "Broadcasting in Python", "A note on python/numpy vectors", "Quick tour of Jupyter/iPython Notebooks", "Explanation of logistic regression cost function (optional)", "Deep Learning Honor Code", "Programming Assignment FAQ", "Python Basics with numpy (optional)", "Python Basics with numpy (optional)", "Logistic Regression with a Neural Network mindset", "Pieter Abbeel interview", "Neural Network Basics", "Logistic Regression with a Neural Network mindset"]}, {"title": "Shallow neural networks", "description": "Learn to build a neural network with one hidden layer, using forward propagation and backpropagation. ", "video": ["Neural Networks Overview", "Neural Network Representation", "Computing a Neural Network's Output", "Vectorizing across multiple examples", "Explanation for Vectorized Implementation", "Activation functions", "Why do you need non-linear activation functions?", "Derivatives of activation functions", "Gradient descent for Neural Networks", "Backpropagation intuition (optional)", "Random Initialization", "Planar data classification with a hidden layer", "Ian Goodfellow interview", "Shallow Neural Networks", "Planar data classification with a hidden layer"]}, {"title": "Deep Neural Networks", "description": "Understand the key computations underlying deep learning, use them to build and train deep neural networks, and apply it to computer vision. ", "video": ["Deep L-layer neural network", "Forward Propagation in a Deep Network", "Getting your matrix dimensions right", "Why deep representations?", "Building blocks of deep neural networks", "Forward and Backward Propagation", "Parameters vs Hyperparameters", "What does this have to do with the brain?", "Building your Deep Neural Network: Step by Step", "Deep Neural Network - Application", "Key concepts on Deep Neural Networks", "Building your deep neural network: Step by Step", "Deep Neural Network Application"]}]}, {"title": "Convolutional Neural Networks", "course_info": "About this course: This course will teach you how to build convolutional neural networks and apply it to image data. Thanks to deep learning, computer vision is working far better than just two years ago, and this is enabling numerous exciting applications ranging from safe autonomous driving, to accurate face recognition, to automatic reading of radiology images. \n\nYou will:\n- Understand how to build a convolutional neural network, including recent variations such as residual networks.\n- Know how to apply convolutional networks to visual detection and recognition tasks.\n- Know to use neural style transfer to generate art.\n- Be able to apply these algorithms to a variety of image, video, and other 2D or 3D data.\n\nThis is the fourth course of the Deep Learning Specialization.", "target_audience": "Who is this class for: - Learners that took the first two courses of the specialization. The third course is recommended. \n- Anyone that already has a solid understanding of densely connected neural networks, and wants to learn convolutional neural networks or work with image data.", "created_by": "deeplearning.ai", "teach_by": [{"name": "Andrew Ng", "department": null}, {"name": "Head Teaching Assistant - Kian Katanforoosh", "department": null}, {"name": "Teaching Assistant - Younes Bensouda Mourri", "department": null}], "package_num": "4", "package_name": "Deep Learning Specialization ", "level": "Intermediate", "rating": "4.8", "week_data": [{"title": "Foundations of Convolutional Neural Networks", "description": "Learn to implement the foundational layers of CNNs (pooling, convolutions) and to stack them properly in a deep network to solve multi-class image classification problems.", "video": ["Computer Vision", "Edge Detection Example", "More Edge Detection", "Padding", "Strided Convolutions", "Convolutions Over Volume", "One Layer of a Convolutional Network", "Simple Convolutional Network Example", "Pooling Layers", "CNN Example", "Why Convolutions?", "Convolutional Model: step by step", "Convolutional Model: application", "The basics of ConvNets", "Convolutional Model: step by step", "Convolutional model: application"]}, {"title": "Deep convolutional models: case studies", "description": "Learn about the practical tricks and methods used in deep CNNs straight from the research papers. ", "video": ["Why look at case studies?", "Classic Networks", "ResNets", "Why ResNets Work", "Networks in Networks and 1x1 Convolutions", "Inception Network Motivation", "Inception Network", "Using Open-Source Implementation", "Transfer Learning", "Data Augmentation", "State of Computer Vision", "Keras Tutorial - The Happy House (not graded)", "Residual Networks", "Deep convolutional models", "Residual Networks"]}, {"title": "Object detection", "description": "Learn how to apply your knowledge of CNNs to one of the toughest but hottest field of computer vision: Object detection.", "video": ["Object Localization", "Landmark Detection", "Object Detection", "Convolutional Implementation of Sliding Windows", "Bounding Box Predictions", "Intersection Over Union", "Non-max Suppression", "Anchor Boxes", "YOLO Algorithm", "(Optional) Region Proposals", "Car detection with YOLOv2", "Detection algorithms", "Car detection with YOLOv2"]}, {"title": "Special applications: Face recognition & Neural style transfer", "description": "Discover how CNNs can be applied to multiple fields, including art generation and face recognition. Implement your own algorithm to generate art and recognize faces!", "video": ["What is face recognition?", "One Shot Learning", "Siamese Network", "Triplet Loss", "Face Verification and Binary Classification", "What is neural style transfer?", "What are deep ConvNets learning?", "Cost Function", "Content Cost Function", "Style Cost Function", "1D and 3D Generalizations", "Art generation with Neural Style Transfer", "Face Recognition for the Happy House", "Special applications: Face recognition & Neural style transfer", "Art generation with Neural Style Transfer", "Face Recognition for the Happy House"]}]}, {"title": "Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization", "course_info": "About this course: This course will teach you the \"magic\" of getting deep learning to work well. Rather than the deep learning process being a black box, you will understand what drives performance, and be able to more systematically get good results. You will also learn TensorFlow. \n\nAfter 3 weeks, you will: \n- Understand industry best-practices for building deep learning applications. \n- Be able to effectively use the common neural network \"tricks\", including initialization, L2 and dropout regularization, Batch normalization, gradient checking, \n- Be able to implement and apply a variety of optimization algorithms, such as mini-batch gradient descent, Momentum, RMSprop and Adam, and check for their convergence. \n- Understand new best-practices for the deep learning era of how to set up train/dev/test sets and analyze bias/variance\n- Be able to implement a neural network in TensorFlow. \n\nThis is the second course of the Deep Learning Specialization.", "target_audience": "Who is this class for: This class is for:\n- Learners that took the first course of the specialization: \"Neural Networks and Deep Learning\"\n- Anyone that already understands fully-connected neural networks, and wants to learn the practical aspects of making them work well. ", "created_by": "deeplearning.ai", "teach_by": [{"name": "Andrew Ng", "department": null}, {"name": "Head Teaching Assistant - Kian Katanforoosh", "department": null}, {"name": "Teaching Assistant - Younes Bensouda Mourri", "department": null}], "package_num": "2", "package_name": "Deep Learning Specialization ", "level": "Beginner", "rating": "4.9", "week_data": [{"title": "Practical aspects of Deep Learning", "description": "", "video": ["Train / Dev / Test sets", "Bias / Variance", "Basic Recipe for Machine Learning", "Regularization", "Why regularization reduces overfitting?", "Dropout Regularization", "Understanding Dropout", "Other regularization methods", "Normalizing inputs", "Vanishing / Exploding gradients", "Weight Initialization for Deep Networks", "Numerical approximation of gradients", "Gradient checking", "Gradient Checking Implementation Notes", "Initialization", "Regularization", "Gradient Checking", "Yoshua Bengio interview", "Practical aspects of deep learning", "Initialization", "Regularization", "Gradient Checking"]}, {"title": "Optimization algorithms", "description": "", "video": ["Mini-batch gradient descent", "Understanding mini-batch gradient descent", "Exponentially weighted averages", "Understanding exponentially weighted averages", "Bias correction in exponentially weighted averages", "Gradient descent with momentum", "RMSprop", "Adam optimization algorithm", "Learning rate decay", "The problem of local optima", "Optimization", "Yuanqing Lin interview", "Optimization algorithms", "Optimization"]}, {"title": "Hyperparameter tuning, Batch Normalization and Programming Frameworks", "description": "", "video": ["Tuning process", "Using an appropriate scale to pick hyperparameters", "Hyperparameters tuning in practice: Pandas vs. Caviar", "Normalizing activations in a network", "Fitting Batch Norm into a neural network", "Why does Batch Norm work?", "Batch Norm at test time", "Softmax Regression", "Training a softmax classifier", "Deep learning frameworks", "TensorFlow", "Tensorflow", "Hyperparameter tuning, Batch Normalization, Programming Frameworks", "Tensorflow"]}]}, {"title": "Structuring Machine Learning Projects", "course_info": "About this course: You will learn how to build a successful machine learning project. If you aspire to be a technical leader in AI, and know how to set direction for your team's work, this course will show you how.\n\nMuch of this content has never been taught elsewhere, and is drawn from my experience building and shipping many deep learning products. This course also has two \"flight simulators\" that let you practice decision-making as a machine learning project leader. This provides \"industry experience\" that you might otherwise get only after years of ML work experience.\n\nAfter 2 weeks, you will: \n- Understand how to diagnose errors in a machine learning system, and \n- Be able to prioritize the most promising directions for reducing error\n- Understand complex ML settings, such as mismatched training/test sets, and comparing to and/or surpassing human-level performance\n- Know how to apply end-to-end learning, transfer learning, and multi-task learning\n\nI've seen teams waste months or years through not understanding the principles taught in this course. I hope this two week course will save you months of time.\n\nThis is a standalone course, and you can take this so long as you have basic machine learning knowledge. This is the third course in the Deep Learning Specialization.", "target_audience": "Who is this class for: Pre-requisites:\n- This course is aimed at individuals with basic knowledge of machine learning, who want to know how to set technical direction and prioritization for their work.\n- It is recommended that you take course one and two of this specialization (Neural Networks and Deep Learning, and Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization) prior to beginning this course.", "created_by": "deeplearning.ai", "teach_by": [{"name": "Andrew Ng", "department": null}, {"name": "Head Teaching Assistant - Kian Katanforoosh", "department": null}, {"name": "Teaching Assistant - Younes Bensouda Mourri", "department": null}], "package_num": "3", "package_name": "Deep Learning Specialization ", "level": "Beginner", "rating": "4.8", "week_data": [{"title": "ML Strategy (1)", "description": "", "video": ["Why ML Strategy", "Orthogonalization", "Single number evaluation metric", "Satisficing and Optimizing metric", "Train/dev/test distributions", "Size of the dev and test sets", "When to change dev/test sets and metrics", "Why human-level performance?", "Avoidable bias", "Understanding human-level performance", "Surpassing human-level performance", "Improving your model performance", "Machine Learning flight simulator", "Andrej Karpathy interview", "Bird recognition in the city of Peacetopia (case study)"]}, {"title": "ML Strategy (2)", "description": "", "video": ["Carrying out error analysis", "Cleaning up incorrectly labeled data", "Build your first system quickly, then iterate", "Training and testing on different distributions", "Bias and Variance with mismatched data distributions", "Addressing data mismatch", "Transfer learning", "Multi-task learning", "What is end-to-end deep learning?", "Whether to use end-to-end deep learning", "Ruslan Salakhutdinov interview", "Autonomous driving (case study)"]}]}, {"title": "Neural Networks for Machine Learning", "course_info": "About this course: Learn about artificial neural networks and how they're being used for machine learning, as applied to speech and object recognition, image segmentation, modeling language and human motion, etc. We'll emphasize both the basic algorithms and the practical tricks needed to get them to work well.\n\nThis course contains the same content presented on Coursera beginning in 2013. It is not a continuation or update of the original course. It has been adapted for the new platform.\n\nPlease be advised that the course is suited for an intermediate level learner - comfortable with calculus and with experience programming (Python).", "target_audience": null, "created_by": "University of Toronto", "teach_by": [{"name": "Geoffrey Hinton", "department": "Department of Computer Science"}], "package_num": null, "package_name": null, "level": null, "rating": "4.6", "week_data": [{"title": "Introduction ", "description": "Introduction to the course -  machine learning and neural nets", "video": ["Syllabus and Course Logistics", "Lecture Slides (and resources)", "Why do we need machine learning? [13 min]", "What are neural networks? [8 min]", "Some simple models of neurons [8 min]", "A simple example of learning [6 min]", "Three types of learning [8 min]", "Setting Up Your Programming Assignment Environment", "Installing Octave on Windows", "Installing Octave on Mac OS X (10.10 Yosemite and 10.9 Mavericks)", "Installing Octave on Mac OS X (10.8 Mountain Lion and Earlier)", "Installing Octave on GNU/Linux", "More Octave", "Lecture 1 Quiz"]}, {"title": "The Perceptron learning procedure", "description": "An overview of the main types of neural\nnetwork architecture ", "video": ["Lecture Slides (and resources)", "Types of neural network architectures [7 min]", "Perceptrons: The first generation of neural networks [8 min]", "A geometrical view of perceptrons [6 min]", "Why the learning works [5 min]", "What perceptrons can't do [15 min]", "Lecture 2 Quiz"]}, {"title": "The backpropagation learning proccedure", "description": "Learning the weights of a linear neuron ", "video": ["Lecture Slides (and resources)", "Learning the weights of a linear neuron [12 min]", "The error surface for a linear neuron [5 min]", "Learning the weights of a logistic output neuron [4 min]", "The backpropagation algorithm [12 min]", "Using the derivatives computed by backpropagation [10 min]", "Forward Propagation in Neural Networks", "Lecture 3 Quiz", "Programming Assignment 1: The perceptron learning algorithm."]}, {"title": "Learning feature vectors for words", "description": "Learning to predict the next word", "video": ["Lecture Slides (and resources)", "Learning to predict the next word [13 min]", "A brief diversion into cognitive science [4 min]", "Another diversion: The softmax output function [7 min]", "Neuro-probabilistic language models [8 min]", "Ways to deal with the large number of possible outputs [15 min]", "Lecture 4 Quiz"]}, {"title": "Object recognition with neural nets", "description": "In this module we look at why object recognition is difficult. ", "video": ["Lecture Slides (and resources)", "Why object recognition is difficult [5 min]", "Achieving viewpoint invariance [6 min]", "Convolutional nets for digit recognition [16 min]", "Convolutional nets for object recognition [17min]", "Lecture 5 Quiz", "Programming Assignment 2: Learning Word Representations."]}, {"title": "Optimization: How to make the learning go faster", "description": "We delve into mini-batch gradient descent as well as discuss adaptive learning rates.", "video": ["Lecture Slides (and resources)", "Overview of mini-batch gradient descent", "A bag of tricks for mini-batch gradient descent", "The momentum method", "Adaptive learning rates for each connection", "Rmsprop: Divide the gradient by a running average of its recent magnitude", "Lecture 6 Quiz"]}, {"title": "Recurrent neural networks", "description": "This module explores training recurrent neural networks", "video": ["Lecture Slides (and resources)", "Modeling sequences: A brief overview", "Training RNNs with back propagation", "A toy example of training an RNN", "Why it is difficult to train an RNN", "Long-term Short-term-memory", "Lecture 7 Quiz"]}, {"title": "More recurrent neural networks", "description": "We continue our look at recurrent neural networks", "video": ["Lecture Slides (and resources)", "Modeling character strings with multiplicative connections [14 mins]", "Learning to predict the next character using HF [12  mins]", "Echo State Networks [9 min]", "Lecture 8 Quiz"]}, {"title": "Ways to make neural networks generalize better", "description": "We discuss strategies to make neural networks generalize better", "video": ["Lecture Slides (and resources)", "Overview of ways to improve generalization [12 min]", "Limiting the size of the weights [6 min]", "Using noise as a regularizer [7 min]", "Introduction to the full Bayesian approach [12 min]", "The Bayesian interpretation of weight decay [11 min]", "MacKay's quick and dirty method of setting weight costs [4 min]", "Lecture 9 Quiz", "Programming assignment 3: Optimization and generalization"]}, {"title": "Combining multiple neural networks to improve generalization", "description": "This module we look at why it helps to combine multiple neural networks to improve generalization", "video": ["Lecture Slides (and resources)", "Why it helps to combine models [13 min]", "Mixtures of Experts [13 min]", "The idea of full Bayesian learning [7 min]", "Making full Bayesian learning practical [7 min]", "Dropout [9 min]", "Lecture 10 Quiz"]}, {"title": "Hopfield nets and Boltzmann machines", "description": "", "video": ["Lecture Slides (and resources)", "Hopfield Nets [13 min]", "Dealing with spurious minima [11 min]", "Hopfield nets with hidden units [10 min]", "Using stochastic units to improv search [11 min]", "How a Boltzmann machine models data [12 min]", "Lecture 11 Quiz"]}, {"title": "Restricted Boltzmann machines (RBMs)", "description": "This module deals with Boltzmann machine learning ", "video": ["Lecture Slides (and resources)", "Boltzmann machine learning [12 min]", "OPTIONAL VIDEO: More efficient ways to get the statistics [15 mins]", "Restricted Boltzmann Machines [11 min]", "An example of RBM learning [7 mins]", "RBMs for collaborative filtering [8 mins]", "Lecture 12 Quiz"]}, {"title": "Stacking RBMs to make Deep Belief Nets", "description": "", "video": ["Lecture Slides (and resources)", "The ups and downs of back propagation [10 min]", "Belief Nets [13 min]", "The wake-sleep algorithm [13 min]", "Programming Assignment 4: Restricted Boltzmann Machines", "Lecture 13 Quiz"]}, {"title": "Deep neural nets with generative pre-training", "description": "", "video": ["Lecture Slides (and resources)", "Learning layers of features by stacking RBMs [17 min]", "Discriminative learning for DBNs [9 mins]", "What happens during discriminative fine-tuning? [8 mins]", "Modeling real-valued data with an RBM [10 mins]", "OPTIONAL VIDEO: RBMs are infinite sigmoid belief nets [17 mins]", "Lecture 14 Quiz"]}, {"title": "Modeling hierarchical structure with neural nets", "description": "", "video": ["Lecture Slides (and resources)", "From PCA to autoencoders [5 mins]", "Deep auto encoders [4 mins]", "Deep auto encoders for document retrieval [8 mins]", "Semantic Hashing [9 mins]", "Learning binary codes for image retrieval [9 mins]", "Shallow autoencoders for pre-training [7 mins]", "Lecture 15 Quiz", "Final Exam"]}, {"title": "Recent applications of deep neural nets", "description": "", "video": ["OPTIONAL: Learning a joint model of images and captions [10 min]", "OPTIONAL: Hierarchical Coordinate Frames [10 mins]", "OPTIONAL: Bayesian optimization of hyper-parameters [13 min]"]}]}, {"title": "Sequence Models", "course_info": "About this course: This course will teach you how to build models for natural language, audio, and other sequence data. Thanks to deep learning, sequence algorithms are working far better than just two years ago, and this is enabling numerous exciting applications in speech recognition, music synthesis, chatbots, machine translation, natural language understanding, and many others. \n\nYou will:\n- Understand how to build and train Recurrent Neural Networks (RNNs), and commonly-used variants such as GRUs and LSTMs.\n- Be able to apply sequence models to natural language problems, including text synthesis. \n- Be able to apply sequence models to audio applications, including speech recognition and music synthesis.\n\nThis is the fifth and final course of the Deep Learning Specialization.", "target_audience": "Who is this class for: - Learners that took course one, two, and four of the specialization. Course three is also recommended.\n- Anyone that already has a solid understanding of learning with neural networks, including convolutional networks, and wants to learn how to develop recurrent neural networks. ", "created_by": "deeplearning.ai", "teach_by": [{"name": "Andrew Ng", "department": null}, {"name": "Head Teaching Assistant - Kian Katanforoosh", "department": null}, {"name": "Teaching Assistant - Younes Bensouda Mourri", "department": null}], "package_num": "5", "package_name": "Deep Learning Specialization ", "level": "Intermediate", "rating": null, "week_data": []}, {"title": "Introduction to Deep Learning", "course_info": "About this course: The goal of this course is to give learners basic understanding of modern neural networks and their applications in computer vision and natural language understanding. The course starts with a recap of linear models and discussion of stochastic optimization methods that are crucial for training deep neural networks. Learners will study all popular building blocks of neural networks including fully connected layers, convolutional and recurrent layers. \nLearners will use these building blocks to define complex modern architectures in TensorFlow and Keras frameworks. In the course project learner will implement deep neural network for the task of image captioning which solves the problem of giving a text description for an input image.\n\nThe prerequisites for this course are: \n1) Basic knowledge of Python.\n2) Basic linear algebra and probability.\n\nPlease note that this is an advanced course and we assume basic knowledge of machine learning. You should understand:\n1) Linear regression: mean squared error, analytical solution.\n2) Logistic regression: model, cross-entropy loss, class probability estimation.\n3) Gradient descent for linear models. Derivatives of MSE and cross-entropy loss functions.\n4) The problem of overfitting.\n5) Regularization for linear models.", "target_audience": "Who is this class for: Developers, analysts and researchers who are faced with tasks involving complex structure understanding such as image, sound and text analysis.", "created_by": "National Research University Higher School of Economics", "teach_by": [{"name": "Evgeny Sokolov", "department": "HSE Faculty of Computer Science"}, {"name": "Andrei Zimovnov", "department": "HSE Faculty of Computer Science"}, {"name": "Alexander Panin", "department": "HSE Faculty of Computer Science"}, {"name": "Ekaterina Lobacheva", "department": "HSE Faculty of Computer Science"}, {"name": "Nikita Kazeev", "department": "HSE Faculty of Computer Science"}], "package_num": "1", "package_name": "Advanced Machine Learning Specialization ", "level": "Advanced", "rating": "4.3", "week_data": [{"title": "Introduction to optimization", "description": "Welcome to the \"Introduction to Deep Learning\" course! In the first week you'll learn about linear models and stochatic optimization methods. Linear models are basic building blocks for many deep architectures, and stochastic optimization is used to learn every model that we'll discuss in our course.", "video": ["Welcome!", "Linear regression", "Linear classification", "Gradient descent", "Overfitting problem and model validation", "Model regularization", "Stochastic gradient descent", "Gradient descent extensions", "Linear models and optimization", "Linear models", "Overfitting and regularization", "Linear models and optimization"]}, {"title": "Introduction to neural networks", "description": "This module is an introduction to the concept of a deep neural network. You'll begin with the linear model in numpy and finish with writing your very first deep network.", "video": ["Multilayer perceptron", "Training a neural network", "Backpropagation primer", "Multilayer perceptron", "Tensorflow_task.ipynb", "Going deeper with Tensorflow", "MSE in TensorFlow", "Gradients & optimization in Tensorflow", "my1stNN boilerplate", "Keras-task.ipynb", "Keras introduction", "What Deep Learning is and is not", "Deep learning as a language", "NumpyNN (honor).ipynb", "Logistic regression in TensorFlow", "my1stNN", "my1stNN - Keras this time", "Your very own neural network"]}, {"title": "Deep Learning for images", "description": "In this week you will learn about building blocks of deep learning for image input. You will learn how to build Convolutional Neural Network (CNN) architectures with these blocks and how to quickly solve a new task using so-called pre-trained models.", "video": ["Motivation for convolutional layers", "Our first CNN architecture", "Training tips and tricks for deep CNNs", "Overview of modern CNN architectures", "Your first CNN on CIFAR-10", "Learning new tasks with pre-trained CNNs", "A glimpse of other Computer Vision tasks", "Fine-tuning InceptionV3 for flowers classification", "Convolutions and pooling", "Your first CNN on CIFAR-10", "Fine-tuning InceptionV3 for flowers classification"]}, {"title": "Unsupervised representation learning", "description": "This week we're gonna dive into unsupervised parts of deep learning. You'll learn how to generate, morph and search images with deep learning.", "video": ["Unsupervised learning: what it is and why bother", "Autoencoders 101", "Autoencoder applications", "Autoencoder applications: image generation, data visualization & more", "Autoencoders.ipynb", "Natural language processing primer", "Word embeddings", "Generative models 101", "Generative Adversarial Networks", "Applications of adversarial approach", "Generative Adversarial Networks", "Simple autoencoder", "Word embeddings", "Generative adversarial networks"]}, {"title": "Deep learning for sequences", "description": "In this week you will learn how to use deep learning for sequences such as texts, video, audio, etc. You will learn about several Recurrent Neural Network (RNN) architectures and how to apply them for different tasks with sequential input/output.", "video": ["Motivation for recurrent layers", "Simple RNN and Backpropagation", "Generating names with RNNs", "The training of RNNs is not that easy", "Dealing with vanishing and exploding gradients", "Modern RNNs: LSTM and GRU", "More RNNs in Keras", "Practical use cases for RNNs", "RNN and Backpropagation", "Generating names with RNNs", "Modern RNNs", "How to use RNNs"]}, {"title": "Final Project", "description": "In this week you will apply all your knowledge about neural networks for images and texts for the final project. You will solve the task of generating descriptions for real world images!", "video": ["Image Captioning Final Project", "Image Captioning Final Project", "Image Captioning Final Project"]}]}, {"title": "Machine Learning Foundations: A Case Study Approach", "course_info": "About this course: Do you have data and wonder what it can tell you?  Do you need a deeper understanding of the core ways in which machine learning can improve your business?  Do you want to be able to converse with specialists about anything from regression and classification to deep learning and recommender systems?\n\nIn this course, you will get hands-on experience with machine learning from a series of practical case-studies.  At the end of the first course you will have studied how to predict house prices based on house-level features, analyze sentiment from user reviews, retrieve documents of interest, recommend products, and search for images.  Through hands-on practice with these use cases, you will be able to apply machine learning methods in a wide range of domains.\n\nThis first course treats the machine learning method as a black box.  Using this abstraction, you will focus on understanding tasks of interest, matching these tasks to machine learning tools, and assessing the quality of the output. In subsequent courses, you will delve into the components of this black box by examining models and algorithms.  Together, these pieces form the machine learning pipeline, which you will use in developing intelligent applications.\n\nLearning Outcomes:  By the end of this course, you will be able to:\n   -Identify potential applications of machine learning in practice.  \n   -Describe the core differences in analyses enabled by regression, classification, and clustering.\n   -Select the appropriate machine learning task for a potential application.  \n   -Apply regression, classification, clustering, retrieval, recommender systems, and deep learning.\n   -Represent your data as features to serve as input to machine learning models. \n   -Assess the model quality in terms of relevant error metrics for each task.\n   -Utilize a dataset to fit a model to analyze new data.\n   -Build an end-to-end application that uses machine learning at its core.  \n   -Implement these techniques in Python.", "target_audience": null, "created_by": "University of Washington", "teach_by": [{"name": "Carlos Guestrin", "department": "Computer Science and Engineering"}, {"name": "Emily Fox", "department": "Statistics"}], "package_num": "1", "package_name": "Machine Learning Specialization ", "level": null, "rating": "4.6", "week_data": [{"title": "Welcome", "description": "Machine learning is everywhere, but is often operating behind the scenes. <p>This introduction to the specialization provides you with insights into the power of machine learning, and the multitude of intelligent applications you personally will be able to develop and deploy upon completion.</p>We also discuss who we are, how we got here, and our view of the future of intelligent applications.", "video": ["Important Update regarding the Machine Learning Specialization", "Slides presented in this module", "Welcome to this course and specialization", "Who we are", "Machine learning is changing the world", "Why a case study approach?", "Specialization overview", "How we got into ML", "Who is this specialization for?", "What you'll be able to do", "The capstone and an example intelligent application", "The future of intelligent applications", "Reading: Getting started with Python, IPython Notebook & GraphLab Create", "Reading: where should my files go?", "Download the IPython Notebook used in this lesson to follow along", "Starting an IPython Notebook", "Creating variables in Python", "Conditional statements and loops in Python", "Creating functions and lambdas in Python", "Download the IPython Notebook used in this lesson to follow along", "Starting GraphLab Create & loading an SFrame", "Canvas for data visualization", "Interacting with columns of an SFrame", "Using .apply() for data transformation"]}, {"title": "Regression: Predicting House Prices", "description": "This week you will build your first intelligent application that makes predictions from data.<p>We will explore this idea within the context of our first case study, predicting house prices, where you will create models that predict a continuous value (price) from input features (square footage, number of bedrooms and bathrooms,...).  <p>This is just one of the many places where regression can be applied.Other applications range from predicting health outcomes in medicine, stock prices in finance, and power usage in high-performance computing, to analyzing which regulators are important for gene expression.</p>You will also examine how to analyze the performance of your predictive model and implement regression in practice using an iPython notebook.", "video": ["Slides presented in this module", "Predicting house prices: A case study in regression", "What is the goal and how might you naively address it?", "Linear Regression: A Model-Based Approach", "Adding higher order effects", "Evaluating overfitting via training/test split", "Training/test curves", "Adding other features", "Other regression examples", "Regression ML block diagram", "Download the IPython Notebook used in this lesson to follow along", "Loading & exploring house sale data", "Splitting the data into training and test sets", "Learning a simple regression model to predict house prices from house size", "Evaluating error (RMSE) of the simple model", "Visualizing predictions of simple model with Matplotlib", "Inspecting the model coefficients learned", "Exploring other features of the data", "Learning a model to predict house prices from more features", "Applying learned models to predict price of an average house", "Applying learned models to predict price of two fancy houses", "Reading: Predicting house prices assignment", "Regression", "Predicting house prices"]}, {"title": "Classification: Analyzing Sentiment", "description": "How do you guess whether a person felt positively or negatively about an experience, just from a short review they wrote?<p>In our second case study, analyzing sentiment, you will create models that predict a class (positive/negative sentiment) from input features (text of the reviews, user profile information,...).This task is an example of classification, one of the most widely used areas of machine learning, with a broad array of applications, including ad targeting, spam detection, medical diagnosis and image classification.</p>You will analyze the accuracy of your classifier, implement an actual classifier in an iPython notebook, and take a first stab at a core piece of the intelligent application you will build and deploy in your capstone.  ", "video": ["Slides presented in this module", "Analyzing the sentiment of reviews: A case study in classification", "What is an intelligent restaurant \u000breview system?", "Examples of classification tasks", "Linear classifiers", "Decision boundaries", "Training and evaluating a classifier", "What's a good accuracy?", "False positives, false negatives, and confusion matrices", "Learning curves", "Class probabilities", "Classification ML block diagram", "Download the IPython Notebook used in this lesson to follow along", "Loading & exploring product review data", "Creating the word count vector", "Exploring the most popular product", "Defining which reviews have positive or negative sentiment", "Training a sentiment classifier", "Evaluating a classifier & the ROC curve", "Applying model to find most positive & negative reviews for a product", "Exploring the most positive & negative aspects of a product", "Reading: Analyzing product sentiment assignment", "Classification", "Analyzing product sentiment"]}, {"title": "Clustering and Similarity: Retrieving Documents", "description": "A reader is interested in a specific news article and you want to find a similar articles to recommend.  What is the right notion of similarity?  How do I automatically search over documents to find the one that is most similar?  How do I quantitatively represent the documents in the first place?<p>In this third case study, retrieving documents, you will examine various document representations and an algorithm to retrieve the most similar subset.  You will also consider structured representations of the documents that automatically group articles by similarity (e.g., document topic).</p>You will actually build an intelligent document retrieval system for Wikipedia entries in an iPython notebook.", "video": ["Slides presented in this module", "Document retrieval: A case study in clustering and measuring similarity", "What is the document retrieval task?", "Word count representation for measuring similarity", "Prioritizing important words with tf-idf", "Calculating tf-idf vectors", "Retrieving similar documents using nearest neighbor search", "Clustering documents task overview", "Clustering documents: An unsupervised learning task", "k-means: A clustering algorithm", "Other examples of clustering", "Clustering and similarity ML block diagram", "Download the IPython Notebook used in this lesson to follow along", "Loading & exploring Wikipedia data", "Exploring word counts", "Computing & exploring TF-IDFs", "Computing distances between Wikipedia articles", "Building & exploring a nearest neighbors model for Wikipedia articles", "Examples of document retrieval in action", "Reading: Retrieving Wikipedia articles assignment", "Clustering and Similarity", "Retrieving Wikipedia articles"]}, {"title": "Recommending Products", "description": "Ever wonder how Amazon forms its personalized product recommendations?  How Netflix suggests movies to watch?  How Pandora selects the next song to stream?  How Facebook or LinkedIn finds people you might connect with?  Underlying all of these technologies for personalized content is something called collaborative filtering. <p>You will learn how to build such a recommender system using a variety of techniques, and explore their tradeoffs.</p> One method we examine is matrix factorization, which learns features of users and products to form recommendations.  In an iPython notebook, you will use these techniques to build a real song recommender system.", "video": ["Slides presented in this module", "Recommender systems overview", "Where we see recommender systems in action", "Building a recommender system via classification", "Collaborative filtering: People who bought this also bought...", "Effect of popular items", "Normalizing co-occurrence matrices and leveraging purchase histories", "The matrix completion task", "Recommendations from known user/item features", "Predictions in matrix form", "Discovering hidden structure by matrix factorization", "Bringing it all together: Featurized matrix factorization", "A performance metric for recommender systems", "Optimal recommenders", "Precision-recall curves", "Recommender systems ML block diagram", "Download the IPython Notebook used in this lesson to follow along", "Loading and exploring song data", "Creating & evaluating a popularity-based song recommender", "Creating & evaluating a personalized song recommender", "Using precision-recall to compare recommender models", "Reading: Recommending songs assignment", "Recommender Systems", "Recommending songs"]}, {"title": "Deep Learning: Searching for Images", "description": "You’ve probably heard that Deep Learning is making news across the world as one of the most promising techniques in machine learning. Every industry is dedicating resources to unlock the deep learning potential, including for tasks such as image tagging, object recognition, speech recognition, and text analysis.<p>In our final case study, searching for images, you will learn how layers of neural networks provide very descriptive (non-linear) features that provide impressive performance in image classification and retrieval tasks.  You will then construct deep features, a transfer learning technique that allows you to use deep learning very easily, even when you have little data to train the model.</p>Using iPhython notebooks, you will build an image classifier and an intelligent image retrieval system with deep learning.   ", "video": ["Slides presented in this module", "Searching for images: A case study in deep learning", "What is a visual product recommender?", "Learning very non-linear features with neural networks", "Application of deep learning to computer vision", "Deep learning performance", "Demo of deep learning model on ImageNet data", "Other examples of deep learning in computer vision", "Challenges of deep learning", "Deep Features", "Deep learning ML block diagram", "Download the IPython Notebook used in this lesson to follow along", "Loading image data", "Training & evaluating a classifier using raw image pixels", "Training & evaluating a classifier using deep features", "Download the IPython Notebook used in this lesson to follow along", "Loading image data", "Creating a nearest neighbors model for image retrieval", "Querying the nearest neighbors model to retrieve images", "Querying for the most similar images for car image", "Displaying other example image retrievals with a Python lambda", "Reading: Deep features for image retrieval assignment", "Deep Learning", "Deep features for image retrieval"]}, {"title": "Closing Remarks", "description": "In the conclusion of the course, we will describe the final stage in turning our machine learning tools into a service: deployment.<p>We will also discuss some open challenges that the field of machine learning still faces, and where we think machine learning is heading.  We conclude with an overview of what's in store for you in the rest of the specialization, and the amazing intelligent applications that are ahead for us as we evolve machine learning.  ", "video": ["Slides presented in this module", "You've made it!", "Deploying an ML service", "What happens after deployment?", "Open challenges in ML", "Where is ML going?", "What's ahead in the specialization", "Thank you!"]}]}, {"title": "How to Win a Data Science Competition: Learn from Top Kagglers", "course_info": "About this course: If you want to break into competitive data science, then this course is for you! Participating in predictive modelling competitions can help you gain practical experience, improve and harness your data modelling skills in various domains such as credit, insurance, marketing, natural language processing, sales’ forecasting and computer vision to name a few. At the same time you get to do it in a competitive context against thousands of participants where each one tries to build the most predictive algorithm. Pushing each other to the limit can result in better performance and smaller prediction errors. Being able to achieve high ranks consistently can help you accelerate your career in data science.\n\nIn this course, you will learn to analyse and solve competitively such predictive modelling tasks. \n\nWhen you finish this class, you will:\n\n- Understand how to solve predictive modelling competitions efficiently and learn which of the skills obtained can be applicable to real-world tasks.\n- Learn how to preprocess the data and generate new features from various sources such as text and images.\n- Be taught advanced feature engineering techniques like generating mean-encodings, using aggregated statistical measures or finding nearest neighbors as a means to improve your predictions.\n- Be able to form reliable cross validation methodologies that help you benchmark your solutions and avoid overfitting or underfitting when tested with unobserved (test) data. \n- Gain experience of analysing and interpreting the data. You will become aware of inconsistencies, high noise levels, errors and other data-related issues such as leakages and you will learn how to overcome them. \n- Acquire knowledge of different algorithms and learn how to efficiently tune their hyperparameters and achieve top performance. \n- Master the art of combining different machine learning models and learn how to ensemble. \n- Get exposed to past (winning) solutions and codes and learn how to read them.\n\nDisclaimer : This is not a machine learning course in the general sense. This course will teach you how to get high-rank solutions against thousands of competitors with focus on practical usage of machine learning methods rather than the theoretical underpinnings behind them.\n\nPrerequisites: \n- Python: work with DataFrames in pandas, plot figures in matplotlib, import and train models from scikit-learn, XGBoost, LightGBM.\n- Machine Learning: basic understanding of linear models, K-NN, random forest, gradient boosting and neural networks.", "target_audience": null, "created_by": "National Research University Higher School of Economics", "teach_by": [{"name": "Dmitry Ulyanov", "department": "HSE Faculty of Computer Science"}, {"name": "Alexander Guschin", "department": "HSE Faculty of Computer Science"}, {"name": "Mikhail Trofimov", "department": "HSE Faculty of Computer Science"}, {"name": "Dmitry Altukhov", "department": "HSE Faculty of Computer Science"}, {"name": "Marios Michailidis", "department": "H2O.ai"}], "package_num": "2", "package_name": "Advanced Machine Learning Specialization ", "level": "Advanced", "rating": "4.8", "week_data": [{"title": "Introduction & Recap", "description": "This week we will introduce you to competitive data science. You will learn about competitions' mechanics, the difference between competitions and a real life data science,  hardware and software that people usually use in competitions. We will also briefly recap major ML models frequently used in competitions.", "video": ["Introduction", "Welcome!", "Meet your lecturers", "Course overview", "Week 1 overview", "Competition Mechanics", "Kaggle Overview [screencast]", "Real World Application vs Competitions", "Practice Quiz", "Recap of main ML algorithms", "Disclaimer", "Recap", "Explanation for quiz questions", "Will performance of GBDT model drop dramatically if we remove the first tree?", "Additional Materials and Links", "Software/Hardware Requirements", "Software/Hardware", "Pandas basics", "Explanation for quiz questions", "Additional Material and Links", "Recap", "Pandas basics", "Graded Soft/Hard Quiz"]}, {"title": "Feature Preprocessing and Generation with Respect to Models", "description": "In this module we will summarize approaches to work with features: preprocessing, generation and extraction. We will see, that the choice of the machine learning model impacts both preprocessing we apply to the features and our approach to generation of new ones. We will also discuss feature extraction from text with Bag Of Words and Word2vec, and feature extraction from images with Convolution Neural Networks.", "video": ["Overview", "Numeric features", "Categorical and ordinal features", "Datetime and coordinates", "Handling missing values", "Feature preprocessing and generation with respect to models", "Explanation for quiz questions", "Additional Material and Links", "Bag of words", "Word2vec, CNN", "Feature extraction from text and images", "Explanation for quiz questions", "Additional Material and Links", "Feature preprocessing and generation with respect to models", "Feature extraction from text and images"]}, {"title": "Final Project Description", "description": "This is just a reminder, that the final project in this course is better to start soon! The final project is in fact a competition, in this module you can find an information about it.", "video": ["Final project", "Final project overview", "Meet and Greet ", "Final project advice #1"]}, {"title": "Exploratory Data Analysis", "description": "We will start this week with Exploratory Data Analysis (EDA). It is a very broad and exciting topic and an essential component of solving process. Besides regular videos you will find a walk through EDA process for Springleaf competition data and an example of prolific EDA for NumerAI competition with extraordinary findings.", "video": ["Week 2 overview", "Exploratory data analysis", "Building intuition about the data", "Reading material for video 2", "Exploring anonymized data", "Notebook for video 3 screencast ", "Visualizations", "Dataset cleaning and other things to check", "Additional material and links", "Notebook for the screencast", "Springleaf competition EDA I", "Springleaf competition EDA II", "Numerai competition EDA", "Exploratory data analysis"]}, {"title": "Validation", "description": "In this module we will discuss various validation strategies. We will see that the strategy we choose depends on the competition setup and that correct validation scheme is one of the bricks for any winning solution.   ", "video": ["Validation and overfitting", "Validation strategies", "Validation strategies", "Data splitting strategies", "Problems occurring during validation", "Validation", "Comments on quiz", "Additional material and links", "Validation"]}, {"title": "Data Leakages", "description": "Finally, in this module we will cover something very unique to data science competitions. That is, we will see examples how it is sometimes possible to get a top position in a competition with a very little machine learning, just by exploiting a data leakage.   ", "video": ["Basic data leaks", "Leaderboard probing and examples of rare data leaks", "Expedia challenge", "Comments on quiz", "Data leakages", "Additional material and links", "Final project advice #2", "Looking for a team", "Data leakages", "Data leakages", "Data leakages"]}, {"title": "Metrics Optimization", "description": "This week we will first study another component of the competitions: the evaluation metrics. We will recap the most prominent ones and then see, how we can efficiently optimize a metric given in a competition.", "video": ["Week 3 overview", "Motivation", "Regression metrics review I", "Constants for MSE and MAE", "Regression metrics review II", "A note about weighted median", "Classification metrics review", "General approaches for metrics optimization", "Regression metrics optimization", "Classification metrics optimization I", "Classification metrics optimization II", "\"Soft kappa\" loss implementation", "Metrics", "Comments on quiz", "Additional material and links", "Metrics"]}, {"title": "Advanced Feature Engineering I", "description": "In this module we will study a very powerful technique for feature generation. It has a lot of names, but here we call it \"mean encodings\". We will see the intuition behind them, how to construct them, regularize and extend them.    ", "video": ["Concept of mean encoding", "Regularization", "Extensions and generalizations", "Comments on quiz", "Mean encoding implementations notebook", "Final project advice #3", "Mean encodings", "Mean encoding implementation"]}, {"title": "Hyperparameter Optimization", "description": "In this module we will talk about hyperparameter optimization process. We will also have a special video with practical tips and tricks, recorded by four instructors.", "video": ["Week 4 overview", "Hyperparameter tuning I", "Hyperparameter tuning II", "How to find sufficient `n_estimators` in Random Forest", "Hyperparameter tuning III", "Practice quiz", "Comments on quiz", "Additional material and links", "Practical guide", "How to use macros in Jupyter", "Additional materials and links", "Graded quiz"]}, {"title": "Advanced feature engineering II", "description": "In this module we will learn about a few more advanced feature engineering techniques.", "video": ["Statistics and distance based features", "Matrix factorizations", "Feature Interactions", "t-SNE", "Comments on quiz", "Additional Materials and Links", "KNN features implementation", "Graded Advanced Features II Quiz", "KNN features implementation"]}, {"title": "Ensembling", "description": "Nowadays it is hard to find a competition won by a single model! Every winning solution incorporates ensembles of models. In this module we will talk about the main ensembling techniques in general, and, of course, how it is better to ensemble the models in practice. ", "video": ["Introduction into ensemble methods", "Bagging", "Boosting", "Stacking", "StackNet", "Ensembling Tips and Tricks", "Validation schemes for 2-nd level models", "Ensembling implementation notebook", "Ensembling", "Comments on quiz", "Additional materials and links", "Final project advice #4", "Ensembling implementation", "Ensembling"]}, {"title": "Competitions go through", "description": "For the 5th week we've prepared for you several \"walk-through\" videos. In these videos we discuss solutions to competitions we took prizes at. The video content is quite short this week to let you spend more time on the final project. Good luck!", "video": ["Week 5 overview", "Crowdflower Competition", "Springleaf Marketing Response", "Microsoft Malware Classification Challenge", "Walmart: Trip Type Classification", "Additional material and links"]}, {"title": "Final Project", "description": "Final project for the course.", "video": ["Final project", "Final project"]}]}, {"title": "Bayesian Methods for Machine Learning", "course_info": "About this course: Bayesian methods are used in lots of fields: from game development to drug discovery. They give superpowers to many machine learning algorithms: handling missing data, extracting  much more information from small datasets. Bayesian methods also allow us to estimate uncertainty in predictions, which is a really desirable feature for fields like medicine. \nWhen Bayesian methods are applied to deep learning, it turns out that they allow you to compress your models 100 folds, and automatically tune hyperparametrs, saving your time and money.\nIn six weeks we will discuss the basics of Bayesian methods: from how to define a probabilistic model to how to make predictions from it. We will see how one can fully automate this workflow and how to speed it up using some advanced techniques. \nWe will also see applications of Bayesian methods to deep learning and how to generate new images with it. We will see how new drugs that cure severe diseases be found with Bayesian methods.", "target_audience": "Who is this class for: This course was designed for students with strong mathematical and machine learning background who want to get a different perspective of ML algorithms.\nNote that this is a very advanced course! You must have strong background in statistics, calculus and linear algebra.", "created_by": "National Research University Higher School of Economics", "teach_by": [{"name": "Daniil Polykovskiy", "department": "HSE Faculty of Computer Science"}, {"name": "Alexander Novikov", "department": "HSE Faculty of Computer Science"}], "package_num": "3", "package_name": "Advanced Machine Learning Specialization ", "level": "Advanced", "rating": "4.4", "week_data": [{"title": "Introduction to Bayesian methods & Conjugate priors", "description": "Welcome to first week of our course! Today we will discuss what bayesian methods are and what are probabilistic models. We will see how they can be used to model real-life situations and how to make conclusions from them. We will also learn about conjugate priors — a class of models where all math becomes really simple.", "video": ["Think bayesian & Statistics review", "Bayesian approach to statistics", "How to define a model", "Example: thief & alarm", "Linear regression", "MLE estimation of Gaussian mean", "Analytical inference", "Conjugate distributions", "Example: Normal, precision", "Example: Bernoulli", "Introduction to Bayesian methods", "Conjugate priors"]}, {"title": "Expectation-Maximization algorithm", "description": "This week we will about the central topic in probabilistic modeling: the Latent Variable Models and how to train them, namely the Expectation Maximization algorithm. We will see models for clustering and dimensionality reduction where Expectation Maximization algorithm can be applied as is. In the following weeks, we will spend weeks 3, 4, and 5 discussing numerous extensions to this algorithm to make it work for more complicated models and scale to large datasets.", "video": ["Latent Variable Models", "Probabilistic clustering", "Gaussian Mixture Model", "Training GMM", "Example of GMM training", "Jensen's inequality & Kullback Leibler divergence", "Expectation-Maximization algorithm", "E-step details", "M-step details", "Example: EM for discrete mixture, E-step", "Example: EM for discrete mixture, M-step", "Summary of Expectation Maximization", "General EM for GMM", "K-means from probabilistic perspective", "K-means, M-step", "Probabilistic PCA", "EM for Probabilistic PCA", "EM algorithm for GMM", "EM algorithm", "Latent Variable Models and EM algorithm", "EM algorithm for GMM"]}, {"title": "Variational Inference & Latent Dirichlet Allocation", "description": "This week we will move on to approximate inference methods. We will see why we care about approximating distributions and see variational inference — one of the most powerful methods for this task. We will also see mean-field approximation in details. And apply it to text-mining algorithm called Latent Dirichlet Allocation", "video": ["Why approximate inference?", "Mean field approximation", "Example: Ising model", "Variational EM & Review", "Topic modeling", "Dirichlet distribution", "Latent Dirichlet Allocation", "LDA: E-step, theta", "LDA: E-step, z", "LDA: M-step & prediction", "Extensions of LDA", "Variational inference", "Latent Dirichlet Allocation"]}, {"title": "Markov chain Monte Carlo", "description": "This week we will learn how to approximate training and inference with sampling and how to sample from complicated distributions. This will allow us to build simple method to deal with LDA and with Bayesian Neural Networks — Neural Networks which weights are random variables themselves and instead of training (finding the best value for the weights) we will sample from the posterior distributions on weights.", "video": ["Monte Carlo estimation", "Sampling from 1-d distributions", "Markov Chains", "Gibbs sampling", "Example of Gibbs sampling", "Metropolis-Hastings", "Metropolis-Hastings: choosing the critic", "Example of Metropolis-Hastings", "Markov Chain Monte Carlo summary", "MCMC for LDA", "Bayesian Neural Networks", "PyMC", "Markov Chain Monte Carlo", "PyMC"]}, {"title": "Variational Autoencoder", "description": "Welcome to the fifth week of the course! This week we will combine many ideas from the previous weeks and add some new to build Variational Autoencoder -- a model that can learn a distribution over structured data (like photographs or molecules) and then sample new data points from the learned distribution, hallucinating new photographs of non-existing people. We will also the same techniques to Bayesian Neural Networks and will see how this can greatly compress the weights of the network without reducing the accuracy.", "video": ["Scaling Variational Inference & Unbiased estimates", "Modeling a distribution of images", "Using CNNs with a mixture of Gaussians", "Scaling variational EM", "Gradient of decoder", "Log derivative trick", "Reparameterization trick", "VAE paper", "Variational Autoencoder", "Learning with priors", "Dropout as Bayesian procedure", "Sparse variational dropout", "Relevant papers", "Categorical Reparametrization with Gumbel-Softmax", "Variational autoencoders", "Variational Autoencoder", "Categorical Reparametrization with Gumbel-Softmax"]}, {"title": "Gaussian processes & Bayesian optimization", "description": "Welcome to the final week of our course! This time we will see nonparametric Bayesian methods. Specifically, we will learn about Gaussian processes and their application to Bayesian optimization that allows one to perform optimization for scenarios in which each function evaluation is very expensive: oil probe, drug discovery and neural network architecture tuning.", "video": ["Nonparametric methods", "Gaussian processes", "GP for machine learning", "Derivation of main formula", "Nuances of GP", "Bayesian optimization", "Applications of Bayesian optimization", "GPy and GPyOpt", "Gaussian Processes and Bayesian Optimization", "GPy and GPyOpt"]}, {"title": "Final project", "description": "In this module you will apply methods that you learned in this course to this final project", "video": ["Final project: Finding the suspect"]}]}, {"title": "Practical Machine Learning", "course_info": "About this course: One of the most common tasks performed by data scientists and data analysts are prediction and machine learning. This course will cover the basic components of building and applying prediction functions with an emphasis on practical applications. The course will provide basic grounding in concepts such as training and tests sets, overfitting, and error rates. The course will also introduce a range of model based and algorithmic machine learning methods including regression, classification trees, Naive Bayes, and random forests. The course will cover the complete process of building prediction functions including data collection, feature creation, algorithms, and evaluation.", "target_audience": null, "created_by": "Johns Hopkins University", "teach_by": [{"name": "Jeff Leek, PhD", "department": "Bloomberg School of Public Health "}, {"name": "Roger D. Peng, PhD", "department": "Bloomberg School of Public Health"}, {"name": "Brian Caffo, PhD", "department": "Bloomberg School of Public Health"}], "package_num": "8", "package_name": "Data Science Specialization ", "level": null, "rating": "4.4", "week_data": [{"title": "Week 1: Prediction, Errors, and Cross Validation", "description": "This week will cover prediction, relative importance of steps, errors, and cross validation.", "video": ["Welcome to Practical Machine Learning", "Syllabus", "Pre-Course Survey", "Prediction motivation", "What is prediction?", "Relative importance of steps", "In and out of sample errors", "Prediction study design", "Types of errors", "Receiver Operating Characteristic", "Cross validation", "What data should you use?", "Quiz 1"]}, {"title": "Week 2: The Caret Package", "description": "This week will introduce the caret package, tools for creating features and preprocessing.", "video": ["Caret package", "Data slicing", "Training options", "Plotting predictors", "Basic preprocessing", "Covariate creation", "Preprocessing with principal components analysis", "Predicting with Regression", "Predicting with Regression Multiple Covariates", "Quiz 2"]}, {"title": "Week 3: Predicting with trees, Random Forests, & Model Based Predictions", "description": "This week we introduce a number of machine learning algorithms you can use to complete your course project.", "video": ["Predicting with trees", "Bagging", "Random Forests", "Boosting", "Model Based Prediction", "Quiz 3"]}, {"title": "Week 4: Regularized Regression and Combining Predictors", "description": "This week, we will cover regularized regression and combining predictors.  ", "video": ["Regularized regression", "Combining predictors", "Forecasting", "Unsupervised Prediction", "Course Project Instructions (READ FIRST)", "Post-Course Survey", "Quiz 4", "Prediction Assignment Writeup", "Course Project Prediction Quiz"]}]}, {"title": "Computational Neuroscience", "course_info": "About this course: This course provides an introduction to basic computational methods for understanding what nervous systems do and for determining how they function. We will explore the computational principles governing various aspects of vision, sensory-motor control, learning, and memory. Specific topics that will be covered include representation of information by spiking neurons, processing of information in neural networks, and algorithms for adaptation and learning. We will make use of Matlab/Octave/Python demonstrations and exercises to gain a deeper understanding of concepts and methods introduced in the course. The course is primarily aimed at third- or fourth-year undergraduates and beginning graduate students, as well as professionals and distance learners interested in learning how the brain processes information.", "target_audience": "Who is this class for: The course is primarily aimed at third- or fourth-year undergraduates and beginning graduate students, as well as professionals and distance learners interested in learning how the brain processes information.", "created_by": "University of Washington", "teach_by": [{"name": "Rajesh P. N. Rao", "department": "Computer Science & Engineering"}, {"name": "Adrienne Fairhall", "department": "Physiology and Biophysics"}], "package_num": null, "package_name": null, "level": "Beginner", "rating": "4.6", "week_data": [{"title": "Introduction & Basic Neurobiology (Rajesh Rao)", "description": "This module includes an Introduction to Computational Neuroscience, along with a primer on Basic Neurobiology. ", "video": ["Welcome Message & Course Logistics", "About the Course Staff", "Syllabus and Schedule", "Matlab & Octave Information and Tutorials", "Python Information and Tutorials", "Week 1 Lecture Notes", "1.1 Course Introduction", "1.2 Computational Neuroscience: Descriptive Models", "1.3 Computational Neuroscience: Mechanistic and Interpretive Models", "1.4 The Electrical Personality of Neurons", "1.5 Making Connections: Synapses", "1.6 Time to Network: Brain Areas and their Function", "Matlab/Octave Programming", "Python Programming"]}, {"title": "What do Neurons Encode? Neural Encoding Models (Adrienne Fairhall)", "description": "This module introduces you to the captivating world of neural information coding. You will learn about the technologies that are used to record brain activity. We will then develop some mathematical formulations that allow us to characterize spikes from neurons as a code, at increasing levels of detail. Finally we investigate variability and noise in the brain, and how our models can accommodate them.", "video": ["Welcome Message", "Week 2 Lecture Notes and Tutorials", "2.1 What is the Neural Code?", "2.2 Neural Encoding: Simple Models", "2.3 Neural Encoding: Feature Selection", "2.4 Neural Encoding: Variability", "Vectors and Functions (by Rich Pang)", "Convolutions and Linear Systems (by Rich Pang)", "Change of Basis and PCA (by Rich Pang)", "Welcome to the Eigenworld! (by Rich Pang)", "IMPORTANT: Quiz Instructions", "Spike Triggered Averages: A Glimpse Into Neural Encoding"]}, {"title": "Extracting Information from Neurons: Neural Decoding (Adrienne Fairhall)", "description": "In this module, we turn the question of neural encoding around and ask: can we estimate what the brain is seeing, intending, or experiencing just from its neural activity? This is the problem of neural decoding and it is playing an increasingly important role in applications such as neuroprosthetics and brain-computer interfaces, where the interface must decode a person's movement intentions from neural activity. As a bonus for this module, you get to enjoy a guest lecture by well-known computational neuroscientist Fred Rieke. ", "video": ["Welcome Message", "Week 3 Lecture Notes and Supplementary Material", "3.1 Neural Decoding and Signal Detection Theory", "3.2 Population Coding and Bayesian Estimation", "3.3 Reading Minds: Stimulus Reconstruction", "Fred Rieke on Visual Processing in the Retina", "Gaussians in One Dimension (by Rich Pang)", "Probability distributions in 2D and Bayes' Rule (by Rich Pang)", "Neural Decoding"]}, {"title": "Information Theory & Neural Coding (Adrienne Fairhall)", "description": "This module will unravel the intimate connections between the venerable field of information theory and that equally venerable object called our brain.", "video": ["Welcome Message", "Week 4 Lecture Notes and Supplementary Material", "4.1 Information and Entropy", "4.2 Calculating Information in Spike Trains", "4.3 Coding Principles", "What's up with entropy? (by Rich Pang)", "Information theory? That's crazy! (by Rich Pang)", "Information Theory & Neural Coding"]}, {"title": "Computing in Carbon (Adrienne Fairhall)", "description": "This module takes you into the world of biophysics of neurons, where you will meet one of the most famous mathematical models in neuroscience, the Hodgkin-Huxley model of action potential (spike) generation. We will also delve into other models of neurons and learn how to model a neuron's structure, including those intricate branches called dendrites.", "video": ["Welcome Message", "Week 5 Lecture Notes and Supplementary Material", "5.1 Modeling Neurons", "5.2 Spikes", "5.3 Simplified Model Neurons", "5.4 A Forest of Dendrites", "Eric Shea-Brown on Neural Correlations and Synchrony", "Dynamical Systems Theory Intro Part 1: Fixed points (by Rich Pang)", "Dynamical Systems Theory Intro Part 2: Nullclines (by Rich Pang)", "Computing in Carbon"]}, {"title": "Computing with Networks (Rajesh Rao)", "description": "This module explores how models of neurons can be connected to create network models. The first lecture shows you how to model those remarkable connections between neurons called synapses. This lecture will leave you in the company of a simple network of integrate-and-fire neurons which follow each other or dance in synchrony. In the second lecture, you will learn about firing rate models and feedforward networks, which transform their inputs to outputs in a single \"feedforward\" pass. The last lecture takes you to the dynamic world of recurrent networks, which use feedback between neurons for amplification, memory, attention, oscillations, and more!", "video": ["Welcome Message", "Week 6 Lecture Notes and Tutorials", "6.1 Modeling Connections Between Neurons", "6.2 Introduction to Network Models", "6.3 The Fascinating World of Recurrent Networks", "Computing with Networks"]}, {"title": "Networks that Learn: Plasticity in the Brain & Learning (Rajesh Rao)", "description": "This module investigates models of synaptic plasticity and learning in the brain, including a Canadian psychologist's prescient prescription for how neurons ought to learn (Hebbian learning) and the revelation that brains can do statistics (even if we ourselves sometimes cannot)! The next two lectures explore unsupervised learning and theories of brain function based on sparse coding and predictive coding.", "video": ["Welcome Message", "Week 7 Lecture Notes and Tutorials", "7.1 Synaptic Plasticity, Hebb's Rule, and Statistical Learning", "7.2 Introduction to Unsupervised Learning", "7.3 Sparse Coding and Predictive Coding", "Gradient Ascent and Descent (by Rich Pang)", "Networks that Learn"]}, {"title": "Learning from Supervision and Rewards (Rajesh Rao)", "description": "In this last module, we explore supervised learning and reinforcement learning. The first lecture introduces you to supervised learning with the help of famous faces from politics and Bollywood, casts neurons as classifiers, and gives you a taste of that bedrock of supervised learning, backpropagation, with whose help you will learn to back a truck into a loading dock.The second and third lectures focus on reinforcement learning. The second lecture will teach you how to predict rewards à la Pavlov's dog and will explore the connection to that important reward-related chemical in our brains: dopamine. In the third lecture, we will learn how to select the best actions for maximizing rewards, and examine a possible neural implementation of our computational model in the brain region known as the basal ganglia. The grand finale: flying a helicopter using reinforcement learning!", "video": ["Welcome Message and Concluding Remarks", "Week 8 Lecture Notes and Supplementary Material", "8.1 Neurons as Classifiers and Supervised Learning", "8.2 Reinforcement Learning: Predicting Rewards", "8.3 Reinforcement Learning: Time for Action!", "Eb Fetz on Bidirectional Brain-Computer Interfaces", "Learning from Supervision and Rewards"]}]}, {"title": "Machine Learning: Regression", "course_info": "About this course: Case Study - Predicting Housing Prices\n\nIn our first case study, predicting house prices, you will create models that predict a continuous value (price) from input features (square footage, number of bedrooms and bathrooms,...).  This is just one of the many places where regression can be applied.  Other applications range from predicting health outcomes in medicine, stock prices in finance, and power usage in high-performance computing, to analyzing which regulators are important for gene expression.\n\nIn this course, you will explore regularized linear regression models for the task of prediction and feature selection.  You will be able to handle very large sets of features and select between models of various complexity.  You will also analyze the impact of aspects of your data -- such as outliers -- on your selected models and predictions.  To fit these models, you will implement optimization algorithms that scale to large datasets.\n\nLearning Outcomes:  By the end of this course, you will be able to:\n   -Describe the input and output of a regression model.\n   -Compare and contrast bias and variance when modeling data.\n   -Estimate model parameters using optimization algorithms.\n   -Tune parameters with cross validation.\n   -Analyze the performance of the model.\n   -Describe the notion of sparsity and how LASSO leads to sparse solutions.\n   -Deploy methods to select between models.\n   -Exploit the model to form predictions. \n   -Build a regression model to predict prices using a housing dataset.\n   -Implement these techniques in Python.", "target_audience": null, "created_by": "University of Washington", "teach_by": [{"name": "Emily Fox", "department": "Statistics"}, {"name": "Carlos Guestrin", "department": "Computer Science and Engineering"}], "package_num": "2", "package_name": "Machine Learning Specialization ", "level": null, "rating": "4.8", "week_data": [{"title": "Welcome", "description": "Regression is one of the most important and broadly used machine learning and statistics tools out there.  It allows you to make predictions from data by learning the relationship between features of your data and some observed, continuous-valued response.  Regression is used in a massive number of applications ranging from predicting stock prices to understanding gene regulatory networks.<p>This introduction to the course provides you with an overview of the topics we will cover and the background knowledge and resources we assume you have.", "video": ["Slides presented in this module", "Welcome!", "What is the course about?", "Outlining the first half of the course", "Outlining the second half of the course", "Assumed background", "Reading: Software tools you'll need"]}, {"title": "Simple Linear Regression", "description": "Our course starts from the most basic regression model: Just fitting a line to data.  This simple model for forming predictions from a single, univariate feature of the data is appropriately called \"simple linear regression\".<p> In this module, we describe the high-level regression task and then specialize these concepts to the simple linear regression case. You will learn how to formulate a simple regression model and fit the model to data using both a closed-form solution as well as an iterative optimization algorithm called gradient descent.  Based on this fitted function, you will interpret the estimated model parameters and form predictions.  You will also analyze the sensitivity of your fit to outlying observations.<p> You will examine all of these concepts in the context of a case study of predicting house prices from the square feet of the house.", "video": ["Slides presented in this module", "A case study in predicting house prices", "Regression fundamentals: data & model", "Regression fundamentals: the task", "Regression ML block diagram", "The simple linear regression model", "The cost of using a given line", "Using the fitted line", "Interpreting the fitted line", "Defining our least squares optimization objective", "Finding maxima or minima analytically", "Maximizing a 1d function: a worked example", "Finding the max via hill climbing", "Finding the min via hill descent", "Choosing stepsize and convergence criteria", "Gradients: derivatives in multiple dimensions", "Gradient descent: multidimensional hill descent", "Computing the gradient of RSS", "Approach 1: closed-form solution", "Optional reading: worked-out example for closed-form solution", "Approach 2: gradient descent", "Optional reading: worked-out example for gradient descent", "Comparing the approaches", "Download notebooks to follow along", "Influence of high leverage points: exploring the data", "Influence of high leverage points: removing Center City", "Influence of high leverage points: removing high-end towns", "Asymmetric cost functions", "A brief recap", "Reading: Fitting a simple linear regression model on housing data", "Simple Linear Regression", "Fitting a simple linear regression model on housing data"]}, {"title": "Multiple Regression", "description": "The next step in moving beyond simple linear regression is to consider \"multiple regression\" where multiple features of the data are used to form predictions.  <p> More specifically, in this module, you will learn how to build models of more complex relationship between a single variable (e.g., 'square feet') and the observed response (like 'house sales price').  This includes things like fitting a polynomial to your data, or capturing seasonal changes in the response value.  You will also learn how to incorporate multiple input variables (e.g., 'square feet', '# bedrooms', '# bathrooms').  You will then be able to describe how all of these models can still be cast within the linear regression framework, but now using multiple \"features\".   Within this multiple regression framework, you will fit models to data, interpret estimated coefficients, and form predictions. <p>Here, you will also implement a gradient descent algorithm for fitting a multiple regression model.", "video": ["Slides presented in this module", "Multiple regression intro", "Polynomial regression", "Modeling seasonality", "Where we see seasonality", "Regression with general features of 1 input", "Motivating the use of multiple inputs", "Defining notation", "Regression with features of multiple inputs", "Interpreting the multiple regression fit", "Optional reading: review of matrix algebra", "Rewriting the single observation model in vector notation", "Rewriting the model for all observations in matrix notation", "Computing the cost of a D-dimensional curve", "Computing the gradient of RSS", "Approach 1: closed-form solution", "Discussing the closed-form solution", "Approach 2: gradient descent", "Feature-by-feature update", "Algorithmic summary of gradient descent approach", "A brief recap", "Reading: Exploring different multiple regression models for house price prediction", "Numpy tutorial", "Reading: Implementing gradient descent for multiple regression", "Multiple Regression", "Exploring different multiple regression models for house price prediction", "Implementing gradient descent for multiple regression"]}, {"title": "Assessing Performance", "description": "Having learned about linear regression models and algorithms for estimating the parameters of such models, you are now ready to assess how well your considered method should perform in predicting new data.  You are also ready to select amongst possible models to choose the best performing.  <p> This module is all about these important topics of model selection and assessment.  You will examine both theoretical and practical aspects of such analyses. You will first explore the concept of measuring the \"loss\" of your predictions, and use this to define training, test, and generalization error.  For these measures of error, you will analyze how they vary with model complexity and how they might be utilized to form a valid assessment of predictive performance.  This leads directly to an important conversation about the bias-variance tradeoff, which is fundamental to machine learning.  Finally, you will devise a method to first select amongst models and then assess the performance of the selected model. <p>The concepts described in this module are key to all machine learning problems, well-beyond the regression setting addressed in this course.", "video": ["Slides presented in this module", "Assessing performance intro", "What do we mean by \"loss\"?", "Training error: assessing loss on the training set", "Generalization error: what we really want", "Test error: what we can actually compute", "Defining overfitting", "Training/test split", "Irreducible error and bias", "Variance and the bias-variance tradeoff", "Error vs. amount of data", "Formally defining the 3 sources of error", "Formally deriving why 3 sources of error", "Training/validation/test split for model selection, fitting, and assessment", "A brief recap", "Reading: Exploring the bias-variance tradeoff", "Assessing Performance", "Exploring the bias-variance tradeoff"]}, {"title": "Ridge Regression", "description": "You have examined how the performance of a model varies with increasing model complexity, and can describe the potential pitfall of complex models becoming overfit to the training data.   In this module, you will explore a very simple, but extremely effective technique for automatically coping with this issue.  This method is called \"ridge regression\".  You start out with a complex model, but now fit the model in a manner that not only incorporates a measure of fit to the training data, but also a term that biases the solution away from overfitted functions.  To this end, you will explore symptoms of overfitted functions and use this to define a quantitative measure to use in your revised optimization objective.  You will derive both a closed-form and gradient descent algorithm for fitting the ridge regression objective; these forms are small modifications from the original algorithms you derived for multiple regression.  To select the strength of the bias away from overfitting, you will explore a general-purpose method called \"cross validation\". <p>You will implement both cross-validation and gradient descent to fit a ridge regression model and select the regularization constant.", "video": ["Slides presented in this module", "Symptoms of overfitting in polynomial regression", "Download the notebook and follow along", "Overfitting demo", "Overfitting for more general multiple regression models", "Balancing fit and magnitude of coefficients", "The resulting ridge objective and its extreme solutions", "How ridge regression balances bias and variance", "Download the notebook and follow along", "Ridge regression demo", "The ridge coefficient path", "Computing the gradient of the ridge objective", "Approach 1: closed-form solution", "Discussing the closed-form solution", "Approach 2: gradient descent", "Selecting tuning parameters via cross validation", "K-fold cross validation", "How to handle the intercept", "A brief recap", "Reading: Observing effects of L2 penalty in polynomial regression", "Reading: Implementing ridge regression via gradient descent", "Ridge Regression", "Observing effects of L2 penalty in polynomial regression", "Implementing ridge regression via gradient descent"]}, {"title": "Feature Selection & Lasso", "description": "A fundamental machine learning task is to select amongst a set of features to include in a model.  In this module, you will explore this idea in the context of multiple regression, and describe how such feature selection is important for both interpretability and efficiency of forming predictions. <p> To start, you will examine methods that search over an enumeration of models including different subsets of features.  You will analyze both exhaustive search and greedy algorithms.  Then, instead of an explicit enumeration, we turn to Lasso regression, which implicitly performs feature selection in a manner akin to ridge regression: A complex model is fit based on a measure of fit to the training data plus a measure of overfitting different than that used in ridge.  This lasso method has had impact in numerous applied domains, and the ideas behind the method have fundamentally changed machine learning and statistics. You will also implement a coordinate descent algorithm for fitting a Lasso model. <p>Coordinate descent is another, general, optimization technique, which is useful in many areas of machine learning. ", "video": ["Slides presented in this module", "The feature selection task", "All subsets", "Complexity of all subsets", "Greedy algorithms", "Complexity of the greedy forward stepwise algorithm", "Can we use regularization for feature selection?", "Thresholding ridge coefficients?", "The lasso objective and its coefficient path", "Visualizing the ridge cost", "Visualizing the ridge solution", "Visualizing the lasso cost and solution", "Download the notebook and follow along", "Lasso demo", "What makes the lasso objective different", "Coordinate descent", "Normalizing features", "Coordinate descent for least squares regression (normalized features)", "Coordinate descent for lasso (normalized features)", "Assessing convergence and other lasso solvers", "Coordinate descent for lasso (unnormalized features)", "Deriving the lasso coordinate descent update", "Choosing the penalty strength and other practical issues with lasso", "A brief recap", "Reading: Using LASSO to select features", "Reading: Implementing LASSO using coordinate descent", "Feature Selection and Lasso", "Using LASSO to select features", "Implementing LASSO using coordinate descent"]}, {"title": "Nearest Neighbors & Kernel Regression", "description": "Up to this point, we have focused on methods that fit parametric functions---like polynomials and hyperplanes---to the entire dataset.  In this module, we instead turn our attention to a class of \"nonparametric\" methods.  These methods allow the complexity of the model to increase as more data are observed, and result in fits that adapt locally to the observations.  <p> We start by considering the simple and intuitive example of nonparametric methods, nearest neighbor regression: The prediction for a query point is based on the outputs of the most related observations in the training set.  This approach is extremely simple, but can provide excellent predictions, especially for large datasets. You will deploy algorithms to search for the nearest neighbors and form predictions based on the discovered neighbors.  Building on this idea, we turn to kernel regression.  Instead of forming predictions based on a small set of neighboring observations, kernel regression uses all observations in the dataset, but the impact of these observations on the predicted value is weighted by their similarity to the query point.  You will analyze the theoretical performance of these methods in the limit of infinite training data, and explore the scenarios in which these methods work well versus struggle.  You will also implement these techniques and observe their practical behavior.", "video": ["Slides presented in this module", "Limitations of parametric regression", "1-Nearest neighbor regression approach", "Distance metrics", "1-Nearest neighbor algorithm", "k-Nearest neighbors regression", "k-Nearest neighbors in practice", "Weighted k-nearest neighbors", "From weighted k-NN to kernel regression", "Global fits of parametric models vs. local fits of kernel regression", "Performance of NN as amount of data grows", "Issues with high-dimensions, data scarcity, and computational complexity", "k-NN for classification", "A brief recap", "Reading: Predicting house prices using k-nearest neighbors regression", "Nearest Neighbors & Kernel Regression", "Predicting house prices using k-nearest neighbors regression"]}, {"title": "Closing Remarks", "description": "In the conclusion of the course, we will recap what we have covered.  This represents both techniques specific to regression, as well as foundational machine learning concepts that will appear throughout the specialization.  We also briefly discuss some important regression techniques we did not cover in this course.<p> We conclude with an overview of what's in store for you in the rest of the specialization.  ", "video": ["Slides presented in this module", "Simple and multiple regression", "Assessing performance and ridge regression", "Feature selection, lasso, and nearest neighbor regression", "What we covered and what we didn't cover", "Thank you!"]}]}, {"title": "Probabilistic Graphical Models 1: Representation", "course_info": "About this course: Probabilistic graphical models (PGMs) are a rich framework for encoding probability distributions over complex domains: joint (multivariate) distributions over large numbers of random variables that interact with each other. These representations sit at the intersection of statistics and computer science, relying on concepts from probability theory, graph algorithms, machine learning, and more. They are the basis for the state-of-the-art methods in a wide variety of applications, such as medical diagnosis, image understanding, speech recognition, natural language processing, and many, many more. They are also a foundational tool in formulating many machine learning problems. \n\nThis course is the first in a sequence of three. It describes the two basic PGM representations: Bayesian Networks, which rely on a directed graph; and Markov networks, which use an undirected graph. The course discusses both the theoretical properties of these representations as well as their use in practice. The (highly recommended) honors track contains several hands-on assignments on how to represent some real-world problems. The course also presents some important extensions beyond the basic PGM representation, which allow more complex models to be encoded compactly.", "target_audience": null, "created_by": "Stanford University", "teach_by": [{"name": "Daphne Koller", "department": "School of Engineering"}], "package_num": "1", "package_name": "Probabilistic Graphical Models  Specialization ", "level": "Advanced", "rating": "4.7", "week_data": [{"title": "Introduction and Overview", "description": "This module provides an overall introduction to probabilistic graphical models, and defines a few of the key concepts that will be used later in the course.", "video": ["Welcome!", "Overview and Motivation", "Distributions", "Factors", "Basic Definitions"]}, {"title": "Bayesian Network (Directed Models)", "description": "In this module, we define the Bayesian network representation and its semantics. We also analyze the relationship between the graph structure and the independence properties of a distribution represented over that graph. Finally, we give some practical tips on how to model a real-world situation as a Bayesian network.", "video": ["Semantics & Factorization", "Reasoning Patterns", "Flow of Probabilistic Influence", "Conditional Independence", "Independencies in Bayesian Networks", "Naive Bayes", "Application - Medical Diagnosis", "Knowledge Engineering Example - SAMIAM", "Setting Up Your Programming Assignment Environment", "Installing Octave/MATLAB on Windows", "Installing Octave/MATLAB on Mac OS X (10.10 Yosemite and 10.9 Mavericks)", "Installing Octave/MATLAB on Mac OS X (10.8 Mountain Lion and Earlier)", "Installing Octave/MATLAB on GNU/Linux", "More Octave/MATLAB resources", "Basic Operations ", "Moving Data Around ", "Computing On Data ", "Plotting Data ", "Control Statements: for, while, if statements ", "Vectorization ", "Working on and Submitting Programming Exercises ", "Bayesian Network Fundamentals", "Bayesian Network Independencies", "Octave/Matlab installation", "Simple BN Knowledge Engineering"]}, {"title": "Template Models for Bayesian Networks", "description": "In many cases, we need to model distributions that have a recurring structure. In this module, we describe representations for two such situations. One is temporal scenarios, where we want to model a probabilistic structure that holds constant over time; here, we use Hidden Markov Models, or, more generally, Dynamic Bayesian Networks. The other is aimed at scenarios that involve multiple similar entities, each of whose properties is governed by a similar model; here, we use Plate Models.", "video": ["Overview of Template Models", "Temporal Models - DBNs", "Temporal Models - HMMs", "Plate Models", "Template Models"]}, {"title": "Structured CPDs for Bayesian Networks", "description": "A table-based representation of a CPD in a Bayesian network has a size that grows exponentially in the number of parents. There are a variety of other form of CPD that exploit some type of structure in the dependency model to allow for a much more compact representation. Here we describe a number of the ones most commonly used in practice.", "video": ["Overview: Structured CPDs", "Tree-Structured CPDs", "Independence of Causal Influence", "Continuous Variables", "Structured CPDs", "BNs for Genetic Inheritance", "BNs for Genetic Inheritance PA Quiz"]}, {"title": "Markov Networks (Undirected Models)", "description": "In this module, we describe Markov networks (also called Markov random fields): probabilistic graphical models based on an undirected graph representation. We discuss the representation of these models and their semantics. We also analyze the independence properties of distributions encoded by these graphs, and their relationship to the graph structure. We compare these independencies to those encoded by a Bayesian network, giving us some insight on which type of model is more suitable for which scenarios.", "video": ["Pairwise Markov Networks", "General Gibbs Distribution", "Conditional Random Fields", "Independencies in Markov Networks", "I-maps and perfect maps", "Log-Linear Models", "Shared Features in Log-Linear Models", "Markov Networks", "Independencies Revisited", "Markov Networks for OCR"]}, {"title": "Decision Making", "description": "In this module, we discuss the task of decision making under uncertainty. We describe the framework of decision theory, including some aspects of utility functions. We then talk about how decision making scenarios can be encoded as a graphical model called an Influence Diagram, and how such models provide insight both into decision making and the value of information gathering.", "video": ["Maximum Expected Utility", "Utility Functions", "Value of Perfect Information", "Decision Theory", "Decision Making", "Decision Making PA Quiz"]}, {"title": "Knowledge Engineering & Summary", "description": "This module provides an overview of graphical model representations and some of the real-world considerations when modeling a scenario as a graphical model. It also includes the course final exam.", "video": ["Knowledge Engineering", "Representation Final Exam"]}]}, {"title": "Machine Learning: Classification", "course_info": "About this course: Case Studies: Analyzing Sentiment & Loan Default Prediction\n\nIn our case study on analyzing sentiment, you will create models that predict a class (positive/negative sentiment) from input features (text of the reviews, user profile information,...).  In our second case study for this course, loan default prediction, you will tackle financial data, and predict when a loan is likely to be risky or safe for the bank. These tasks are an examples of classification, one of the most widely used areas of machine learning, with a broad array of applications, including ad targeting, spam detection, medical diagnosis and image classification. \n\nIn this course, you will create classifiers that provide state-of-the-art performance on a variety of tasks.  You will become familiar with  the most successful techniques, which are most widely used in practice, including logistic regression, decision trees and boosting.  In addition, you will be able to design and implement the underlying algorithms that can learn these models at scale, using stochastic gradient ascent.  You will implement these technique on real-world, large-scale machine learning tasks.  You will also address significant tasks you will face in real-world applications of ML, including handling missing data and measuring precision and recall to evaluate a classifier.  This course is hands-on, action-packed, and full of visualizations and illustrations of how these techniques will behave on real data.  We've also included optional content in every module, covering advanced topics for those who want to go even deeper! \n\nLearning Objectives: By the end of this course, you will be able to:\n   -Describe the input and output of a classification model.\n   -Tackle both binary and multiclass classification problems.\n   -Implement a logistic regression model for large-scale classification.  \n   -Create a non-linear model using decision trees.\n   -Improve the performance of any model using boosting.\n   -Scale your methods with stochastic gradient ascent.\n   -Describe the underlying decision boundaries.  \n   -Build a classification model to predict sentiment in a product review dataset.  \n   -Analyze financial data to predict loan defaults.\n   -Use techniques for handling missing data.\n   -Evaluate your models using precision-recall metrics.\n   -Implement these techniques in Python (or in the language of your choice, though Python is highly recommended).", "target_audience": null, "created_by": "University of Washington", "teach_by": [{"name": "Carlos Guestrin", "department": "Computer Science and Engineering"}, {"name": "Emily Fox", "department": "Statistics"}], "package_num": "3", "package_name": "Machine Learning Specialization ", "level": null, "rating": "4.7", "week_data": [{"title": "Welcome!", "description": "Classification is one of the most widely used techniques in machine learning, with a broad array of applications, including sentiment analysis, ad targeting, spam detection, risk assessment, medical diagnosis and image classification. The core goal of classification is to predict a category or class y from some inputs x. Through this course, you will become familiar with the fundamental models and algorithms used in classification, as well as a number of core machine learning concepts. Rather than covering all aspects of classification, you will focus on a few core techniques, which are widely used in the real-world to get state-of-the-art performance. By following our hands-on approach, you will implement your own algorithms on multiple real-world tasks, and deeply grasp the core techniques needed to be successful with these approaches in practice. This introduction to the course provides you with an overview of the topics we will cover and the background knowledge and resources we assume you have.", "video": ["Slides presented in this module", "Welcome to the classification course, a part of the Machine Learning Specialization", "What is this course about?", "Impact of classification", "Course overview", "Outline of first half of course", "Outline of second half of course", "Assumed background", "Let's get started!", "Reading: Software tools you'll need"]}, {"title": "Linear Classifiers & Logistic Regression", "description": "Linear classifiers are amongst the most practical classification methods. For example, in our sentiment analysis case-study, a linear classifier associates a coefficient with the counts of each word in the sentence. In this module, you will become proficient in this type of representation. You will focus on a particularly useful type of linear classifier called logistic regression, which, in addition to allowing you to predict a class, provides a probability associated with the prediction. These probabilities are extremely useful, since they provide a degree of confidence in the predictions. In this module, you will also be able to construct features from categorical inputs, and to tackle classification problems with more than two class (multiclass problems). You will examine the results of these techniques on a real-world product sentiment analysis task.", "video": ["Slides presented in this module", "Linear classifiers: A motivating example", "Intuition behind linear classifiers", "Decision boundaries", "Linear classifier model", "Effect of coefficient values on decision boundary", "Using features of the inputs", "Predicting class probabilities", "Review of basics of probabilities", "Review of basics of conditional probabilities", "Using probabilities in classification", "Predicting class probabilities with (generalized) linear models", "The sigmoid (or logistic) link function", "Logistic regression model", "Effect of coefficient values on predicted probabilities", "Overview of learning logistic regression models", "Encoding categorical inputs", "Multiclass classification with 1 versus all", "Recap of logistic regression classifier", "Predicting sentiment from product reviews", "Linear Classifiers & Logistic Regression", "Predicting sentiment from product reviews"]}, {"title": "Learning Linear Classifiers", "description": "Once familiar with linear classifiers and logistic regression, you can now dive in and write your first learning algorithm for classification. In particular, you will use gradient ascent to learn the coefficients of your classifier from data. You first will need to define the quality metric for these tasks using an approach called maximum likelihood estimation (MLE). You will also become familiar with a simple technique for selecting the step size for gradient ascent. An optional, advanced part of this module will cover the derivation of the gradient for logistic regression.  You will implement your own learning algorithm for logistic regression from scratch, and use it to learn a sentiment analysis classifier.", "video": ["Slides presented in this module", "Goal: Learning parameters of logistic regression", "Intuition behind maximum likelihood estimation", "Data likelihood", "Finding best linear classifier with gradient ascent", "Review of gradient ascent", "Learning algorithm for logistic regression", "Example of computing derivative for logistic regression", "Interpreting derivative for logistic regression", "Summary of gradient ascent for logistic regression", "Choosing step size", "Careful with step sizes that are too large", "Rule of thumb for choosing step size", "(VERY OPTIONAL) Deriving gradient of logistic regression: Log trick", "(VERY OPTIONAL) Expressing the log-likelihood", "(VERY OPTIONAL) Deriving probability y=-1 given x", "(VERY OPTIONAL) Rewriting the log likelihood into a simpler form", "(VERY OPTIONAL) Deriving gradient of log likelihood", "Recap of learning logistic regression classifiers", "Implementing logistic regression from scratch", "Learning Linear Classifiers", "Implementing logistic regression from scratch"]}, {"title": "Overfitting & Regularization in Logistic Regression", "description": "As we saw in the regression course, overfitting is perhaps the most significant challenge you will face as you apply machine learning approaches in practice. This challenge can be particularly significant for logistic regression, as you will discover in this module, since we not only risk getting an overly complex decision boundary, but your classifier can also become overly confident about the probabilities it predicts. In this module, you will investigate overfitting in classification in significant detail, and obtain broad practical insights from some interesting visualizations of the classifiers' outputs. You will then add a regularization term to your optimization to mitigate overfitting. You will investigate both L2 regularization to penalize large coefficient values, and L1 regularization to obtain additional sparsity in the coefficients. Finally, you will modify your gradient ascent algorithm to learn regularized logistic regression classifiers. You will implement your own regularized logistic regression classifier from scratch, and investigate the impact of the L2 penalty on real-world sentiment analysis data.", "video": ["Slides presented in this module", "Evaluating a classifier", "Review of overfitting in regression", "Overfitting in classification", "Visualizing overfitting with high-degree polynomial features", "Overfitting in classifiers leads to overconfident predictions", "Visualizing overconfident predictions", "(OPTIONAL) Another perspecting on overfitting in logistic regression", "Penalizing large coefficients to mitigate overfitting", "L2 regularized logistic regression", "Visualizing effect of L2 regularization in logistic regression", "Learning L2 regularized logistic regression with gradient ascent", "Sparse logistic regression with L1 regularization", "Recap of overfitting & regularization in logistic regression", "Logistic Regression with L2 regularization", "Overfitting & Regularization in Logistic Regression", "Logistic Regression with L2 regularization"]}, {"title": "Decision Trees", "description": "Along with linear classifiers, decision trees are amongst the most widely used classification techniques in the real world. This method is extremely intuitive, simple to implement and provides interpretable predictions. In this module, you will become familiar with the core decision trees representation. You will then design a simple, recursive greedy algorithm to learn decision trees from data. Finally, you will extend this approach to deal with continuous inputs, a fundamental requirement for practical problems. In this module, you will investigate a brand new case-study in the financial sector: predicting the risk associated with a bank loan. You will implement your own decision tree learning algorithm on real loan data.", "video": ["Slides presented in this module", "Predicting loan defaults with decision trees", "Intuition behind decision trees", "Task of learning decision trees from data", "Recursive greedy algorithm", "Learning a decision stump", "Selecting best feature to split on", "When to stop recursing", "Making predictions with decision trees", "Multiclass classification with decision trees", "Threshold splits for continuous inputs", "(OPTIONAL) Picking the best threshold to split on", "Visualizing decision boundaries", "Recap of decision trees", "Identifying safe loans with decision trees", "Implementing binary decision trees", "Decision Trees", "Identifying safe loans with decision trees", "Implementing binary decision trees"]}, {"title": "Preventing Overfitting in Decision Trees", "description": "Out of all machine learning techniques, decision trees are amongst the most prone to overfitting. No practical implementation is possible without including approaches that mitigate this challenge. In this module, through various visualizations and investigations, you will investigate why decision trees suffer from significant overfitting problems. Using the principle of Occam's razor, you will mitigate overfitting by learning simpler trees. At first, you will design algorithms that stop the learning process before the decision trees become overly complex. In an optional segment, you will design a very practical approach that learns an overly-complex tree, and then simplifies it with pruning. Your implementation will investigate the effect of these techniques on mitigating overfitting on our real-world loan data set. ", "video": ["Slides presented in this module", "A review of overfitting", "Overfitting in decision trees", "Principle of Occam's razor: Learning simpler decision trees", "Early stopping in learning decision trees", "(OPTIONAL) Motivating pruning", "(OPTIONAL) Pruning decision trees to avoid overfitting", "(OPTIONAL) Tree pruning algorithm", "Recap of overfitting and regularization in decision trees", "Decision Trees in Practice", "Preventing Overfitting in Decision Trees", "Decision Trees in Practice"]}, {"title": "Handling Missing Data", "description": "Real-world machine learning problems are fraught with missing data. That is, very often, some of the inputs are not observed for all data points. This challenge is very significant, happens in most cases, and needs to be addressed carefully to obtain great performance. And, this issue is rarely discussed in machine learning courses. In this module, you will tackle the missing data challenge head on. You will start with the two most basic techniques to convert a dataset with missing data into a clean dataset, namely skipping missing values and inputing missing values. In an advanced section, you will also design a modification of the decision tree learning algorithm that builds decisions about missing data right into the model. You will also explore these techniques in your real-data implementation.  ", "video": ["Slides presented in this module", "Challenge of missing data", "Strategy 1: Purification by skipping missing data", "Strategy 2: Purification by imputing missing data", "Modifying decision trees to handle missing data", "Feature split selection with missing data", "Recap of handling missing data", "Handling Missing Data"]}, {"title": "Boosting", "description": "One of the most exciting theoretical questions that have been asked about machine learning is whether simple classifiers can be combined into a highly accurate ensemble. This question lead to the developing of boosting, one of the most important and practical techniques in machine learning today. This simple approach can boost the accuracy of any classifier, and is widely used in practice, e.g., it's used by more than half of the teams who win the Kaggle machine learning competitions. In this module, you will first define the ensemble classifier, where multiple models vote on the best prediction. You will then explore a boosting algorithm called  AdaBoost, which provides a great approach for boosting classifiers. Through visualizations, you will become familiar with many of the practical aspects of this techniques. You will create your very own implementation of AdaBoost, from scratch, and use it to boost the performance of your loan risk predictor on real data. ", "video": ["Slides presented in this module", "The boosting question", "Ensemble classifiers", "Boosting", "AdaBoost overview", "Weighted error", "Computing coefficient of each ensemble component", "Reweighing data to focus on mistakes", "Normalizing weights", "Example of AdaBoost in action", "Learning boosted decision stumps with AdaBoost", "Exploring Ensemble Methods", "The Boosting Theorem", "Overfitting in boosting", "Ensemble methods, impact of boosting & quick recap", "Boosting a decision stump", "Exploring Ensemble Methods", "Boosting", "Boosting a decision stump"]}, {"title": "Precision-Recall", "description": "In many real-world settings, accuracy or error are not the best quality metrics for classification. You will explore a case-study that significantly highlights this issue: using sentiment analysis to display positive reviews on a restaurant website. Instead of accuracy, you will define two metrics: precision and recall, which are widely used in real-world applications to measure the quality of classifiers. You will explore how the probabilities output by your classifier can be used to trade-off precision with recall, and dive into this spectrum, using precision-recall curves. In your hands-on implementation, you will compute these metrics with your learned classifier on real-world sentiment analysis data.", "video": ["Slides presented in this module", "Case-study where accuracy is not best metric for classification", "What is good performance for a classifier?", "Precision: Fraction of positive predictions that are actually positive", "Recall: Fraction of positive data predicted to be positive", "Precision-recall extremes", "Trading off precision and recall", "Precision-recall curve", "Recap of precision-recall", "Exploring precision and recall", "Precision-Recall", "Exploring precision and recall"]}, {"title": "Scaling to Huge Datasets & Online Learning", "description": "With the advent of the internet, the growth of social media, and the embedding of sensors in the world, the magnitudes of data that our machine learning algorithms must handle have grown tremendously over the last decade. This effect is sometimes called \"Big Data\". Thus, our learning algorithms must scale to bigger and bigger datasets. In this module, you will develop a small modification of gradient ascent called stochastic gradient, which provides significant speedups in the running time of our algorithms. This simple change can drastically improve scaling, but makes the algorithm less stable and harder to use in practice. In this module, you will investigate the practical techniques needed to make stochastic gradient viable, and to thus to obtain learning algorithms that scale to huge datasets. You will also address a new kind of machine learning problem, online learning, where the data streams in over time, and we must learn the coefficients as the data arrives. This task can also be solved with stochastic gradient. You will implement your very own stochastic gradient ascent algorithm for logistic regression from scratch, and evaluate it on sentiment analysis data. ", "video": ["Slides presented in this module", "Gradient ascent won't scale to today's huge datasets", "Timeline of scalable machine learning & stochastic gradient", "Why gradient ascent won't scale", "Stochastic gradient: Learning one data point at a time", "Comparing gradient to stochastic gradient", "Why would stochastic gradient ever work?", "Convergence paths", "Shuffle data before running stochastic gradient", "Choosing step size", "Don't trust last coefficients", "(OPTIONAL) Learning from batches of data", "(OPTIONAL) Measuring convergence", "(OPTIONAL) Adding regularization", "The online learning task", "Using stochastic gradient for online learning", "Scaling to huge datasets through parallelization & module recap", "Training Logistic Regression via Stochastic Gradient Ascent", "Scaling to Huge Datasets & Online Learning", "Training Logistic Regression via Stochastic Gradient Ascent"]}]}, {"title": "The Unix Workbench", "course_info": "About this course: Unix forms a foundation that is often very helpful for accomplishing other goals you might have for you and your computer, whether that goal is running a business, writing a book, curing disease, or creating the next great app. The means to these goals are sometimes carried out by writing software. Software can’t be mined out of the ground, nor can software seeds be planted in spring to harvest by autumn. Software isn’t produced in factories on an assembly line. Software is a hand-made, often bespoke good. If a software developer is an artisan, then Unix is their workbench. Unix provides an essential and simple set of tools in a distraction-free environment. Even if you’re not a software developer learning Unix can open you up to new methods of thinking and novel ways to scale your ideas. \n\nThis course is intended for folks who are new to programming and new to Unix-like operating systems like macOS and Linux distributions like Ubuntu. Most of the technologies discussed in this course will be accessed via a command line interface. Command line interfaces can seem alien at first, so this course attempts to draw parallels between using the command line and actions that you would normally take while using your mouse and keyboard. You’ll also learn how to write little pieces of software in a programming language called Bash, which allows you to connect together the tools we’ll discuss. My hope is that by the end of this course you be able to use different Unix tools as if they’re interconnecting Lego bricks.", "target_audience": "Who is this class for: This course is for people in who want to use the command line, Bash, and Git for data science, machine learning, and artificial intelligence. ", "created_by": "Johns Hopkins University", "teach_by": [{"name": "Sean Kross", "department": "Bloomberg School of Public Health"}, {"name": "Jeff Leek, PhD", "department": "Bloomberg School of Public Health "}, {"name": "Brian Caffo, PhD", "department": "Bloomberg School of Public Health"}, {"name": "Roger D. Peng, PhD", "department": "Bloomberg School of Public Health"}], "package_num": null, "package_name": null, "level": "Beginner", "rating": "4.7", "week_data": [{"title": "Unix and Command Line Basics", "description": "This week we'll help you get access to Unix (you may already be using it), and you'll start using the command line. We'll draw parallels between using your mouse and keyboard with your computer's graphics versus only using the command line.", "video": ["Welcome to Week 1", "Introduction", "The Unix Workbench Book", "What is Unix?", "Mac & Ubuntu Users", "Windows", "Hello Terminal!", "Hello Terminal! Exercises", "Navigating the Command Line", "Navigating the Command Line Exercises", "Creation and Inspection", "Creation and Inspection Exercises", "Migration and Destruction", "Migration and Destruction Exercises", "Command Line Basics"]}, {"title": "Working with Unix", "description": "Now we'll get into the power of different Unix tools. We'll walk through several scenarios where you could use Unix to perform tasks at a much faster speed than you would be able to normally.", "video": ["Welcome to Week 2", "Self-Help", "Self-Help Exercises", "Get Wild", "Get Wild Exercises", "Regular Expressions", "Metacharacters", "Character Sets", "Escaping, Anchors, Odds, and Ends", "Find", "Search Exercises", "History", "Customizing Bash", "Differentiate", "Pipes", "Pipes Exercises", "Make", "Working with Unix"]}, {"title": "Bash Programming", "description": "During this week we'll unleash the command line's usefulness as a programming language. By the end of this week you'll be writing your own little computer programs that you can use on the command line.", "video": ["Welcome to Week 3", "Math", "Math Exercises", "Variables", "Variables Exercises", "User Input", "User Input Exercise", "Conditional Execution", "Conditional Expressions", "If and Else", "Logic and If/Else Exercises", "Arrays", "Arrays Exercises", "Braces", "Braces Exercise", "for", "while", "Nesting", "Loops Exercises", "Writing Functions", "Getting Values from Functions", "Functions Exercises", "The Unix Philosophy", "Making Programs Executable", "Environmental Variables", "Writing Programs Exercises", "Bash Programming"]}, {"title": "Git and GitHub", "description": "First you'll learn how to use Git, which is like \"track changes\" for your code and plain text files, but much more powerful. We'll then explore how to use Git with GitHub, a social coding network where you can publish you projects and explore other's code. ", "video": ["Welcome to Week 4", "What are Git and GitHub?", "Setting Up Git and GitHub", "Getting Started with Git", "Git Exercises", "Gitting Help, Logs, and Diffs", "Ignoring Files", "Important Git Features Exercises", "Branching, Part 1", "Branching, Part 2", "Branching Exercises", "GitHub", "Markdown", "Pull Requests", "Pages", "Forking", "GitHub Exercises", "Git & GitHub", "Bash, Make, Git, and GitHub"]}, {"title": "Nephology", "description": "Finally we'll set up a cloud computing environment so we can explore how computers communicate with each other using the internet.", "video": ["Introduction to Cloud Computing", "Setting Up DigitalOcean", "Connecting to the Cloud", "Moving Files In and Out of the Cloud", "Talking to Other Servers", "Automating Tasks", "Cloud Computing Exercises", "Shutting Down a Server", "Next Steps", "Giving Feedback", "Using This Book", "Nephology"]}]}, {"title": "A developer's guide to the Internet of Things (IoT)", "course_info": "About this course: >>> By enrolling in this course you agree to the End User License Agreement as set out in the FAQ.  Once enrolled you can access the license in the Resources area <<<\n\nThe Internet of Things (IoT) is an area of rapid growth and opportunity. Technical innovations in networks, sensors and applications, coupled with the advent of 'smart machines' have resulted in a huge diversity of devices generating all kinds of structured and unstructured data that needs to be processed somewhere.  Collecting and understanding that data, combining it with other sources of information and putting it to good  use can be achieved by using connectivity, analytical and cognitive services now available on the cloud, allowing development and deployment of solutions to be achieved faster and more efficiently than ever before.\n\nThis course is an entry level introduction to developing and deploying solutions for the Internet of Things. It will focus on capturing data from a trusted device and sending the data to a cloud platform where it can be exploited by the many services available. You will explore all the steps required to create a basic IoT solution using a popular device, the Raspberry Pi, and a trial version of the cloud-based IBM Watson IoT Platform. \n\nWhat you will learn: \nQuickly create applications that leverage connectivity and analytics as part of an integrated IoT platform.  Use Node-RED, an open-source visual application development environment, on both the device and the cloud.  Create a basic IoT solution by leveraging pre-built blocks of code that abstracts and speeds the development process. Use APIs to access the platform and explore the different connectivity options for various devices, gateways and applications. Explore options to ensure your solution makes best use of the captured data. \n \nWhat technology is required to complete the course?  \nThe programming assignments require you to have a Raspberry Pi device - any model of Raspberry Pi with a 40 pin header. The course also uses the SenseHAT extension board, whilst it is preferable to have a SenseHat there is a simulator provided if you can't get a SenseHAT.  \n\nYou will need internet connectivity to download software, connect to the platform, develop and deploy your IoT solution.\n\nYour Rasberry Pi will need the latest Rasbian Jessie OS. This OS will be on a Micro SD Card. The recommended size of the SD card is 8GB but 4GB will do. Note that the learner kit comes with a preconfigured SD card.\n\nIn order to setup the Micro SD card, you will need a computer with either a windows, apple or Linux OS. Since most computer do not have a micro SD port, you will need a Micro SD adapter or USB Micro SD card adapter. Your computer will also be used when working on the platform.\n\nTo work on your Raspberry Pi, you will need an HDMI monitor or TV to work as the display for the Raspberry Pi (DVI monitor will also work). To connect the monitor to the Raspberry Pi you will need an HDMI cable (or a DVI to HDMI cable).\nYour Raspberry Pi needs a way to connect to the internet; either an Ethernet cable for connecting to the Router, or a USB WiFi dongle if you have wireless connectivity. Note that the Raspberry Pi 3 includes built-in WiFi\nA USB Keyboard and mouse.\n\nYour Raspberry Pi will also needs a 5V micro USB power supply i(This may be a phone charger for example)\nThere is an IoT Learner kit available from element14 which includes the Raspberry Pi, a pre-flashed SD card, a case and power supply : https://www.element14.com/community/docs/DOC-82034/l/element14-iot-learner-kit \n\nWhat prerequisite skills are required ?\nThis is an entry level course, but does assume you have basic programming skills. The assignments set use both Python and JavaScript programming languages, so some basic skill in these languages is required. No previous experience with IBM Bluemix or the IBM Watson IoT Platform is required.\n\nWhat additional resources do I need for this course? \nThe Server side code for the assignments will use the IBM Bluemix cloud platform, so you will need to sign up for a free account on that platform.\n\nWhen your 30-day trial expires, you can enter a credit card to keep using Bluemix. Bluemix has a set amount of free resources available to users who have registered with their credit card. If you stay within these free resources limits you will not incur any charges. This is a good idea if you are planning to take longer than 30 days to complete the course, or if you have an existing trial account that that is about to expire and you need longer time on the platform to complete the course.", "target_audience": "Who is this class for: This course is an entry level course for the Internet of Things.  Some basic programming knowledge is assumed and the course requires learners to complete simple programming tasks in both Python and JavaScript.", "created_by": "IBM", "teach_by": [{"name": "Brian Innes", "department": "IBM Digital Business Group"}, {"name": "Yianna Papadakis Kantos", "department": "IBM Watson IoT"}], "package_num": null, "package_name": null, "level": "Beginner", "rating": "4.5", "week_data": [{"title": "Introduction to the course", "description": "Welcome to the course.  This learning module introduces you to course and the instructors.  The module outlines the content covered on the course and gives an introduction to the Internet of Things.  It also discusses the requirements needed to complete the course including the hardware, software and details of prerequisite skills required to complete the programming assignments ", "video": ["Welcome to A developer's guide to the Internet of Things", "Course Prerequisites", "Summary of the lessons", "What practical work is in this course?", "Learning module summary: About this course", "Overview of Internet of Things", "Learning module  summary: What is the Internet of Things?", "IoT Quiz"]}, {"title": "Rapid application development in the cloud", "description": "An Internet of Things solution usually requires a back-end server to receive and process data coming from sensors.  Cloud platforms allow new solutions to be created and deployed very rapidly without having to worry about how to host the application.  This series of lessons introduces you to a cloud based Platform as a Service and an open source rapid application development environment called NodeRED.", "video": ["Introduction to IBM Bluemix - Agenda", "Overview of Cloud Computing", "What is IBM Bluemix?", "Create an IBM Bluemix account", "Get an IBM Cloud promo code", "A tour of IBM Bluemix", "IBM Bluemix Summary", "Learning module summary: Introduction to Platform as a Service - IBM Bluemix", "Deploying Node-RED on the IBM Cloud", "Deploy NodeRED to Bluemix using a Boilerplate - step by step", "Introduction to NodeRED - 1", "Introduction to NodeRED - 2", "Adding a new node - step by step", "Learning module summary: Rapid application development for Internet of Things", "The NodeRED Function node part 1", "Function node - step by step", "The NodeRED Function node part 2", "The NodeRED Function node part 3", "Making packages available to the function node - step by step", "Submitting your first assignment", "Learning module summary: NodeRED function node", "NodeRED Additional node part 1", "NodeRED Additional node part 2", "Template node sample flow", "NodeRED Additional node part 3", "Controlling a node using input data", "NodeRED Additional node part 4", "Learning module summary: Additional NodeRED nodes", "Using the function node", "Your First NodeRED application", "NodeRED application"]}, {"title": "Rapid application development on a Raspberry Pi ", "description": "This unit looks at how to add a device to your solution.  Creating an application on a Raspberry Pi and establishing secure, trusted communication between your cloud application and devices", "video": ["A quick look at devices and sensor options", "Setting up a Raspberry Pi and Raspberry Pi Sense Hat", "Setting up your Raspberry Pi - step by step", "Extra resource – (for Windows) Install the Raspbian Jessie OS on an SD Card", "Learning module summary: Raspberry Pi and SenseHAT", "NodeRED on Raspberry Pi part 1", "NodeRED on Raspberry Pi part 2", "QuickStart flow - step by step", "Learning module summary: Rapid Application Development with NodeRED on a Raspberry Pi", "Watson Internet of Things platform", "Devices, Applications and Gateways part 1", "Devices, Applications and Gateways part 2", "Learning module summary: Introduction to the Watson Internet of Things Platform", "Sending commands to a device", "SenseHAT and SenseHAT simulator nodes in NodeRED", "Additional assistance for the end-to-end assignment", "Learning module summary: Controlling the device", "QuickStart flow on Raspberry Pi", "Using the NodeRED flow editor with your own Watson IoT platform.", "End-to-end scenario"]}, {"title": "Lower level programming for the Internet of Things", "description": "Up to now the course has used the NodeRED rapid application development environment.  This unit looks at how to program for the Internet of Things platform using more traditional programming environments", "video": ["IoT platform APIs", "SenseHAT python API", "Learning module summary: Watson IoT APIs", "MQTT", "MQTT Exercise", "You reached the end of this learning module.  You are now able to:", "Deploying an application to Bluemix part 1", "Application development for Bluemix - basic server step by step", "Deploying an application to Bluemix part 2", "Application development for Bluemix - deploy to Bluemix step by step", "Installing additional developer tools", "Deploying an application to Bluemix part 3", "Application development for Bluemix - accessing services step by step", "Learning module summary: Deploying Applications to Bluemix", "Course summary", "SenseHAT python API", "MQTT in Watson IoT Platform", "Using the IoT APIs in a Bluemix application"]}]}, {"title": "Deep Learning for Business", "course_info": "About this course: Your smartphone, smartwatch, and automobile (if it is a newer model) have AI (Artificial Intelligence) inside serving you every day. In the near future, more advanced “self-learning” capable DL (Deep Learning) and ML (Machine Learning) technology will be used in almost every aspect of your business and industry. So now is the right time to learn what DL and ML is and how to use it in advantage of your company. This course has three parts, where the first part focuses on DL and ML technology based future business strategy including details on new state-of-the-art products/services and open source DL software, which are the future enablers. The second part focuses on the core technologies of DL and ML systems, which include NN (Neural Network), CNN (Convolutional NN), and RNN (Recurrent NN) systems. The third part focuses on four TensorFlow Playground projects, where experience on designing DL NNs can be gained using an easy and fun yet very powerful application called the TensorFlow Playground. This course was designed to help you build business strategies and enable you to conduct technical planning on new DL and ML services and products.", "target_audience": null, "created_by": "Yonsei University", "teach_by": [{"name": "Jong-Moon Chung", "department": "Director, Communications & Networking Laboratory"}], "package_num": null, "package_name": null, "level": "Beginner", "rating": "4.4", "week_data": [{"title": "Deep Learning Products & Services ", "description": "For the course “Deep Learning for Business,” the first module is “Deep Learning Products & Services,” which starts with the lecture “Future Industry Evolution & Artificial Intelligence” that explains past, current, and future industry evolutions and how DL (Deep Learning) and ML (Machine Learning) technology will be used in almost every aspect of future industry in the near future. The following lectures look into the hottest DL and ML products and services that are exciting the business world. First, the “Jeopardy!” winning versatile IBM Watson is introduced along with its DeepQA and AdaptWatson systems that use DL technology. Then the Amazon Echo and Echo Dot products are introduced along with the Alexa cloud based DL personal assistant that uses ASR (Automated Speech Recognition) and NLU (Natural Language Understanding) technology. The next lecture focuses on LettuceBot, which is a DL system that plants lettuce seeds with automatic fertilizer and herbicide nozzles control. Then the computer vision based DL blood cells analysis diagnostic system Athelas is introduced followed by the introduction of a classical and symphonic music composing DL system named AIVA (Artificial Intelligence Virtual Artist). As the last topic of module 1, the upcoming Apple watchOS 4 and the HomePod speaker that was presented at Apple's 2017 WWDC (World Wide Developers Conference) is introduced.", "video": ["0.0 Introduction to Deep Learning for Business", "1.1 Future Industry Evolution & Artificial Intelligence", "1.2 IBM Watson", "1.3 Amazon Echo, Echo Dot, Alexa", "1.4 LettuceBot / 1.5 Athelas / 1.6 AIVA (Artificial Intelligence Virtual Artist) / 1.7 Apple watchOS 4, HomePod speaker", "Ungraded Quiz", "Graded Quiz"]}, {"title": "Business with Deep Learning & Machine Learning", "description": "The second module “Business with Deep Learning & Machine Learning” first focuses on various business considerations based on changes to come due to DL (Deep Learning) and ML (Machine Learning) technology in the lecture “Business Considerations in the Machine Learning Era.” In the following lecture “Business Strategy with Machine Learning & Deep Learning” explains the changes that are needed to be more successful in business, and provides an example of business strategy modeling based on the three stages of preparation, business modeling, and model rechecking & adaptation. The next lecture “Why is Deep Learning Popular Now?” explains the changes in recent technology and support systems that enable the DL systems to perform with amazing speed, accuracy, and reliability. The last lecture “Characteristics of Businesses with DL & ML” first explains DL and ML based business characteristics based on data types, followed by DL & ML deployment options, the competitive landscape, and future opportunities are also introduced.", "video": ["2.1 Business Considerations in the Machine Learning Era", "2.2 Business Strategy with Machine Learning & Deep Learning", "2.3 Why is Deep Learning Popular Now?", "2.4 Characteristics of Businesses with DL & ML", "What is your company’s business plan considering DL (Deep Learning) technology?", "Ungraded Quiz", "Graded Quiz"]}, {"title": "Deep Learning Computing Systems & Software", "description": "The third module “Deep Learning Computing Systems & Software” focuses on the most significant DL (Deep Learning) and ML (Machine Learning) systems and software. Except for the NVIDIA DGX-1, the introduced DL systems and software in this module are not for sale, and therefore, may not seem to be important for business at first glance. But in reality, the companies that created these systems and software are indeed the true leaders of the future DL and ML business era. Therefore, this module introduces the true state-of-the-art level of DL and ML technology. The first lecture introduces the most popular DL open source software TensorFlow, CNTK (Cognitive Toolkit), Keras, Caffe, Theano, and their characteristics. Due to their popularly, strong influence, and diverse capabilities, the following lectures introduce the details of Google TensorFlow and Microsoft CNTK. Next, NVIDIA’s supercomputer DGX-1, that has fully integrated customized DL hardware and software, is introduced. In the following lectures, the most interesting competition of human versus machine is introduced in the Google AlphaGo lecture, and in the ILSVRC (ImageNet Large Scale Visual Recognition Challenge) lecture, the results of competition between cutting edge DL systems is introduced and the winning performance for each year is compared.", "video": ["3.1 Deep Learning Open Source Software / 3.2 Google TensorFlow", "3.3 Microsoft CNTK (Cognitive Toolkit) / 3.4 NVIDIA DGX-1", "3.5 Google AlphaGo", "3.6 ILSVRC (ImageNet Large Scale Visual Recognition Challenge)", "Ungraded Quiz", "Graded Quiz"]}, {"title": "Basics of Deep Learning Neural Networks", "description": "The module “Basics of Deep Learning Neural Networks” first focuses on explaining the technical differences of AI (Artificial Intelligence), ML (Machine Learning), and DL (Deep Learning) in the first lecture titled “What is DL (Deep Learning) and ML (Machine Learning).” In addition, the characteristics of CPUs (Central Processing Units) and GPUs (Graphics Processing Units) used in DL as well as the representative computer performance units of FLOPS (FLoating-Point Operations Per Second) and IPS (Instructions Per Second) are introduced. Next, in the NN (Neural Network) lecture, the biological neuron (nerve cell) and its signal transfer is introduced followed by an ANN (Artificial Neural Network) model of a neuron based on a threshold logic unit and soft output activation functions is introduced. Then the extended NN technologies that uses MLP (Multi-Layer Perceptron), SoftMax, and AutoEncoder are explained. In the last lecture of the module, NN learning based on backpropagation is introduced along with the learning method types, which include supervised learning, unsupervised learning, semi-supervised learning, and reinforcement learning.", "video": ["4.1 What is Deep Learning & Machine Learning?", "4.2 NN (Neural Network)", "4.3 Neural Network Learning (Backpropagation)", "Ungraded Quiz", "Graded Quiz"]}, {"title": "Deep Learning with CNN & RNN ", "description": "The module “Deep Learning with CNN & RNN” focuses on CNN (Convolutional Neural Network) and RNN (Recurrent Neural Network) technology that enable DL (Deep Learning). First the lectures introduce how CNNs used in image/video recognition, recommender systems, natural language processing, and games (like Chess and Go) are made possible through processing in the convolutional layer and feature maps. The lecture also introduces how CNNs use subsampling (pooling), LCN (Local Contrast Normalization), dropout, ensemble, and bagging technology to become more efficient, reliable, robust, and accurate. Next, the lectures introduce how DL with RNN is used in speech recognition (as in Apple's Siri, Google’s Voice Search, and Samsung's S Voice), handwriting recognition, sequence data analysis, and program code generation. Then the details of RNN technologies are introduced, which include S2S (Sequence to Sequence) learning, forward RNN, backward RNN, representation techniques, context based projection, and representation with attention. As the last part of the module, the early model of RNN, which is the FRNN (Fully Recurrent NN), and the currently popular RNN model LSTM (Long Short-Term Memory) is introduced.", "video": ["5.1 Deep Learning with CNN (Convolutional Neural Network)", "5.2 Deep Learning with RNN (Recurrent Neural Network)", "Have you seen any fun/amazing new DL (Deep Learning) based service or product recently?", "Ungraded Quiz", "Graded Quiz"]}, {"title": "Deep Learning Project with  TensorFlow Playground", "description": "The module “Deep Learning Project with TensorFlow Playground” focuses on four NN (Neural Network) design projects, where experience on designing DL (Deep Learning) NNs can be gained using a fun and powerful application called the TensorFlow Playground. The lectures first teach how to use the TensorFlow Playground, which is followed by guidance on three projects so you can easily buildup experience on using the TensorFlow Playground system. Then in Project 4 a “DL NN Design Challenge” is given, where you will need to make the NN “Deeper” by adding hidden layers and neurons to satisfy the classification objectives. The knowledge you obtained in the lecture of Modules 1~5 will be used in these projects.", "video": ["6.1 Introduction to TensorFlow Playground", "6.2 Project Setup, Project 1, and Project 2", "6.3 Project 3 and Project 4", "TensorFlow Playground DL (Deep Learning) NN (Neural Network) Design Challenge"]}]}, {"title": "Machine Learning: Clustering & Retrieval", "course_info": "About this course: Case Studies: Finding Similar Documents\n\nA reader is interested in a specific news article and you want to find similar articles to recommend.  What is the right notion of similarity?  Moreover, what if there are millions of other documents?  Each time you want to a retrieve a new document, do you need to search through all other documents?  How do you group similar documents together?  How do you discover new, emerging topics that the documents cover?   \n\nIn this third case study, finding similar documents, you will examine similarity-based algorithms for retrieval.  In this course, you will also examine structured representations for describing the documents in the corpus, including clustering and mixed membership models, such as latent Dirichlet allocation (LDA).  You will implement expectation maximization (EM) to learn the document clusterings, and see how to scale the methods using MapReduce.\n\nLearning Outcomes:  By the end of this course, you will be able to:\n   -Create a document retrieval system using k-nearest neighbors.\n   -Identify various similarity metrics for text data.\n   -Reduce computations in k-nearest neighbor search by using KD-trees.\n   -Produce approximate nearest neighbors using locality sensitive hashing.\n   -Compare and contrast supervised and unsupervised learning tasks.\n   -Cluster documents by topic using k-means.\n   -Describe how to parallelize k-means using MapReduce.\n   -Examine probabilistic clustering approaches using mixtures models.\n   -Fit a mixture of Gaussian model using expectation maximization (EM).\n   -Perform mixed membership modeling using latent Dirichlet allocation (LDA).\n   -Describe the steps of a Gibbs sampler and how to use its output to draw inferences.\n   -Compare and contrast initialization techniques for non-convex optimization objectives.\n   -Implement these techniques in Python.", "target_audience": null, "created_by": "University of Washington", "teach_by": [{"name": "Emily Fox", "department": "Statistics"}, {"name": "Carlos Guestrin", "department": "Computer Science and Engineering"}], "package_num": "4", "package_name": "Machine Learning Specialization ", "level": null, "rating": "4.6", "week_data": [{"title": "Welcome", "description": "Clustering and retrieval are some of the most high-impact machine learning tools out there.  Retrieval is used in almost every applications and device we interact with, like in providing a set of products related to one a shopper is currently considering, or a list of people you might want to connect with on a social media platform.  Clustering can be used to aid retrieval, but is a more broadly useful tool for automatically discovering structure in data, like uncovering groups of similar patients.<p>This introduction to the course provides you with an overview of the topics we will cover and the background knowledge and resources we assume you have.", "video": ["Slides presented in this module", "Welcome and introduction to clustering and retrieval tasks", "Course overview", "Module-by-module topics covered", "Assumed background", "Software tools you'll need for this course", "A big week ahead!"]}, {"title": "Nearest Neighbor Search", "description": "We start the course by considering a retrieval task of fetching a document similar to one someone is currently reading.  We cast this problem as one of nearest neighbor search, which is a concept we have seen in the Foundations and Regression courses.  However, here, you will take a deep dive into two critical components of the algorithms: the data representation and metric for measuring similarity between pairs of datapoints.  You will examine the computational burden of the naive nearest neighbor search algorithm, and instead implement scalable alternatives using KD-trees for handling large datasets and locality sensitive hashing (LSH) for providing approximate nearest neighbors, even in high-dimensional spaces.  You will explore all of these ideas on a Wikipedia dataset, comparing and contrasting the impact of the various choices you can make on the nearest neighbor results produced.", "video": ["Slides presented in this module", "Retrieval as k-nearest neighbor search", "1-NN algorithm", "k-NN algorithm", "Document representation", "Distance metrics: Euclidean and scaled Euclidean", "Writing (scaled) Euclidean distance using (weighted) inner products", "Distance metrics: Cosine similarity", "To normalize or not and other distance considerations", "Choosing features and metrics for nearest neighbor search", "Complexity of brute force search", "KD-tree representation", "NN search with KD-trees", "Complexity of NN search with KD-trees", "Visualizing scaling behavior of KD-trees", "Approximate k-NN search using KD-trees", "(OPTIONAL) A worked-out example for KD-trees", "Limitations of KD-trees", "LSH as an alternative to KD-trees", "Using random lines to partition points", "Defining more bins", "Searching neighboring bins", "LSH in higher dimensions", "(OPTIONAL) Improving efficiency through multiple tables", "Implementing Locality Sensitive Hashing from scratch", "A brief recap", "Representations and metrics", "Choosing features and metrics for nearest neighbor search", "KD-trees", "Locality Sensitive Hashing", "Implementing Locality Sensitive Hashing from scratch"]}, {"title": "Clustering with k-means", "description": "In clustering, our goal is to group the datapoints in our dataset into disjoint sets.  Motivated by our document analysis case study, you will use clustering to discover thematic groups of articles by \"topic\".  These topics are not provided in this unsupervised learning task; rather, the idea is to output such cluster labels that can be post-facto associated with known topics like \"Science\", \"World News\", etc.  Even without such post-facto labels, you will examine how the clustering output can provide insights into the relationships between datapoints in the dataset.  The first clustering algorithm you will implement is k-means, which is the most widely used clustering algorithm out there.  To scale up k-means, you will learn about the general MapReduce framework for parallelizing and distributing computations, and then how the iterates of k-means can utilize this framework.  You will show that k-means can provide an interpretable grouping of Wikipedia articles when appropriately tuned.", "video": ["Slides presented in this module", "The goal of clustering", "An unsupervised task", "Hope for unsupervised learning, and some challenge cases", "The k-means algorithm", "k-means as coordinate descent", "Smart initialization via k-means++", "Assessing the quality and choosing the number of clusters", "Clustering text data with k-means", "Motivating MapReduce", "The general MapReduce abstraction", "MapReduce execution overview and combiners", "MapReduce for k-means", "Other applications of clustering", "A brief recap", "k-means", "Clustering text data with K-means", "MapReduce for k-means"]}, {"title": "Mixture Models", "description": "In k-means, observations are each hard-assigned to a single cluster, and these assignments are based just on the cluster centers, rather than also incorporating shape information.  In our second module on clustering, you will perform probabilistic model-based clustering that provides (1) a more descriptive notion of a \"cluster\" and (2) accounts for uncertainty in assignments of datapoints to clusters via \"soft assignments\".  You will explore and implement a broadly useful algorithm called expectation maximization (EM) for inferring these soft assignments, as well as the model parameters.  To gain intuition, you will first consider a visually appealing image clustering task.  You will then cluster Wikipedia articles, handling the high-dimensionality of the tf-idf document representation considered.", "video": ["Slides presented in this module", "Motiving probabilistic clustering models", "Aggregating over unknown classes in an image dataset", "Univariate Gaussian distributions", "Bivariate and multivariate Gaussians", "Mixture of Gaussians", "Interpreting the mixture of Gaussian terms", "Scaling mixtures of Gaussians for document clustering", "Computing soft assignments from known cluster parameters", "(OPTIONAL) Responsibilities as Bayes' rule", "Estimating cluster parameters from known cluster assignments", "Estimating cluster parameters from soft assignments", "EM iterates in equations and pictures", "Convergence, initialization, and overfitting of EM", "Relationship to k-means", "(OPTIONAL) A worked-out example for EM", "A brief recap", "Implementing EM for Gaussian mixtures", "Clustering text data with Gaussian mixtures", "EM for Gaussian mixtures", "Implementing EM for Gaussian mixtures", "Clustering text data with Gaussian mixtures"]}, {"title": "Mixed Membership Modeling via Latent Dirichlet Allocation", "description": "The clustering model inherently assumes that data divide into disjoint sets, e.g., documents by topic.  But, often our data objects are better described via memberships in a collection of sets, e.g., multiple topics.  In our fourth module, you will explore latent Dirichlet allocation (LDA) as an example of such a mixed membership model particularly useful in document analysis.  You will interpret the output of LDA, and various ways the output can be utilized, like as a set of learned document features.  The mixed membership modeling ideas you learn about through LDA for document analysis carry over to many other interesting models and applications, like social network models where people have multiple affiliations.<p>Throughout this module, we introduce aspects of Bayesian modeling and a Bayesian inference algorithm called Gibbs sampling.  You will be able to implement a Gibbs sampler for LDA by the end of the module.", "video": ["Slides presented in this module", "Mixed membership models for documents", "An alternative document clustering model", "Components of latent Dirichlet allocation model", "Goal of LDA inference", "The need for Bayesian inference", "Gibbs sampling from 10,000 feet", "A standard Gibbs sampler for LDA", "What is collapsed Gibbs sampling?", "A worked example for LDA: Initial setup", "A worked example for LDA: Deriving the resampling distribution", "Using the output of collapsed Gibbs sampling", "A brief recap", "Modeling text topics with Latent Dirichlet Allocation", "Latent Dirichlet Allocation", "Learning LDA model via Gibbs sampling", "Modeling text topics with Latent Dirichlet Allocation"]}, {"title": "Hierarchical Clustering & Closing Remarks", "description": "In the conclusion of the course, we will recap what we have covered.  This represents both techniques specific to clustering and retrieval, as well as foundational machine learning concepts that are more broadly useful.<p>We provide a quick tour into an alternative clustering approach called hierarchical clustering, which you will experiment with on the Wikipedia dataset.  Following this exploration, we discuss how clustering-type ideas can be applied in other areas like segmenting time series.  We then briefly outline some important clustering and retrieval ideas that we did not cover in this course.<p> We conclude with an overview of what's in store for you in the rest of the specialization.  ", "video": ["Slides presented in this module", "Module 1 recap", "Module 2 recap", "Module 3 recap", "Module 4 recap", "Why hierarchical clustering?", "Divisive clustering", "Agglomerative clustering", "The dendrogram", "Agglomerative clustering details", "Hidden Markov models", "Modeling text data with a hierarchy of clusters", "What we didn't cover", "Thank you!", "Modeling text data with a hierarchy of clusters"]}]}, {"title": "Google Cloud Platform Big Data and Machine Learning Fundamentals", "course_info": "About this course: This 1-week accelerated on-demand course introduces participants to the Big Data and Machine Learning capabilities of Google Cloud Platform (GCP). It provides a quick overview of the Google Cloud Platform and a deeper dive of the data processing capabilities.\n\nAt the end of this course, participants will be able to:\n• Identify the purpose and value of the key Big Data and Machine Learning products in the Google Cloud Platform\n• Use CloudSQL and Cloud Dataproc to migrate existing MySQL and Hadoop/Pig/Spark/Hive workloads to Google Cloud Platform\n• Employ BigQuery and Cloud Datalab to carry out interactive data analysis\n• Choose between Cloud SQL, BigTable and Datastore\n• Train and use a neural network using TensorFlow\n• Choose between different data processing products on the Google Cloud Platform\n\nBefore enrolling in this course, participants should have roughly one (1) year of experience with one or more of the following:\n• A common query language such as SQL\n• Extract, transform, load activities\n• Data modeling\n• Machine learning and/or statistics\n• Programming in Python\n\nGoogle Account Notes:\n• You'll need a Google/Gmail account and a credit card or bank account to sign up for the Google Cloud Platform free trial (Google is currently blocked in China).\n• There is a known issue with certain EU countries where individuals are not able to sign up, but you may sign up as \"business\" status and intend to see a potential economic benefit from the trial. More details at: https://support.google.com/cloud/answer/6090602\n• More Google Cloud Platform free trial FAQs are available at: https://cloud.google.com/free-trial/", "target_audience": "Who is this class for: This class is intended for Data analysts, Data scientists and Business analysts. It is also suitable for IT decision makers evaluating Google Cloud Platform for use by data scientists.\n\nThis class is for people who do the following with big data:\n\n• Extracting, Loading, Transforming, cleaning, and validating data for use in analytics\n• Designing pipelines and architectures for data processing\n• Creating and maintaining machine learning and statistical models\n• Querying datasets, visualizing query results and creating reports", "created_by": "Google Cloud", "teach_by": [{"name": "Google Cloud Training", "department": null}], "package_num": "1", "package_name": "Data Engineering on Google Cloud Platform Specialization ", "level": "Intermediate", "rating": "4.6", "week_data": [{"title": "Introduction to the Data and Machine Learning on Google Cloud Platform Specialization", "description": "", "video": ["Introduction to the Data and Machine Learning Specialization", "Please read me", "Intro to Big Data and Machine Learning Fundamentals", "Course Overview and Agenda", "Meet Your Instructor"]}, {"title": "Module 1: Introduction to Google Cloud Platform and its Big Data Products", "description": "In this module you will be introduced to Google Cloud Platform and the data handling aspects of the platform.", "video": ["Welcome to Introduction to GCP and its Big Data Products", "What is the Google Cloud Platform?", "GCP Big Data Products", "Usage Scenarios", "How to do the Labs", "Sign Up for the Free Trial and Create a Project", "Module 1 Resources", "Module 1 Review"]}, {"title": "Module 2: Foundations of GCP Compute and Storage", "description": "In this module, we introduce the foundations of the Google Cloud Platform: compute and storage and introduce how they work to provide data ingest, storage, and federated analysis.", "video": ["Welcome to Foundations of GCP Compute and Storage", "CPUs On Demand", "Lab 2a Overview", "Start Compute Engine Instance (Lab 2a)", "Lab 2a Review", "A Global Filesystem", "Lab 2b Overview", "Interact with Cloud Storage", "Lab 2b Review", "Module 2 Review", "Module 2 Resources", "Module 2 Resources", "Module 2 Review"]}, {"title": "Module 3: Data Analysis on the Cloud", "description": "In this module we introduce the common Big Data use cases that Google will manage for you. These are the things that are widely done in industry today and for which we provide easy migration to the cloud.", "video": ["Intro to Managed Services for Common Use Cases", "Stepping Stones to Transformation", "Your SQL Database in the Cloud", "Lab 3a Overview", "Setup rentals data in Cloud SQL", "Lab 3a Review", "Managed Hadoop in the Cloud", "Lab 3b Overview", "Recommendations ML with Dataproc", "Lab 3b Review", "Module 3 Review", "Module 3 Resources", "Module 3 Review"]}, {"title": "Module 4: Scaling Data Analysis: Compute with GCP", "description": "This module is about the more transformational technologies in Google Cloud platform that may not have immediate parallels to technologies that attendees are using (“what's next”).", "video": ["Intro to Scaling Data Analysis: Change How You Compute with GCP", "Fast Random Access", "Interactive, Iterative Development & Demo", "Warehouse and Interactively Query Petabytes", "Lab 4a Overview", "Create ML Dataset with BigQuery (Lab 4a)", "Lab 4a Review", "Machine Learning with TensorFlow", "Training and Creating a Neural Network Model", "Lab 4b Overview", "Carry out ML with TensorFlow", "Fully Build Machine Learning Models", "Lab 4c Overview", "Machine Learning APIs (Lab 4c)", "Module 4 Review", "Module 4 Resources", "Module 4 Resources", "Module 4 Review"]}, {"title": "Module 5: Data Processing Architectures: Scalable Ingest, Transform and Load", "description": "In this module we will introduce you to data processing architectures in Google Cloud Platform: Asynchronous processing with TaskQueues. Message-oriented architectures with Pub/Sub. Creating pipelines with Dataflow.", "video": ["Intro to Data Processing Architectures", "Message-oriented Architectures", "Serverless Data Pipelines", "Module 5 Review", "Module 5 Resources", "Module 5 Review"]}, {"title": "Module 6: Summary of Google Cloud Platform, Big Data, and ML", "description": "", "video": ["Summary of GCP, Big Data, and ML", "Next Steps", "Module 6 Resources", "Module 6 Resources"]}]}, {"title": "Machine Learning With Big Data", "course_info": "About this course: Want to make sense of the volumes of data you have collected?  Need to incorporate data-driven decisions into your process?  This course provides an overview of machine learning techniques to explore, analyze, and leverage data.  You will be introduced to tools and algorithms you can use to create machine learning models that learn from data, and to scale those models up to big data problems.\n\nAt the end of the course, you will be able to:\n•\tDesign an approach to leverage data using the steps in the machine learning process.\n•\tApply machine learning techniques to explore and prepare data for modeling.\n•\tIdentify the type of machine learning problem in order to apply the appropriate set of techniques.\n•\tConstruct models that learn from data using widely available open source tools.\n•\tAnalyze big data problems using scalable machine learning algorithms on Spark.", "target_audience": "Who is this class for: This course is for those new to data science.  Completion of “Big Data Integration and Processing” is recommended.  No prior programming experience is needed, although the ability to install applications and utilize a virtual machine is necessary to complete the hands-on assignments.  Refer to the specialization technical requirements for complete hardware and software specifications.", "created_by": "University of California, San Diego", "teach_by": [{"name": "Mai Nguyen", "department": "San Diego Supercomputer Center"}, {"name": "Ilkay Altintas", "department": "San Diego Supercomputer Center"}], "package_num": "4", "package_name": "Big Data Specialization ", "level": null, "rating": "4.5", "week_data": [{"title": "Welcome", "description": "", "video": ["Welcome to Machine Learning With Big Data", "Summary of Big Data Integration and Processing", "Getting to Know You: Tell us about yourself and why you are taking this course.", "Discussion Forum for Course Content Issues"]}, {"title": "Introduction to Machine Learning with Big Data", "description": "", "video": ["Machine Learning Overview", "Categories Of Machine Learning Techniques", "Slides: Machine Learning Overview and Applications", "Machine Learning in Everyday Life", "Machine Learning Process", "Goals and Activities in the Machine Learning Process", "CRISP-DM", "Scaling Up Machine Learning Algorithms", "Tools Used in this Course", "Downloading, Installing and Using KNIME", "Downloading and Installing the Cloudera VM Instructions (Windows)", "Downloading and Installing the Cloudera VM Instructions (Mac)", "Instructions for Downloading Hands On Datasets", "Instructions for Starting Jupyter", "PDFs of Readings for Week 1 Hands-On", "Machine Learning Overview"]}, {"title": "Data Exploration", "description": "", "video": ["Data Terminology", "Data Exploration", "Data Exploration through Summary Statistics", "Data Exploration through Plots", "What's Wrong with Pie Charts?", "Slides: Data Exploration Overview and Terminology", "Description of Daily Weather Dataset", "Exploring Data with KNIME Plots", "Exploring Data with KNIME Plots", "Data Exploration in Spark", "Data Exploration in Spark", "PDFs of Activities for Data Exploration Hands-On Readings", "Data Exploration", "Data Exploration in KNIME and Spark Quiz"]}, {"title": "Data Preparation", "description": "", "video": ["Data Preparation", "Data Quality", "Quality Issues with Real Data", "Addressing Data Quality Issues", "Feature Selection", "Feature Transformation", "Dimensionality Reduction", "Domain Knowledge in Data Preparation", "Slides: Data Preparation for Machine Learning", "Handling Missing Values in KNIME", "Handling Missing Values in KNIME", "Handling Missing Values in Spark", "Handling Missing Values in Spark", "PDFs for Data Preparation Hands-On Readings", "Data Preparation", "Handling Missing Values in KNIME and Spark Quiz"]}, {"title": "Classification", "description": "", "video": ["Classification", "Building and Applying a Classification Model", "Slides: What is Classification?", "Classification Algorithms", "k-Nearest Neighbors", "Decision Trees", "Naïve Bayes", "Slides: Classification Algorithms", "Classification using Decision Tree in KNIME", "Classification using Decision Tree in KNIME", "Interpreting a Decision Tree in KNIME", "Instructions for Changing the Number of Cloudera VM CPUs", "Classification in Spark", "Classification in Spark", "Why Exclude Relative Humidity?", "PDFs for Classification Hands-On Readings", "Classification", "Classification in KNIME and Spark Quiz"]}, {"title": "Evaluation of Machine Learning Models", "description": "", "video": ["Generalization and Overfitting", "Overfitting in Decision Trees", "Using a Validation Set", "Slides: Overfitting: What is it and how would you prevent it?", "Metrics to Evaluate Model Performance", "Confusion Matrix", "Model Interpretability vs. Accuracy", "Slides: Model evaluation metrics and methods", "Evaluation of Decision Tree in KNIME", "Evaluation of Decision Tree in KNIME", "Completed KNIME Workflows", "Evaluation of Decision Tree in Spark", "Evaluation of Decision Tree in Spark", "Comparing Classification Results for KNIME and Spark", "PDFs for Evaluation of Machine Learning Models Hands-On Readings", "Model Evaluation", "Model Evaluation in KNIME and Spark Quiz"]}, {"title": "Regression, Cluster Analysis, and Association Analysis", "description": "", "video": ["Regression Overview", "Linear Regression", "Slides: Regression", "Cluster Analysis", "k-Means Clustering", "Slides: Cluster Analysis", "Clustering Applications", "Association Analysis", "Association Analysis in Detail", "Slides: Association Analysis", "Applications of Association Analysis", "Machine Learning With Big Data - Final Remarks", "Description of Minute Weather Dataset", "Cluster Analysis in Spark", "Cluster Analysis in Spark", "PDFs of Cluster Analysis in Spark Hands-On Readings", "Regression, Cluster Analysis, & Association Analysis", "Cluster Analysis in Spark Quiz"]}]}, {"title": "Text Mining and Analytics", "course_info": "About this course: This course will cover the major techniques for mining and analyzing text data to discover interesting patterns, extract useful knowledge, and support decision making, with an emphasis on statistical approaches that can be generally applied to arbitrary text data in any natural language with no or minimum human effort. \n\nDetailed analysis of text data requires understanding of natural language text, which is known to be a difficult task for computers. However, a number of statistical approaches have been shown to work well for the \"shallow\" but robust analysis of text data for pattern finding and knowledge discovery. You will learn the basic concepts, principles, and major algorithms in text mining and their potential applications.", "target_audience": null, "created_by": "University of Illinois at Urbana-Champaign", "teach_by": [{"name": "ChengXiang Zhai", "department": "Department of Computer Science"}], "package_num": "3", "package_name": "Data Mining  Specialization ", "level": null, "rating": "4.4", "week_data": [{"title": "Orientation", "description": "You will become familiar with the course, your classmates, and our learning environment. The orientation will also help you obtain the technical skills required for the course.", "video": ["Welcome to Text Mining and Analytics!", "Syllabus", "About the Discussion Forums", "Updating your Profile", "Social Media", "Introduction to Text Mining and Analytics", "Course Prerequisites & Completion", "Pre-Quiz", "Orientation Quiz"]}, {"title": "Week 1", "description": "During this module, you will learn the overall course design, an overview of natural language processing techniques and text representation, which are the foundation for all kinds of text-mining applications, and word association mining with a particular focus on mining one of the two basic forms of word associations (i.e., paradigmatic relations).   ", "video": ["Week 1 Overview", "1.1 Overview Text Mining and Analytics: Part 1", "1.2 Overview Text Mining and Analytics: Part 2", "1.3 Natural Language Content Analysis: Part 1", "1.4 Natural Language Content Analysis: Part 2", "1.5 Text Representation: Part 1", "1.6 Text Representation: Part 2", "1.7 Word Association Mining and Analysis", "1.8 Paradigmatic Relation Discovery Part 1", "1.9 Paradigmatic Relation Discovery Part 2", "Week 1 Practice Quiz", "Week 1 Quiz"]}, {"title": "Week 2", "description": "During this module, you will learn more about word association mining with a particular focus on mining the other basic form of word association (i.e., syntagmatic relations), and start learning topic analysis with a focus on techniques for mining one topic from text. ", "video": ["Week 2 Overview", "2.1 Syntagmatic Relation Discovery: Entropy", "2.2 Syntagmatic Relation Discovery: Conditional Entropy", "2.3 Syntagmatic Relation Discovery: Mutual Information: Part 1", "2.4 Syntagmatic Relation Discovery: Mutual Information: Part 2", "2.5 Topic Mining and Analysis: Motivation and Task Definition", "2.6 Topic Mining and Analysis: Term as Topic", "2.7 Topic Mining and Analysis: Probabilistic Topic Models", "2.8 Probabilistic Topic Models: Overview of Statistical Language Models: Part 1", "2.9 Probabilistic Topic Models: Overview of Statistical Language Models: Part 2", "2.10 Probabilistic Topic Models: Mining One Topic", "Week 2 Practice Quiz", "Week 2 Quiz"]}, {"title": "Week 3", "description": "During this module, you will learn topic analysis in depth, including mixture models and how they work, Expectation-Maximization (EM) algorithm and how it can be used to estimate parameters of a mixture model, the basic topic model, Probabilistic Latent Semantic Analysis (PLSA), and how Latent Dirichlet Allocation (LDA) extends PLSA. ", "video": ["Week 3 Overview", "3.1 Probabilistic Topic Models: Mixture of Unigram Language Models", "3.2 Probabilistic Topic Models: Mixture Model Estimation: Part 1", "3.3 Probabilistic Topic Models: Mixture Model Estimation: Part 2", "3.4 Probabilistic Topic Models: Expectation-Maximization Algorithm: Part 1", "3.5 Probabilistic Topic Models: Expectation-Maximization Algorithm: Part 2", "3.6 Probabilistic Topic Models: Expectation-Maximization Algorithm: Part 3", "3.7 Probabilistic Latent Semantic Analysis (PLSA): Part 1", "3.8 Probabilistic Latent Semantic Analysis (PLSA): Part 2", "3.9 Latent Dirichlet Allocation (LDA): Part 1", "3.10 Latent Dirichlet Allocation (LDA): Part 2", "Week 3 Practice Quiz", "Programming Assignments Overview", "Quiz: Week 3 Quiz", "Programming Assignment"]}, {"title": "Week 4", "description": "During this module, you will learn text clustering, including the basic concepts, main clustering techniques, including probabilistic approaches and similarity-based approaches, and how to evaluate text clustering. You will also start learning text categorization, which is related to text clustering, but with pre-defined categories that can be viewed as pre-defining clusters.   ", "video": ["Week 4 Overview", "4.1 Text Clustering: Motivation", "4.2 Text Clustering: Generative Probabilistic Models Part 1", "4.3 Text Clustering: Generative Probabilistic Models Part 2", "4.4 Text Clustering: Generative Probabilistic Models Part 3", "4.5 Text Clustering: Similarity-based Approaches", "4.6 Text Clustering: Evaluation", "4.7 Text Categorization: Motivation", "4.8 Text Categorization: Methods", "4.9 Text Categorization: Generative Probabilistic Models", "Week 4 Practice Quiz", "Week 4 Quiz"]}, {"title": "Week 5", "description": "During this module, you will continue learning about various methods for text categorization, including multiple methods classified under discriminative classifiers, and you will also learn sentiment analysis and opinion mining, including a detailed introduction to a particular technique for sentiment classification (i.e., ordinal regression). ", "video": ["Week 5 Overview", "5.1 Text Categorization: Discriminative Classifier Part 1", "5.2 Text Categorization: Discriminative Classifier Part 2", "5.3 Text Categorization: Evaluation Part 1", "5.4 Text Categorization: Evaluation Part 2", "5.5 Opinion Mining and Sentiment Analysis: Motivation", "5.6 Opinion Mining and Sentiment Analysis: Sentiment Classification", "5.7 Opinion Mining and Sentiment Analysis: Ordinal Logistic Regression", "Week 5 Practice Quiz", "Week 5 Quiz"]}, {"title": "Week 6", "description": "During this module, you will continue learning about sentiment analysis and opinion mining with a focus on Latent Aspect Rating Analysis (LARA), and you will learn about techniques for joint mining of text and non-text data, including contextual text mining techniques for analyzing topics in text in association with various context information such as time, location, authors, and sources of data. You will also see a summary of the entire course.", "video": ["Week 6 Overview", "6.1 Opinion Mining and Sentiment Analysis: Latent Aspect Rating Analysis Part 1", "6.2 Opinion Mining and Sentiment Analysis: Latent Aspect Rating Analysis Part 2", "6.3 Text-Based Prediction", "6.4 Contextual Text Mining: Motivation", "6.5 Contextual Text Mining: Contextual Probabilistic Latent Semantic Analysis", "6.6 Contextual Text Mining: Mining Topics with Social Network Context", "6.7 Contextual Text Mining: Mining Casual Topics with Time Series Supervision", "6.8 Course Summary", "Week 6 Practice Quiz", "Week 6 Quiz"]}]}, {"title": "Serverless Machine Learning with Tensorflow on Google Cloud Platform", "course_info": "About this course: This one-week accelerated on-demand course provides participants a a hands-on introduction to designing and building machine learning models on Google Cloud Platform. Through a combination of presentations, demos, and hand-on labs, participants will learn machine learning (ML) and TensorFlow concepts, and develop hands-on skills in developing, evaluating, and productionizing ML models.\n\nOBJECTIVES\n\nThis course teaches participants the following skills:\n\n  ● Identify use cases for machine learning\n\n  ● Build an ML model using TensorFlow\n\n  ● Build scalable, deployable ML models using Cloud ML\n\n  ● Know the importance of preprocessing and combining features\n\n  ● Incorporate advanced ML concepts into their models\n\n  ● Productionize trained ML models\n\n\nPREREQUISITES\n\nTo get the most of out of this course, participants should have:\n\n  ● Completed Google Cloud Fundamentals- Big Data and Machine Learning course OR have equivalent experience\n\n  ● Basic proficiency with common query language such as SQL\n\n  ● Experience with data modeling, extract, transform, load activities\n\n  ● Developing applications using a common programming language such Python\n\n  ● Familiarity with Machine Learning and/or statistics\n\nNotes:\n• You'll need a Google/Gmail account and a credit card or bank account to sign up for the Google Cloud Platform free trial (Google is currently blocked in China).\n• There is a known issue with certain EU countries where individuals are not able to sign up, but you may sign up as \"business\" status and intend to see a potential economic benefit from the trial. More details at: https://support.google.com/cloud/answer/6090602\n• More Google Cloud Platform free trial FAQs are available at: https://cloud.google.com/free-trial/", "target_audience": "Who is this class for: This class is intended for experienced developers who are responsible for managing big data transformations including 1) Extracting, Loading, Transforming, cleaning, and validating data 2) Designing pipelines and architectures for data processing 3) Creating and maintaining machine learning and statistical models 4) Querying datasets, visualizing query results and creating reports", "created_by": "Google Cloud", "teach_by": [{"name": "Google Cloud Training", "department": null}], "package_num": "4", "package_name": "Data Engineering on Google Cloud Platform Specialization ", "level": "Intermediate", "rating": "4.4", "week_data": [{"title": "Welcome to Serverless Machine Learning on Google Cloud Platform", "description": "", "video": ["Welcome to the Course", "Learn About the Data Engineer Series of GCP Courses", "How to Think About Machine Learning", "Machine Learning Course Pretest"]}, {"title": "Module 1: Getting Started with Machine Learning", "description": "", "video": ["Module 1 Overview", "What is Machine Learning (ML)?", "Playing with Machine Learning (ML)", "A Neural Network Playground", "Combinations and Hierarchies of Features", "Engineering Features, Layers, and Neurons", "The Reality of Machine Learning", "Covering All Use Cases", "Negative Examples and Near-misses", "Explore the Data and Fix Problems", "Think Carefully About Error Metrics", "Cross-entropy is Not Intuitive", "Confusion Matrix", "Classification Accuracy", "Accuracy in Unbalanced Datasets", "Precision and Recall", "Changing the Model Threshold Pt 1", "Changing the Model Threshold Pt 2", "Defining ML Terms from this Lesson", "Creating Machine Learning Datasets for Regression Problems", "Split Dataset and Model Experimentation", "Evaluating the Final Model", "Create ML Datasets Lab Overview", "Create Machine Learning Datasets (Lab 1a)", "Create ML Datasets Lab Review", "Graded Quiz #1"]}, {"title": "Module 2: Building ML models with Tensorflow", "description": "", "video": ["Module 2 Title", "Module 2 Overview", "Module 2 Agenda", "Building Machine Learning Models with TensorFlow", "Getting Started with TensorFlow Lab Overview", "Getting Started with TensorFlow (Lab 2a)", "TensorFlow Lab Review", "TensorFlow for Machine Learning + Lab", "Machine Learning with tf.learn Lab Overview", "Machine Learning using tf.learn (Lab 2b)", "tf.learn Lab Review", "Gaining More Flexibility + Lab", "TensorFlow on Big Data Lab Overview", "TensorFlow on Big Data (Lab 2c)", "Tensorflow on Big Data Lab Review", "The Experiment Framework + Lab", "TensorFlow Resources", "Graded Quiz #2"]}, {"title": "Module 3: Scaling ML models with Cloud ML Engine", "description": "", "video": ["Scaling TF Models with Cloud ML Engine", "Module 3 Overview", "Why Cloud ML Engine?", "Package up a TensorFlow Model", "Lab: Scaling with Cloud ML Engine", "Lab 3: Getting Started with Cloud ML Engine", "Graded Quiz #3"]}, {"title": "Module 4: Feature Engineering", "description": "", "video": ["Module 4 Overview", "Creating Good Features", "2. Value Should Be Known for Prediction", "Quiz: Value Knowable or Not?", "3. Numeric with Meaningful Magnitude?", "4. Enough Examples", "Raw Data to Numeric Features", "5. Good Features Bring Human Insight to Problems", "Build Effective ML with Model Architectures", "Feature Engineering Lab Overview", "Lab 4: Feature Engineering", "Feature Engineering Lab Review", "Hyperparameter Tuning + Demo", "Resources", "Graded Quiz #4"]}]}, {"title": "Introduction to Recommender Systems:  Non-Personalized and Content-Based", "course_info": "About this course: This course, which is designed to serve as the first course in the Recommender Systems specialization, introduces the concept of recommender systems, reviews several examples in detail, and leads you through non-personalized recommendation using summary statistics and product associations, basic stereotype-based or demographic recommendations, and content-based filtering recommendations. \n\nAfter completing this course, you will be able to compute a variety of recommendations from datasets using basic spreadsheet tools, and if you complete the honors track you will also have programmed these recommendations using the open source LensKit recommender toolkit.  \n\nIn addition to detailed lectures and interactive exercises, this course features interviews with several leaders in research and practice on advanced topics and current directions in recommender systems.", "target_audience": "Who is this class for: This course is appropriate for learners who have a basic understanding of statistics. It can be useful both for those exploring applied machine learning and data mining, and for those focused on technology-supported marketing and commerce.   ", "created_by": "University of Minnesota", "teach_by": [{"name": "Joseph A Konstan", "department": "Computer Science and Engineering"}, {"name": "Michael D. Ekstrand", "department": "Dept. of Computer Science, Boise State University"}], "package_num": "1", "package_name": "Recommender Systems Specialization ", "level": "Intermediate", "rating": "4.5", "week_data": [{"title": "Preface", "description": "This brief module introduces the topic of recommender systems (including placing the technology in historical context) and provides an overview of the structure and coverage of the course and specialization.", "video": ["Intro to Recommender Systems", "Intro to Course and Specialization", "Notes on Course Design and Relationship to Prior Courses"]}, {"title": "Introducing Recommender Systems", "description": "This module introduces recommender systems  in more depth.  It includes a detailed taxonomy of the types of recommender systems, and also includes tours of two systems heavily dependent on recommender technology:  MovieLens and Amazon.com. There is an introductory assessment in the final lesson to ensure that you understand the core concepts behind recommendations before we start learning how to compute them.", "video": ["Movielens Tour", "Preferences and Ratings", "Predictions and Recommendations", "Taxonomy of Recommenders I", "Taxonomy of Recommenders II", "Tour of Amazon.com", "Recommender Systems: Past, Present and Future", "About the Honors Track", "Introducing the Honors Track", "Honors: Setting up the development environment", "Downloads and Resources", "Closing Quiz:  Introducing Recommender Systems", "Honors Track Pre-Quiz"]}, {"title": "Non-Personalized and Stereotype-Based Recommenders", "description": "In this module, you will learn several techniques for non- and lightly-personalized recommendations, including how to use meaningful summary statistics, how to compute product association recommendations, and how to explore using demographics as a means for light personalization.  There is both an assignment (trying out these techniques in a spreadsheet) and a quiz to test your comprehension.  ", "video": ["Non-Personalized and Stereotype-Based Recommenders", "Summary Statistics I", "Summary Statistics II", "External Readings on Ranking and Scoring", "Demographics and Related Approaches", "Product Association Recommenders", "Assignment 1 Instructions: Non-Personalized and Stereotype-Based Recommenders", "Assignment #1 Intro Video", "Assignment Intro: Programming Non-Personalized Recommenders", "Assignment Intro: Programming Non-Personalized Recommenders", "LensKit Resources", "Rating Data Information", "Assignment #1:  Response #1:  Top Movies by Mean Rating", "Assignment #1:  Response #2:  Top Movies by Count", "Assignment #1:  Response #3:  Top Movies by Percent Liking", "Assignment #1:  Response #4:  Association with Toy Story", "Assignment #1:  Response #5:  Correlation with Toy Story", "Assignment #1:  Response #6:  Male-Female Differences in Average Rating", "Assignment #1:  Response #7:  Male-Female differences in Liking", "Non-Personalized Recommenders", "Programmming Non-Personalized Recommenders"]}, {"title": "Content-Based Filtering -- Part I", "description": "The next topic in this course is content-based filtering, a technique for personalization based on building a profile of personal interests.  Divided over two weeks, you will learn and practice the basic techniques for content-based filtering and then explore a variety of advanced interfaces and content-based computational techniques being used in recommender systems.  ", "video": ["Introduction to Content-Based Recommenders", "TFIDF and Content Filtering", "Content-Based Filtering: Deeper Dive", "Entree Style Recommenders -- Robin Burke Interview", "Case-Based Reasoning -- Interview with Barry Smyth", "Dialog-Based Recommenders -- Interview with Pearl Pu", "Search, Recommendation, and Target Audiences -- Interview with Sole Pera", "Beyond TFIDF -- Interview with Pasquale Lops"]}, {"title": "Content-Based Filtering -- Part II", "description": "The assessments for content-based filtering include an assignment where you compute three types of profile and prediction using a spreadsheet and a quiz on the topics covered.  The assignment is in three parts -- a written assignment, a video intro, and a \"quiz\" where you provide answers from your work to be automatically graded.", "video": ["Content-Based Recommenders Spreadsheet Assignment (aka Assignment #2)", "Assignment #2 Introduction: Content-Based Filtering in a Spreadsheet", "Tools for Content-Based Filtering", "CBF Programming Intro", "Honors: Intro to programming assignment", "Assignment #2 Answer Form", "Content-Based Filtering", "CBF Programming Assignment"]}, {"title": "Course Wrap-up", "description": "We close this course with a set of mathematical notation that will be helpful as we move forward into a wider range of recommender systems (in later courses in this specialization).  ", "video": ["Unified Mathematical Model", "Related Readings", "Psychology of Preference & Rating -- Interview with Martijn Willemsen"]}]}, {"title": "Text Retrieval and Search Engines", "course_info": "About this course: Recent years have seen a dramatic growth of natural language text data, including web pages, news articles, scientific literature, emails, enterprise documents, and social media such as blog articles, forum posts, product reviews, and tweets. Text data are unique in that they are usually generated directly by humans rather than a computer system or sensors, and are thus especially valuable for discovering knowledge about people’s opinions and preferences, in addition to many other kinds of knowledge that we encode in text. \n\nThis course will cover search engine technologies, which play an important role in any data mining applications involving text data for two reasons. First, while the raw data may be large for any particular problem, it is often a relatively small subset of the data that are relevant, and a search engine is an essential tool for quickly discovering a small subset of relevant text data in a large text collection. Second, search engines are needed to help analysts interpret any patterns discovered in the data by allowing them to examine the relevant original text data to make sense of any discovered pattern. You will learn the basic concepts, principles, and the major techniques in text retrieval, which is the underlying science of search engines.", "target_audience": null, "created_by": "University of Illinois at Urbana-Champaign", "teach_by": [{"name": "ChengXiang Zhai", "department": "Department of Computer Science"}], "package_num": "2", "package_name": "Data Mining  Specialization ", "level": null, "rating": "4.4", "week_data": [{"title": "Orientation", "description": "You will become familiar with the course, your classmates, and our learning environment. The orientation will also help you obtain the technical skills required for the course.", "video": ["Welcome to Text Retrieval and Search Engines!", "Syllabus", "About the Discussion Forums", "Updating your Profile", "Social Media", "Course Errata", "Course Welcome Video", "Course Introduction Video", "Pre-Quiz", "Orientation Quiz"]}, {"title": "Week 1", "description": "During this week's lessons, you will learn of natural language processing techniques, which are the foundation for all kinds of text-processing applications, the concept of a retrieval model, and the basic idea of the vector space model. ", "video": ["Week 1 Overview", "Lesson 1.1: Natural Language Content Analysis", "Lesson 1.2: Text Access", "Lesson 1.3: Text Retrieval Problem", "Lesson 1.4: Overview of Text Retrieval Methods", "Lesson 1.5: Vector Space Model - Basic Idea", "Lesson 1.6: Vector Space Retrieval Model - Simplest Instantiation", "Week 1 Practice Quiz", "Week 1 Quiz"]}, {"title": "Week 2", "description": "In this week's lessons, you will learn how the vector space model works in detail, the major heuristics used in designing a retrieval function for ranking documents with respect to a query, and how to implement an information retrieval system (i.e., a search engine), including how to build an inverted index and how to score documents quickly for a query. ", "video": ["Week 2 Overview", "Lesson 2.1: Vector Space Model - Improved Instantiation", "Lesson 2.2: TF Transformation", "Lesson 2.3: Doc Length Normalization", "Lesson 2.4: Implementation of TR Systems", "Lesson 2.5: System Implementation - Inverted Index Construction", "Lesson 2.6: System Implementation - Fast Search", "Week 2 Practice Quiz", "Week 2 Quiz"]}, {"title": "Week 3", "description": "In this week's lessons, you will learn how to evaluate an information retrieval system (a search engine), including the basic measures for evaluating a set of retrieved results and the major measures for evaluating a ranked list, including the average precision (AP) and the normalized discounted cumulative gain (nDCG), and practical issues in evaluation, including statistical significance testing and pooling.", "video": ["Week 3 Overview", "Lesson 3.1: Evaluation of TR Systems", "Lesson 3.2: Evaluation of TR Systems - Basic Measures", "Lesson 3.3: Evaluation of TR Systems - Evaluating Ranked Lists - Part 1", "Lesson 3.4: Evaluation of TR Systems - Evaluating Ranked Lists - Part 2", "Lesson 3.5: Evaluation of TR Systems - Multi-Level Judgements", "Lesson 3.6: Evaluation of TR Systems - Practical Issues", "Week 3 Practice Quiz", "Programming Assignments Overview", "Week 3 Quiz", "Programming Assignment 1"]}, {"title": "Week 4", "description": "In this week's lessons, you will learn probabilistic retrieval models and statistical language models, particularly the detail of the query likelihood retrieval function with two specific smoothing methods, and how the query likelihood retrieval function is connected with the retrieval heuristics used in the vector space model. ", "video": ["Week 4 Overview", "Lesson 4.1: Probabilistic Retrieval Model - Basic Idea", "Lesson 4.2: Statistical Language Model", "Lesson 4.3: Query Likelihood Retrieval Function", "Lesson 4.4: Statistical Language Model - Part 1", "Lesson 4.5: Statistical Language Model - Part 2", "Lesson 4.6: Smoothing Methods - Part 1", "Lesson 4.7: Smoothing Methods - Part 2", "Week 4 Practice Quiz", "Week 4 Quiz"]}, {"title": "Week 5", "description": "In this week's lessons, you will learn feedback techniques in information retrieval, including the Rocchio feedback method for the vector space model, and a mixture model for feedback with language models. You will also learn how web search engines work, including web crawling, web indexing, and how links between web pages can be leveraged to score web pages. ", "video": ["Week 5 Overview", "Lesson 5.1: Feedback in Text Retrieval", "Lesson 5.2: Feedback in Vector Space Model - Rocchio", "Lesson 5.3: Feedback in Text Retrieval - Feedback in LM", "Lesson 5.4: Web Search: Introduction & Web Crawler", "Lesson 5.5: Web Indexing", "Lesson 5.6: Link Analysis - Part 1", "Lesson 5.7: Link Analysis - Part 2", "Lesson 5.8: Link Analysis - Part 3", "Week 5 Practice Quiz", "Week 5 Quiz"]}, {"title": "Week 6", "description": "In this week's lessons, you will learn how machine learning can be used to combine multiple scoring factors to optimize ranking of documents in web search (i.e., learning to rank), and learn techniques used in recommender systems (also called filtering systems), including content-based recommendation/filtering and collaborative filtering. You will also have a chance to review the entire course.", "video": ["Week 6 Overview", "Lesson 6.1: Learning to Rank - Part 1", "Lesson 6.2: Learning to Rank - Part 2", "Lesson 6.3: Learning to Rank - Part 3", "Lesson 6.4: Future of Web Search", "Lesson 6.5: Recommender Systems: Content-Based Filtering - Part 1", "Lesson 6.6:  Recommender Systems: Content-Based Filtering - Part 2", "Lesson 6.7: Recommender Systems: Collaborative Filtering - Part 1", "Lesson 6.8: Recommender Systems: Collaborative Filtering - Part 2", "Lesson 6.9: Recommender Systems: Collaborative Filtering - Part 3", "Lesson 6.10: Course Summary", "Week 6 Practice Quiz", "Week 6 Quiz", "Programming Assignment 2"]}]}, {"title": "Practical Reinforcement Learning", "course_info": "About this course: The goal of «Intro to Reinforcement learning» is in its name: introduce students to reinforcement learning – the prominent area of modern research in artificial intelligence.  The reinforcement learning differs much from both supervised and unsupervised learning and is more about how humans learn in reality.  \nStudents will learn from this course both theoretical core and recent practical RL methods. Most importantly, they will learn how to apply such methods to practical problems. In six weeks students will be guided through the basics of Reinforcement Learning (RL):  we will talk about essential theory of RL, value-based methods (such as SARSA and Q-learning), policy based algorithms and methods, designed to solve the optimal exploration problem. In addition to algorithms and theory, during the course we will also present useful practical tips and tricks, needed for learning stabilization, and study how to apply the methods to large scale problems with deep neural networks.", "target_audience": "Who is this class for: The course is designed for people  (1) who already know the basics of machine learning and want to broaden their horizons (2) who have never studied the specifics of reinforcement learning and want to fill that gap  (3) who want to understand the methods and details standing behind the breaking AI news.", "created_by": "National Research University Higher School of Economics", "teach_by": [{"name": "Pavel Shvechikov", "department": "HSE Faculty of Computer Science"}, {"name": "Alexander Panin", "department": "HSE Faculty of Computer Science"}], "package_num": "4", "package_name": "Advanced Machine Learning Specialization ", "level": "Intermediate", "rating": null, "week_data": []}, {"title": "Leveraging Unstructured Data with Cloud Dataproc on Google Cloud Platform", "course_info": "About this course: This 1-week, accelerated course builds upon previous courses in the Data Engineering on Google Cloud Platform specialization. Through a combination of video lectures, demonstrations, and hands-on labs, you'll learn how to create and manage computing clusters to run Hadoop, Spark, Pig and/or Hive jobs on Google Cloud Platform.  You will also learn how to access various cloud storage options from their compute clusters and integrate Google’s machine learning capabilities into their analytics programs.  \n\nIn the hands-on labs, you will create and manage Dataproc Clusters using the Web Console and the CLI, and use cluster to run Spark and Pig jobs. You will then create iPython notebooks that integrate with BigQuery and storage and utilize Spark. Finally, you integrate the machine learning APIs into your data analysis.\n\nPre-requisites\n• Google Cloud Platform Big Data & Machine Learning Fundamentals (or equivalent experience)\n• Some knowledge of Python", "target_audience": "Who is this class for: This class is intended for data analysts, data scientists and programmers who want to migrate Hadoop and Spark workloads onto Google Cloud Platform and also learn how leverage Google’s infrastructure and machine learning API’s to enhance the power of big data processing applications.", "created_by": "Google Cloud", "teach_by": [{"name": "Google Cloud Training", "department": null}], "package_num": "2", "package_name": "Data Engineering on Google Cloud Platform Specialization ", "level": "Intermediate", "rating": "4.4", "week_data": [{"title": "Module 1: Introduction to Cloud Dataproc", "description": "", "video": ["Why Unstructured Data?", "What Data Do Enterprises Analyze?", "Even Google Skipped Unstructured Data", "Considering Counting Problems", "Why Cloud Dataproc?", "Cluster Provisioning Considerations", "Imagine Your Cluster Provisioning", "Dataproc Eases Hadoop Management", "Create a Cluster from the Web", "Cluster Configurations and Preemptible Workers", "Customizing a Dataproc Cluster", "Lab Overview for creating a Dataproc Cluster", "Lab Objectives for creating a Dataproc Cluster", "Codelab – Leveraging Unstructured Data, Part 1", "Lab \"Creating a Dataproc Cluster \" Review", "Creating Custom Machine Types", "Module 1 Quiz"]}, {"title": "Module 2: Running Dataproc jobs", "description": "", "video": ["Overview of Running Dataproc Jobs", "Why SSH into a Cluster?", "Lab Overview", "Lab Objectives", "Codelab – Leveraging Unstructured Data, Part 2", "Lab Review", "Separation of Storage and Compute", "Problem of Compute and Storage Rigidity: Scenario 1", "Problem of Compute and Storage Rigidity - Scenario 2", "Moving to a Serverless World", "Submitting Jobs with Dataproc and Cloud Shell", "Lab Overview", "Lab Objectives", "Codelab – Leveraging Unstructured Data, Part 3", "Lab Review", "Module 2 Quiz"]}, {"title": "Module 3: Leveraging GCP", "description": "", "video": ["Introduction to Leveraging GCP", "Leveraging Google Cloud Platform Pt. 1", "Leveraging Google Cloud Platform Pt. 2", "Dataproc vs. Metadata Server", "Lab Intro", "Lab Objectives", "Codelab – Leveraging Unstructured Data, Part 4", "Lab Review", "Why Process BigQuery Data in Spark?", "BigQuery Support", "Tips for Interacting with BigQuery", "Module 3 Quiz"]}, {"title": "Module 4: Analyzing Unstructured Data", "description": "", "video": ["Introduction to Analyzing Unstructured Data", "Infuse Your Business with Machine Learning", "Lab Objectives", "Codelab – Leveraging Unstructured Data, Part 5", "Lab Review", "Module 4 Quiz"]}]}, {"title": "Big Data Applications: Machine Learning at Scale", "course_info": "About this course: Machine learning is transforming the world around us. To become successful, you’d better know what kinds of problems can be solved with machine learning, and how they can be solved. Don’t know where to start? The answer is one button away.\n \nDuring this course you will:\n- Identify practical problems which can be solved with machine learning\n- Build, tune and apply linear models with Spark MLLib\n- Understand methods of text processing\n- Fit decision trees and boost them with ensemble learning\n- Construct your own recommender system.\n \nAs a practical assignment, you will \n- build and apply linear models for classification and regression tasks; \n- learn how to work with texts; \n- automatically construct decision trees and improve their performance with ensemble learning; \n- finally, you will build your own recommender system!\n\nWith these skills, you will be able to tackle many practical machine learning tasks.\n \nWe provide the tools, you choose the place of application to make this world of machines more intelligent.\n\nSpecial thanks to:\n- Prof. Mikhail Roytberg, APT dept., MIPT, who was the initial reviewer of the project, the supervisor and mentor of half of the BigData team. He was the one, who helped to get this show on the road.\n- Oleg Sukhoroslov (PhD, Senior Researcher at IITP RAS), who has been teaching  MapReduce, Hadoop and friends since 2008. Now he is leading the infrastructure team.\n- Oleg Ivchenko (PhD student APT dept., MIPT), Pavel Akhtyamov (MSc. student at APT dept., MIPT) and Vladimir Kuznetsov (Assistant at P.G. Demidov Yaroslavl State University), superbrains who have developed and now maintain the infrastructure used for practical assignments in this course.\n- Asya Roitberg, Eugene Baulin, Marina Sudarikova. These people never sleep to babysit this course day and night, to make your learning experience productive, smooth and exciting.", "target_audience": "Who is this class for: This course is aimed to everybody, who feel interest in Big Data and Machine Learning. \nThe following is a desirable, but not essential:\n- Python\n- Machine Learning basics\n- Experience with Spark\n- Calculus 101\n- Theory of probability 101", "created_by": "Yandex", "teach_by": [{"name": "Vladimir Lesnichenko", "department": null}, {"name": "Pavel Mezentsev ", "department": "PulsePoint inc"}, {"name": "Emeli Dral ", "department": null}, {"name": "Alexey A. Dral", "department": "Algorithms and Programming Technologies dept. MIPT"}, {"name": "Ilya Trofimov", "department": "Yandex"}, {"name": "Evgeny Frolov", "department": "Computational and Data Intensive Science and Engineering"}], "package_num": "3", "package_name": "Big Data for Data Engineers Specialization ", "level": "Advanced", "rating": "3.7", "week_data": [{"title": "Welcome", "description": "", "video": ["Machine Learning Applications for BigData", "Course Structure", "Meet Alexey", "Meet Pavel", "Meet Ilya"]}, {"title": "(Optional) Machine Learning: Introduction", "description": "", "video": ["(Optional) Intuition", "(Optional) Basic concepts", "(Optional) Types of problems and tasks", "(Optional) Supervised learning", "(Optional) Unsupervised learning", "(Optional) Business applications of the machine learning"]}, {"title": "Spark MLLib and Linear Models", "description": "", "video": ["Introduction to large scale machine learning", "First example. Linear regression", "How MLlib library is arranged", "Large scale machine learning. The beginning", "How to train algorithms. Gradient descent method", "How to train algorithms. Second order methods", "Large scale classification. Logistic regression", "Large scale regression and classification. Detailed analysis", "Regularization", "PCA decomposition", "K-means clustering", "Regularization and Unsupervised Techniques", "First Assignment: Instructions", "How to Submit Your First Assignment", "Demo Assignment", "Rate this week", "Spark MLLib and Linear Models"]}, {"title": "Machine Learning with Texts & Feature Engineering", "description": "", "video": ["Welcome", "Feature Engineering for Texts, part 1", "Feature Engineering for Texts, part 2", "N-grams", "Hashing trick", "Feature Enginering for Texts", "Categorical Features", "Feature Interactions", "Categorical Features & Feature Interactions", "Spark ML. Feature Engineering for Texts, part 1", "Spark ML. Feature Engineering for Texts, part 2", "Spark ML. Categorical Features", "Spark ML Tutorial: Text Processing", "Topic Modeling. LDA.", "Word2Vec", "Advanced Machine Learning with Texts", "Rate this week", "Machine Learning with Texts & Feature Engineering"]}, {"title": "Decision Trees & Ensemble Learning", "description": "", "video": ["Welcome", "Decision Trees Basics", "Decision Trees for Regression", "Decision Trees for Classification", "Decision Trees: Summary", "Decision Trees", "Bootstrap & Bagging", "Random Forest", "Bootstrap, Bagging and Random Forest", "Gradient Boosted Decision Trees: Intro & Regression", "Gradient Boosted Decision Trees: Classification", "Stochastic Boosting", "Gradient Boosted Decision Trees: Usage Tips & Summary", "Gradient Boosted Decision Trees", "Spark ML. Decision Trees & Ensembles", "Spark ML. Cross-validation", "Spark ML Programming Tutorial: Decision Trees & CV", "Rate this week", "Decision Trees & Ensemble Learning", "Predict the tree cover type using Random Forest"]}, {"title": "Recommender Systems", "description": "", "video": ["Recommender Systems, Introduction. Part I", "Recommender Systems, Introduction. Part II", "Non-Personalized Recommender Systems", "Content-Based Recommender Systems", "Recommender System Evaluation", "Basic RecSys for Data Engineers", "Collaborative Filtering RecSys: User-User and Item-Item", "RecSys: SVD I", "RecSys: SVD II", "RecSys: SVD III", "RecSys: MF I", "RecSys: MF II", "Moderate RecSys for Data Engineers", "RecSys: iALS I", "RecSys: iALS II", "RecSys: Hybrid I", "RecSys: Hybrid II", "Advanced RecSys for Data Engineers", "Recommender Systems. Spark Assignment", "Rate this week", "Recommender Systems"]}, {"title": "Recommender Systems (practice week)", "description": "", "video": ["Recommender Systems. Spark Assignment", "Rate this week", "Recommender Systems. Spark Assignment"]}]}, {"title": "Probabilistic Graphical Models 2: Inference", "course_info": "About this course: Probabilistic graphical models (PGMs) are a rich framework for encoding probability distributions over complex domains: joint (multivariate) distributions over large numbers of random variables that interact with each other. These representations sit at the intersection of statistics and computer science, relying on concepts from probability theory, graph algorithms, machine learning, and more. They are the basis for the state-of-the-art methods in a wide variety of applications, such as medical diagnosis, image understanding, speech recognition, natural language processing, and many, many more. They are also a foundational tool in formulating many machine learning problems. \n\nThis course is the second in a sequence of three. Following the first course, which focused on representation, this course addresses the question of probabilistic inference: how a PGM can be used to answer questions. Even though a PGM generally describes a very high dimensional distribution, its structure is designed so as to allow questions to be answered efficiently. The course presents both exact and approximate algorithms for different types of inference tasks, and discusses where each could best be applied. The (highly recommended) honors track contains two hands-on programming assignments, in which key routines of the most commonly used exact and approximate algorithms are implemented and applied to a real-world problem.", "target_audience": null, "created_by": "Stanford University", "teach_by": [{"name": "Daphne Koller", "department": "School of Engineering"}], "package_num": "2", "package_name": "Probabilistic Graphical Models  Specialization ", "level": "Advanced", "rating": "4.6", "week_data": [{"title": "Inference Overview ", "description": "This module provides a high-level overview of the main types of inference tasks typically encountered in graphical models: conditional probability queries, and finding the most likely assignment (MAP inference).", "video": ["Overview: Conditional Probability Queries", "Overview: MAP Inference"]}, {"title": "Variable Elimination", "description": "This module presents the simplest algorithm for exact inference in graphical models: variable elimination. We describe the algorithm, and analyze its complexity in terms of properties of the graph structure.", "video": ["Variable Elimination Algorithm", "Complexity of Variable Elimination", "Graph-Based Perspective on Variable Elimination", "Finding Elimination Orderings", "Variable Elimination"]}, {"title": "Belief Propagation Algorithms ", "description": "This module describes an alternative view of exact inference in graphical models: that of message passing between clusters each of which encodes a factor over a subset of variables. This framework provides a basis for a variety of exact and approximate inference algorithms. We focus here on the basic framework and on its instantiation in the exact case of clique tree propagation. An optional lesson describes the loopy belief propagation (LBP) algorithm and its properties.", "video": ["Belief Propagation Algorithm", "Properties of Cluster Graphs", "Properties of Belief Propagation", "Clique Tree Algorithm - Correctness", "Clique Tree Algorithm - Computation", "Clique Trees and Independence", "Clique Trees and VE", "BP In Practice", "Loopy BP and Message Decoding", "Message Passing in Cluster Graphs", "Clique Tree Algorithm", "Exact Inference"]}, {"title": "MAP Algorithms", "description": "This module describes algorithms for finding the most likely assignment for a distribution encoded as a PGM (a task known as MAP inference). We describe message passing algorithms, which are very similar to the algorithms for computing conditional probabilities, except that we need to also consider how to decode the results to construct a single assignment. In an optional module, we describe a few other algorithms that are able to use very different techniques by exploiting the combinatorial optimization nature of the MAP task.", "video": ["Max Sum Message Passing", "Finding a MAP Assignment", "Tractable MAP Problems", "Dual Decomposition - Intuition", "Dual Decomposition - Algorithm", "MAP Message Passing"]}, {"title": "Sampling Methods", "description": "In this module, we discuss a class of algorithms that uses random sampling to provide approximate answers to conditional probability queries. Most commonly used among these is the class of Markov Chain Monte Carlo (MCMC) algorithms, which includes the simple Gibbs sampling algorithm, as well as a family of methods known as Metropolis-Hastings.", "video": ["Simple Sampling", "Markov Chain Monte Carlo", "Using a Markov Chain", "Gibbs Sampling", "Metropolis Hastings Algorithm", "Sampling Methods", "Sampling Methods", "Sampling Methods PA Quiz"]}, {"title": "Inference in Temporal Models", "description": "In this brief lesson, we discuss some of the complexities of applying some of the exact or approximate inference algorithms that we learned earlier in this course to dynamic Bayesian networks.", "video": ["Inference in Temporal Models", "Inference in Temporal Models"]}, {"title": "Inference Summary", "description": "This module summarizes some of the topics that we covered in this course and discusses tradeoffs between different algorithms. It also includes the course final exam.", "video": ["Inference: Summary", "Inference Final Exam"]}]}, {"title": "Social Media Data Analytics", "course_info": "About this course: Learner Outcomes: After taking this course, you will be able to:\n- Utilize various Application Programming Interface (API) services to collect data from different social media sources such as YouTube, Twitter, and Flickr.\n- Process the collected data - primarily structured - using methods involving correlation, regression, and classification to derive insights about the sources and people who generated that data.\n- Analyze unstructured data - primarily textual comments - for sentiments expressed in them.\n- Use different tools for collecting, analyzing, and exploring social media data for research and development purposes.\n\nSample Learner Story: Data analyst wanting to leverage social media data.\nIsabella is a Data Analyst working as a consultant for a multinational corporation. She has experience working with Web analysis tools as well as marketing data. She wants to now expand into social media arena, trying to leverage the vast amounts of data available through various social media channels. Specifically, she wants to see how their clients, partners, and competitors view their products/services and talk about them. She hopes to build a new workflow of data analytics that incorporates traditional data processing using Web and marketing tools, as well as newer methods of using social media data.\n\nSample Job Roles requiring these skills: \n- Social Media Analyst\n- Web Analyst\n- Data Analyst\n- Marketing and Public Relations \n\nFinal Project Deliverable/ Artifact: The course will have a series of small assignments or mini-projects that involve data collection, analysis, and presentation involving various social media sources using the techniques learned in the class.", "target_audience": "Who is this class for: This course is for students who have at least some beginning training in technologies, including programming and databases. Specifically, it is expected that the student has done some programming before such as C, Java, Python, PHP, Perl, Pascal, Cobol, and JavaScript. The minimal training from any of such programming language expected is the understanding of variable declaration (x=10), condition checking (if x==10), and simple loops (while x<10). The student may or may not have some knowledge of statistics for data analysis - an optional statistics module will be included for reference.", "created_by": "Rutgers the State University of New Jersey", "teach_by": [{"name": "Chirag Shah", "department": "Information and Computer Science"}], "package_num": null, "package_name": null, "level": "Intermediate", "rating": "4.0", "week_data": [{"title": "Introduction to Data Analytics", "description": "In this first unit of the course, several concepts related to social media data and data analytics are introduced. We start by first discussing two kinds of data - structured and unstructured. Then look at how structured data, the primary focus of this course, is analyzed and what one could gain by doing such analysis. Finally, we briefly cover some of the visualizations for exploring and presenting data.Make sure to go through the material for this unit in the sequence it's provided. First, watch the four short videos, then take the practice test, followed by the two quizzes. Finally, read the documents about installation and configuration of Python and R. This is very important - before proceeding to the next units, make sure you have installed necessary tools, and also learned how to install new packages/libraries for them. The course expects students to have programming experience in Python and R.", "video": ["Video-1: Introduction", "Video-2: Structured vs. Unstructured Data", "Video-3: Analyzing Structured Data", "Video-4: Visualization of Data", "Anaconda Installation", "Python installation, configuration, and usage", "R installation", "R/RStudio Setup Guide (on Windows)", "Installation and Configuration of Development Environment", "Quiz-1", "Quiz-2"]}, {"title": "Collecting and Extracting Social Media Data", "description": "In this unit we will see how to collect data from Twitter and YouTube. The unit will start with an introduction to Python programming. Then we will use a Python script, with a little editing, to extract data from Twitter. A similar exercise will then be done with YouTube. In both the cases, we will also see how to create developer accounts and what information to obtain to use the data collection APIs.\n\nOnce again, make sure to go item-by-item in the order provided. Before beginning this unit, ensure that you have all the right tools (Python, R, Anaconda) ready and configured. The lessons depend on them and also your ability to install required packages.", "video": ["Video-1: Introduction", "Errata: please read this first", "Video-2: Introduction to Python Programming", "Python Packages Installation", "(Optional) Introduction to Python for Econometrics, Statistics and Data Analysis", "Video-3: Using Python to Extract Data from Twitter", "Script: twitter_search.py", "Twitter libraries", "Video-4: Using Python to Extract Data from YouTube", "Script: youtube_search.py", "Python Programming Exercise", "Twitter data download using Python", "YouTube data download using Python"]}, {"title": "Data Analysis, Visualization, and Exploration", "description": "In this unit, we will focus on analyzing and visualizing the data from various social media services. We will first use the data collected before from YouTube to do various statistics analyses such as correlation and regression. We will then introduce R - a platform for doing statistical analysis. Using R, then we will analyze a much larger dataset obtained from Yelp.\n\nMake sure you have covered the material in the previous units before proceeding with this. That means, having all the tools (Anaconda, Python, and R) as well as various packages installed. We will also need new packages this time, so make sure you know how to install them to your Python or R. If needed, please review some basic concepts in statistics - specifically, correlation and regression - before or during working on this unit.", "video": ["Video-1: Introduction", "Video-2: Analyzing Social Media Data Using Python", "Script: twitter_process.py", "Statistical Analysis with Twitter Data", "Video-3: Introduction to R", "Data: iqsize.csv", "R Installation Guide", "Installing R Packages", "Statistical Analysis with R", "Read this first", "Video-4: Social Media Data Analysis with R", "Scripts for converting json to csv", "Data Visualization with ggplot2 (R) - Cheat Sheet", "Data Visualization using R", "Statistical Analysis with Twitter Data", "Data Visualization using R"]}, {"title": "Case Studies", "description": "In the final unit of this course, we will work on two case studies - both using Twitter and focusing on unstructured data (in this case, text). The first case study will involve doing sentiment analysis with Python. The second case study will take us through basic text mining application using R. We wrap up the unit with a conclusion of what we did in this course and where to go next for further learning and exploration.", "video": ["Video-1: Introduction", "Video-2: Sentiment Analysis with Twitter Data", "Script: twitter_sentiments.py", "NLTK", "Sentiment Analysis with Twitter Data", "Video-3: Text Mining of Twitter Data", "Script: text_mining_twitter.r", "An Introduction to Network Analysis with R and statnet", "Video-4: Conclusion", "Sentiment Analysis with Twitter", "Text Mining with Twitter"]}]}, {"title": "Machine Learning for Data Analysis", "course_info": "About this course: Are you interested in predicting future outcomes using your data? This course helps you do just that! Machine learning is the process of developing, testing, and applying predictive algorithms to achieve this goal. Make sure to familiarize yourself with course 3 of this specialization before diving into these machine learning concepts. Building on Course 3, which introduces students to integral supervised machine learning concepts, this course will provide an overview of many additional concepts, techniques, and algorithms in machine learning, from basic classification to decision trees and clustering. By completing this course, you will learn how to apply, test, and interpret machine learning algorithms as alternative methods for addressing your research questions.", "target_audience": null, "created_by": "Wesleyan University", "teach_by": [{"name": "Jen Rose", "department": "Psychology"}, {"name": "Lisa Dierker", "department": "Psychology"}], "package_num": "4", "package_name": "Data Analysis and Interpretation Specialization ", "level": null, "rating": "4.1", "week_data": [{"title": "Decision Trees", "description": "In this session, you will learn about decision trees, a type of data mining algorithm that can select from among a large number of variables those and their interactions that are most important in predicting the target or response variable to be explained. Decision trees create segmentations or subgroups in the data, by applying a series of simple rules or criteria over and over again, which choose variable constellations that best predict the target variable.", "video": ["Some Guidance for Learners New to the Specialization", "SAS or Python - Which to Choose?", "Getting Started with SAS", "Getting Started with Python", "Course Codebooks", "Course Data Sets", "Uploading Your Own Data to SAS", "Data Set for Decision Tree Videos (tree_addhealth.csv)", "What Is Machine Learning?", "Machine Learning and the Bias Variance Trade-Off", "What Is a Decision Tree?", "What is the Process of Growing a Decision Tree?", "SAS Code: Decision Trees", "CART Paper - Prevention Science", "Building a Decision Tree with SAS", "Strengths and Weaknesses of Decision Trees in SAS", "Python Code: Decision Trees", "Building a Decision Tree with Python", "Installing Graphviz and pydotplus", "Getting Set up for Assignments", "Tumblr Instructions", "Assignment Example", "Running a Classification Tree"]}, {"title": "Random Forests", "description": "In this session, you will learn about random forests, a type of data mining algorithm that can select from among a large number of variables those that are most important in determining the target or response variable to be explained. Unlike decision trees, the results of random forests generalize well to new data.", "video": ["What Is A Random Forest and How Is It \"Grown\"?", "SAS code: Random Forests", "The HPForest Procedure in SAS", "Building a Random Forest with SAS", "Python Code: Random Forests", "Building a Random Forest with Python", "Validation and Cross-Validation", "Assignment Example", "Running a Random Forest"]}, {"title": "Lasso Regression", "description": "Lasso regression analysis is a shrinkage and variable selection method for linear regression models. The goal of lasso regression is to obtain the subset of predictors that minimizes prediction error for a quantitative response variable. The lasso does this by imposing a constraint on the model parameters that causes regression coefficients for some variables to shrink toward zero. Variables with a regression coefficient equal to zero after the shrinkage process are excluded from the model. Variables with non-zero regression coefficients variables are most strongly associated with the response variable. Explanatory variables can be either quantitative, categorical or both. In this session, you will apply and interpret a lasso regression analysis. You will also develop experience using k-fold cross validation to select the best fitting model and obtain a more accurate estimate of your model’s test error rate. \nTo test a lasso regression model, you will need to identify a quantitative response variable from your data set if you haven’t already done so, and choose a few additional quantitative and categorical predictor (i.e. explanatory) variables to develop a larger pool of predictors.  Having a larger pool of predictors to test will maximize your experience with lasso regression analysis. Remember that lasso regression is a machine learning method, so your choice of additional predictors does not necessarily need to depend on a research hypothesis or theory. Take some chances, and try some new variables. The lasso regression analysis will help you determine which of your predictors are most important. Note also that if you are working with a relatively small data set, you do not need to split your data into training and test data sets. The cross-validation method you apply is designed to eliminate the need to split your data when you have a limited number of observations. ", "video": ["What is Lasso Regression?", "SAS Code: Lasso Regression", "Testing a Lasso Regression with SAS", "Data Management for Lasso Regression in Python", "Testing a Lasso Regression Model in Python", "Python Code: Lasso Regression", "Lasso Regression Limitations", "Assignment Example", "Running a Lasso Regression Analysis"]}, {"title": "K-Means Cluster Analysis", "description": "Cluster analysis is an unsupervised machine learning method that partitions the observations in a data set into a smaller set of clusters where each observation belongs to only one cluster. The goal of cluster analysis is to group, or cluster, observations into subsets based on their similarity of responses on multiple variables. Clustering variables should be primarily quantitative variables, but binary variables may also be included. In this session, we will show you how to use k-means cluster analysis to identify clusters of observations in your data set. You will gain experience in interpreting cluster analysis results by using graphing methods to help you determine the number of clusters to interpret, and examining clustering variable means to evaluate the cluster profiles. Finally, you will get the opportunity to validate your cluster solution by examining differences between clusters on a variable not included in your cluster analysis.  \nYou can use the same variables that you have used in past weeks as clustering variables. If most or all of your previous explanatory variables are categorical, you should identify some additional quantitative clustering variables from your data set. Ideally, most of your clustering variables will be quantitative, although you may also include some binary variables. In addition, you will need to identify a quantitative or binary response variable from your data set that you will not include in your cluster analysis. You will use this variable to validate your clusters by evaluating whether your clusters differ significantly on this response variable using statistical methods, such as analysis of variance or chi-square analysis, which you learned about in Course 2 of the specialization (Data Analysis Tools). Note also that if you are working with a relatively small data set, you do not need to split your data into training and test data sets. \n", "video": ["What Is a k-Means Cluster Analysis?", "Running a k-Means Cluster Analysis in SAS, pt. 1", "Running a k-Means Cluster Analysis in SAS, pt. 2", "SAS Code: k-Means Cluster Analysis", "Python Code: k-Means Cluster Analysis", "Running a k-Means Cluster Analysis in Python, pt. 1", "Running a k-Means Cluster Analysis in Python, pt. 2", "k-Means Cluster Analysis Limitations", "Assignment Example", "Running a k-means Cluster Analysis"]}]}, {"title": "Probabilistic Graphical Models 3: Learning", "course_info": "About this course: Probabilistic graphical models (PGMs) are a rich framework for encoding probability distributions over complex domains: joint (multivariate) distributions over large numbers of random variables that interact with each other. These representations sit at the intersection of statistics and computer science, relying on concepts from probability theory, graph algorithms, machine learning, and more. They are the basis for the state-of-the-art methods in a wide variety of applications, such as medical diagnosis, image understanding, speech recognition, natural language processing, and many, many more. They are also a foundational tool in formulating many machine learning problems. \n\nThis course is the third in a sequence of three. Following the first course, which focused on representation, and the second, which focused on inference, this course addresses the question of learning: how a PGM can be learned from a data set of examples. The course discusses the key problems of parameter estimation in both directed and undirected models, as well as the structure learning task for directed models. The (highly recommended) honors track contains two hands-on programming assignments, in which key routines of two commonly used learning algorithms are implemented and applied to a real-world problem.", "target_audience": null, "created_by": "Stanford University", "teach_by": [{"name": "Daphne Koller", "department": "School of Engineering"}], "package_num": "3", "package_name": "Probabilistic Graphical Models  Specialization ", "level": "Advanced", "rating": "4.7", "week_data": [{"title": "Learning: Overview", "description": "This module presents some of the learning tasks for probabilistic graphical models that we will tackle in this course.", "video": ["Learning: Overview"]}, {"title": "Review of Machine Learning Concepts from Prof. Andrew Ng's Machine Learning Class (Optional)", "description": "This module contains some basic concepts from the general framework of machine learning, taken from Professor Andrew Ng's Stanford class offered on Coursera. Many of these concepts are highly relevant to the problems we'll tackle in this course.", "video": ["Regularization: The Problem of Overfitting ", "Regularization: Cost Function ", "Evaluating a Hypothesis ", "Model Selection and Train Validation Test Sets ", "Diagnosing Bias vs Variance ", "Regularization and Bias Variance"]}, {"title": "Parameter Estimation in Bayesian Networks", "description": "This module discusses the simples and most basic of the learning problems in probabilistic graphical models: that of parameter estimation in a Bayesian network. We discuss maximum likelihood estimation, and the issues with it. We then discuss Bayesian estimation and how it can ameliorate these problems.", "video": ["Maximum Likelihood Estimation", "Maximum Likelihood Estimation for Bayesian Networks", "Bayesian Estimation", "Bayesian Prediction", "Bayesian Estimation for Bayesian Networks", "Learning in Parametric Models", "Bayesian Priors for BNs"]}, {"title": "Learning Undirected Models", "description": "In this module, we discuss the parameter estimation problem for Markov networks - undirected graphical models. This task is considerably more complex, both conceptually and computationally, than parameter estimation for Bayesian networks, due to the issues presented by the global partition function.", "video": ["Maximum Likelihood for Log-Linear Models", "Maximum Likelihood for Conditional Random Fields", "MAP Estimation for MRFs and CRFs", "Parameter Estimation in MNs", "CRF Learning for OCR"]}, {"title": "Learning BN Structure", "description": "This module discusses the problem of learning the structure of Bayesian networks. We first discuss how this problem can be formulated as an optimization problem over a space of graph structures, and what are good ways to score different structures so as to trade off fit to data and model complexity. We then talk about how the optimization problem can be solved: exactly in a few cases, approximately in most others.", "video": ["Structure Learning Overview", "Likelihood Scores", "BIC and Asymptotic Consistency", "Bayesian Scores", "Learning Tree Structured Networks", "Learning General Graphs: Heuristic Search", "Learning General Graphs: Search and Decomposability", "Structure Scores", "Tree Learning and Hill Climbing", "Learning Tree-structured Networks"]}, {"title": "Learning BNs with Incomplete Data", "description": "In this module, we discuss the problem of learning models in cases where some of the variables in some of the data cases are not fully observed. We discuss why this situation is considerably more complex than the fully observable case. We then present the Expectation Maximization (EM) algorithm, which is used in a wide variety of problems.", "video": ["Learning With Incomplete Data - Overview", "Expectation Maximization - Intro", "Analysis of EM Algorithm", "EM in Practice", "Latent Variables", "Learning with Incomplete Data", "Expectation Maximization", "Learning with Incomplete Data"]}, {"title": "Learning Summary and Final", "description": "This module summarizes some of the issues that arise when learning probabilistic graphical models from data. It also contains the course final.", "video": ["Summary: Learning", "Learning: Final Exam"]}, {"title": "PGM Wrapup", "description": "This module contains an overview of PGM methods as a whole, discussing some of the real-world tradeoffs when using this framework in practice. It refers to topics from all three of the PGM courses.", "video": ["PGM Course Summary"]}]}, {"title": "Matrix Factorization and Advanced Techniques", "course_info": "About this course: In this course you will learn a variety of matrix factorization and hybrid machine learning techniques for recommender systems.  Starting with basic matrix factorization, you will understand both the intuition and the practical details of building recommender systems based on reducing the dimensionality of the user-product preference space.  Then you will learn about techniques that combine the strengths of different algorithms into powerful hybrid recommenders.", "target_audience": null, "created_by": "University of Minnesota", "teach_by": [{"name": "Michael D. Ekstrand", "department": "Dept. of Computer Science, Boise State University"}, {"name": "Joseph A Konstan", "department": "Computer Science and Engineering"}], "package_num": "4", "package_name": "Recommender Systems Specialization ", "level": null, "rating": "4.2", "week_data": [{"title": "Preface", "description": "", "video": ["Matrix Factorization and Advanced Techniques"]}, {"title": "Matrix Factorization (Part 1)", "description": "This is a two-part, two-week module on matrix factorization recommender techniques.  It includes an assignment and quiz (both due in the second week), and an honors assignment (also due in the second week).  Please pace yourself carefully -- it will be difficult to finish in two weeks unless you start the assignments during the first week.  ", "video": ["Introduction to Matrix Factorization and Dimensionality Reduction", "Singular Value Decomposition", "Gradient Descent Techniques", "On Folding-In with Gradient Descent", "Deriving FunkSVD", "Probabilistic Matrix Factorization"]}, {"title": "Matrix Factorization (Part 2)", "description": "", "video": ["Assignment Introduction", "Assignment Instructions", "Intro - Programming Matrix Factorization", "Programming Matrix Factorization", "Matrix Factorization Assignment Part l", "Matrix Factorization Assignment Part ll", "Matrix Factorization Assignment Part lll", "Matrix Factorization Quiz", "Programming SVD", "SVD Programming Eval Quiz"]}, {"title": "Hybrid Recommenders", "description": "This is a three-part, two-week module on hybrid and machine learning recommendaton algorithms and advanced recommender techniques.  It includes a quiz (due in the second week), and an honors assignment (also due in the second week).  Please pace yourself carefully -- it will be difficult to finish the honors track in two weeks unless you start the assignments during the first week.  ", "video": ["Hybrid Recommenders", "Hybrids with Robin Burke", "Hybridization through Matrix Factorization", "Matrix Factorization Hybrids with George Karypis", "Interview with Arindam Banerjee", "Interview with Yehuda Koren"]}, {"title": "Advanced Machine Learning", "description": "", "video": ["Learning Recommenders", "Learning to Rank:  Interview with Xavier Amatriain", "Personalized Ranking (with Daniel Kluver)"]}, {"title": "Advanced Topics", "description": "", "video": ["Context-Aware Recommendation I :  Interview with Francesco Ricci", "Context-Aware Recommendation II:  Interview with Bamshad Mobasher (Part 1)", "Context-Aware Recommendation II:  Interview with Bamshad Mobasher (Part 2)", "Industry Practical Issues:  Inteview with Anmol Bhasin", "Recommending Music - Interview with Paul Lamere", "Specialization Wrap Up", "Programming Hybrids and Machine Learning Description", "Programming Hybrids & Learning to Rank", "Hybrid and Advanced Techniques Quiz", "Programming Hybrids and Learning-to-Rank", "Honors Hybrid Assignment Evaluation Quiz"]}]}, {"title": "Digital Manufacturing & Design", "course_info": "About this course: This course will expose you to the transformation taking place, throughout the world, in the way that products are being designed and manufactured. The transformation is happening through digital manufacturing and design (DM&D) – a shift from paper-based processes to digital processes in the manufacturing industry. By the end of this course, you’ll understand what DMD is and how it is impacting careers, practices and processes in companies both large and small.  \n\nYou will gain an understanding of and appreciation for the role that technology is playing in this transition. The technology we use every day – whether it is communicating with friends and family, purchasing products or streaming entertainment – can benefit design and manufacturing, making companies and workers more competitive, agile and productive. Discover how this new approach to making products makes companies more responsive, and employees more involved and engaged, as new career paths in advanced manufacturing evolve.\n\nMain concepts of this course will be delivered through lectures, readings, discussions and various videos. \n\nThis is the first course in the Digital Manufacturing & Design Technology specialization that explores the many facets of manufacturing’s “Fourth Revolution,” and features a culminating project involving creation of a roadmap to achieve a self-established DMD-related professional goal.\n\nTo learn more about the Digital Manufacturing and Design Technology specialization, please watch the overview video by copying and pasting the following link into your web browser: https://youtu.be/r-VHiwsg_t0", "target_audience": "Who is this class for: This course is for anyone interested in how digital advances are changing the landscape and capabilities of manufacturing, from high school graduates exploring careers to operations managers and business owners hungry for an understanding of the newest manufacturing technologies.", "created_by": "University at Buffalo, The State University of New York", "teach_by": [{"name": "Ken English", "department": "Sustainable Manufacturing and Advanced Robotic Technologies Community of Excellence"}], "package_num": "1", "package_name": "Digital Manufacturing & Design Technology  Specialization ", "level": "Beginner", "rating": "4.5", "week_data": [{"title": "The Big Picture", "description": "The purpose of this module is to introduce learners to the factors and trends motivating the transition from the current state of manufacturing to a DMD model. Details of individual lessons in this module are provided below.", "video": ["Introduction to Digital Manufacturing & Design Technology", "Introduction to Digital Manufacturing and Design", "Acknowledgements", "Digital Manufacturing and Design", "Resources: Digital Manufacturing and Design", "Self-check", "Impact on Manufacturing Careers", "Resources: Career Opportunities", "Self-check", "Advantages of Digital Manufacturing and Design", "Resources: Transition to Digital Manufacturing and Design", "Self-check", "Information Sharing in the Digital Thread", "Resources: Data Procurement Standards", "Self-check", "Multiple Organizations in the Manufacturing Process", "Resources: Manufacturing Supply Chains", "Self-check", "Digital Manufacturing & Design-- Week 1 Reflection", "Digital Manufacturing & Design. Week 1 Quiz"]}, {"title": "Components of the Paradigm", "description": "The purpose of this module is to introduce learners to the multiple components that integrate to create a future manufacturing enterprise (i.e., a digital link between design and production, leveraging data analytics to identify opportunities for increased quality and efficiency, interconnected and transparent machines, production facilities, and supply chains).  Details of individual lessons in this module are provided below.", "video": ["Components", "Resources: Introduction to the Digital Thread", "Self-Check", "Gaining Insight from Data", "Resources: Advanced Analysis", "Self- Check", "A Closed Loop Approach", "Resources: Intelligent Machining", "Self-Check", "Integrated Information Systems in the Product Lifecycle", "Resources: Advanced Manufacturing Enterprise", "An Open Source Strategy", "Resources: Digital Manufacturing Commons", "Self-check", "Protecting Your Organization", "Resources: Digital Manufacturing Security", "Self-Check", "Your 4.0 Roadmap to Success: Overview", "Your 4.0 Roadmap to Success in Digital Manufacturing and Design Technology ", "Your 4.0 Roadmap to Success-- Resources", "Your 4.0 Roadmap to Success: Step 1", "Digital Manufacturing & Design-- Key Takeaways", "Digital Manufacturing & Design-- Course References", "Digital Manufacturing & Design. Week 2 Quiz"]}]}, {"title": "Nearest Neighbor Collaborative Filtering", "course_info": "About this course: In this course, you will learn the fundamental techniques for making personalized recommendations through nearest-neighbor techniques.  First you will learn user-user collaborative filtering, an algorithm that identifies other people with similar tastes to a target user and combines their ratings to make recommendations for that user.  You will explore and implement variations of the user-user algorithm, and will explore the benefits and drawbacks of the general approach.  Then you will learn the widely-practiced item-item collaborative filtering algorithm, which identifies global product associations from user ratings, but uses these product associations to provide personalized recommendations based on a user's own product ratings.", "target_audience": null, "created_by": "University of Minnesota", "teach_by": [{"name": "Joseph A Konstan", "department": "Computer Science and Engineering"}, {"name": "Michael D. Ekstrand", "department": "Dept. of Computer Science, Boise State University"}], "package_num": "2", "package_name": "Recommender Systems Specialization ", "level": null, "rating": "4.3", "week_data": [{"title": "Preface", "description": "Note that this course is structured into two-week chunks.  The first chunk focuses on User-User Collaborative Filtering; the second chunk on Item-Item Collaborative Filtering.  Each chunk has most of the lectures in the first week, and assignments/quizzes and advanced topics in the second week.  We encourage learners to treat each two-week chunk as one unit, starting the assignments as soon as they feel they have learned enough to get going.", "video": ["Course Introduction", "Course Structure Outline"]}, {"title": "User-User Collaborative Filtering Recommenders Part 1", "description": "", "video": ["User-User Collaborative Filtering", "Configuring User-User Collaborative Filtering", "Influence Limiting and Attack Resistance; Interview with Paul Resnick", "Trust-Based Recommendation; Interview with Jen Golbeck", "Impact of Bad Ratings; Interview with Dan Cosley"]}, {"title": "User-User Collaborative Filtering Recommenders Part 2", "description": "", "video": ["Assignment Introduction", "Assignment Instructions:  User-User CF", "Introducing User-User CF Programming Assignment", "Programming Assignment - Programming User-User Collaborative Filtering", "User-User CF Answer Sheet", "User-User Collaborative Filtering Quiz", "User-User CF Programming Assignment"]}, {"title": "Item-Item Collaborative Filtering Recommenders Part 1", "description": "", "video": ["Introduction to Item-Item Collaborative Filtering", "Item-Item Algorithm", "Item-Item on Unary Data", "Item-Item Hybrids and Extensions", "Strengths and Weaknesses of Item-Item Collaborative Filtering", "Interview with Brad Miller"]}, {"title": "Item-Item Collaborative Filtering Recommenders Part 2", "description": "", "video": ["Item-Based CF Assignment Intro Video", "Item-Based CF Assignment Instructions", "Introducing Item-Item CF Programming Assignment", "Programming Assignment - Programming Item-Item Collaborative Filtering", "Item Based Assignment Part l", "Item Based Assignment Part II", "Item Based Assignment Part III", "Item Based Assignment Part IV", "Item-Item CF Programming Assignment"]}, {"title": "Advanced Collaborative Filtering Topics", "description": "", "video": ["The Cold Start Problem", "Recommending for Groups:  Interview with Anthony Jameson", "Threat Models", "Explanations", "Explanations, Part II:  Interview with Nava Tintarev", "Item-Based and Advanced Collaborative Filtering Topics Quiz"]}]}, {"title": "Recommender Systems:  Evaluation and Metrics", "course_info": "About this course: In this course you will learn how to evaluate recommender systems.  You will gain familiarity with several families of metrics, including ones to measure prediction accuracy, rank accuracy, decision-support, and other factors such as diversity, product coverage, and serendipity.  You will learn how different metrics relate to different user goals and business goals.  You will also learn how to rigorously conduct offline evaluations (i.e., how to prepare and sample data, and how to aggregate results).  And you will learn about online (experimental) evaluation.  At the completion of this course you will have the tools you need to compare different recommender system alternatives for a wide variety of uses.", "target_audience": null, "created_by": "University of Minnesota", "teach_by": [{"name": "Michael D. Ekstrand", "department": "Dept. of Computer Science, Boise State University"}, {"name": "Joseph A Konstan", "department": "Computer Science and Engineering"}], "package_num": "3", "package_name": "Recommender Systems Specialization ", "level": null, "rating": "4.2", "week_data": [{"title": "Preface", "description": "", "video": ["Introduction to Evaluation and Metrics", "The Goals of Evaluation"]}, {"title": "Basic Prediction and Recommendation Metrics", "description": "", "video": ["Hidden Data Evaluation", "Prediction Accuracy Metrics", "Decision Support Metrics", "Rank-Aware Top-N Metrics", "Assignment Intro Video", "Metric Computation Assignment Instructions", "Basic Prediction and Recommendation Metrics Assignment"]}, {"title": "Advanced Metrics and Offline Evaluation", "description": "", "video": ["Beyond Basic Evaluation", "Additional Item and List-Based Metrics", "Experimental Protocols", "Unary Data Evaluation", "Temporal Evaluation of Recommenders (Interview with Neal Lathia)", "Programming Assignment Introduction", "Evaluating Recommenders", "Offline Evaluation and Metrics Quiz", "Programming Assignment Quiz"]}, {"title": "Online Evaluation", "description": "", "video": ["Introduction to Online Evaluation and User Studies", "Usage Logs and Analysis", "A/B Studies (Field Experiments)", "User-Centered Evaluation (Interview with Bart Knijnenburg)", "Online Evaluation Quiz"]}, {"title": "Evaluation Design", "description": "", "video": ["Matching Evaluation to the Problem/Challenge", "Case Examples", "Assignment Intro Video", "Intro to Assignment:  Evaluation Design Cases", "Quiz Debrief", "Assignment:  Evaluation Design Cases"]}]}, {"title": "Data Science Capstone", "course_info": "About this course: The capstone project class will allow students to create a usable/public data product that can be used to show your skills to potential employers. Projects will be drawn from real-world problems and will be conducted with industry, government, and academic partners.", "target_audience": null, "created_by": "Johns Hopkins University", "teach_by": [{"name": "Jeff Leek, PhD", "department": "Bloomberg School of Public Health "}, {"name": "Roger D. Peng, PhD", "department": "Bloomberg School of Public Health"}, {"name": "Brian Caffo, PhD", "department": "Bloomberg School of Public Health"}], "package_num": "10", "package_name": "Data Science Specialization ", "level": null, "rating": "4.4", "week_data": [{"title": "Overview, Understanding the Problem, and Getting the Data", "description": "This week, we introduce the project so you can get a clear grip on the problem at hand and begin working with the dataset.", "video": ["Welcome to the Capstone Project", "Project Overview", "Welcome from SwiftKey", "You Are a Data Scientist Now", "Syllabus", "Introduction to Task 0: Understanding the Problem", "Task 0 - Understanding the problem", "About the Copora", "Introduction to Task 1: Getting and Cleaning the Data", "Task 1 - Getting and cleaning the data", "Regular Expressions: Part 1 (Optional)", "Regular Expressions: Part 2 (Optional)", "Quiz 1: Getting Started"]}, {"title": "Exploratory Data Analysis and Modeling", "description": "This week, we move on to the next tasks, exploratory data analysis and modeling. You'll also submit your milestone report and review submissions from your classmates.", "video": ["Introduction to Task 2: Exploratory Data Analysis", "Task 2 - Exploratory Data Analysis", "Introduction to Task 3: Modeling", "Task 3 - Modeling", "Milestone Report"]}, {"title": "Prediction Model", "description": "This week, you'll build and evaluate your prediction model. The goal is to make your model efficient and accurate. ", "video": ["Introduction to Task 4: Prediction Model", "Task 4 - Prediction Model", "Quiz 2: Natural language processing I"]}, {"title": "Creative Exploration", "description": "This week's goal is to improve the predictive accuracy while reducing computational runtime and model complexity.", "video": ["Introduction to Task 5: Creative Exploration", "Task 5 - Creative Exploration", "Quiz 3: Natural language processing II"]}, {"title": "Data Product ", "description": "This week, you'll work on developing the first component of your final project, your data product. ", "video": ["Introduction to Task 6: Data Product", "Task 6 - Data Product"]}, {"title": "Slide Deck", "description": "This week, you'll work on developing the second component of your final project, a slide deck to accompany your data product. ", "video": ["Introduction to Task 7: Slide Deck", "Task 7 - Slide Deck"]}, {"title": "Final Project Submission and Evaluation ", "description": "This week, you'll submit your final project and review the work of your classmates.", "video": ["Congratulations!", "Final Project Submission"]}]}, {"title": "Intelligent Machining", "course_info": "About this course: Manufacturers are increasingly utilizing machine tools that are self-aware – they perceive their own states and the state of the surrounding environment – and are able to make decisions related to machine activity processes. This is called intelligent machining, and through this course students will receive a primer on its background, tools and related terminology. \n\nLearn how the integration of smart sensors and controls are helping to improve productivity. You’ll be exposed to various sensors and sensing techniques, process control strategies, and open architecture systems that can be leveraged to enable intelligent machining. This course will prepare you to contribute to the implementation of intelligent machining projects. \n\nMain concepts of this course will be delivered through lectures, readings, discussions and various videos. \n\nThis is the fifth course in the Digital Manufacturing & Design Technology specialization that explores the many facets of manufacturing’s “Fourth Revolution,” and features a culminating project involving creation of a roadmap to achieve a self-established DMD-related professional goal.\n\nTo learn more about the Digital Manufacturing and Design Technology specialization, please watch the overview video by copying and pasting the following link into your web browser: https://youtu.be/r-VHiwsg_t0", "target_audience": "Who is this class for: This course is for anyone interested in how digital advances are changing the landscape and capabilities of manufacturing, from high school graduates exploring careers to operations managers and business owners hungry for an understanding of the newest manufacturing technologies.", "created_by": "University at Buffalo, The State University of New York", "teach_by": [{"name": "Rahul Rai", "department": "Mechanical and Aerospace Engineering"}], "package_num": "5", "package_name": "Digital Manufacturing & Design Technology  Specialization ", "level": "Beginner", "rating": "4.5", "week_data": [{"title": "Introduction to Intelligent Machining ", "description": "The purpose of this module is to introduce the concepts related to intelligent machining paradigm. The key focus will be discussing two key components of intelligent machining, i.e., sensing and control. ", "video": ["Introduction to Intelligent Machining", "Machining Basics", "Resources: Why Intelligent Machining", "Self-check", "Acknowledgements", "The Evolution of Intelligent Machining", "Resources: What Constitutes an Intelligent Machine?", "Self-check", "Components of Intelligent Machining", "Resources: Components of Intelligent Machining", "Self-check", "Introduction to Intelligent Machining"]}, {"title": "Sensors and Sensing Techniques", "description": "The purpose of this module is to introduce spectrum of sensors used to implement intelligent machining. The module will also discuss the basics of signal processing and analysis techniques that has brought intelligent machining paradigm closer to industrial realization. Following issues pertaining to sensors and sensing techniques will be elaborated up: (1) Which sensors are to be used in each application? (2) How to acquire and process sensor signals? \n", "video": ["Sensors", "Resources: Types of Sensors", "Self-check", "Signal Processing", "Resources: Signal Processing", "Self-check", "Transforming Data into Information", "Resources: Machine Learning: Setting the Context", "Self-check", "Practical Uses of Machine Learning", "Self-check", "Let's talk robotics! ", "Sensors and Sensing Techniques"]}, {"title": "Process Control Strategies", "description": "The purpose of this module is to introduce the concept of Programmable Logic Controllers (PLCs) that co-ordinate the real-time control functions.", "video": ["Programmable Logic Controllers (PLC)", "Resources: Introduction to Machining Process Control", "Self-check", "Closed Loop Process Control Systems", "Resources: Adaptive Control with Optimization", "Self-check", "Introduction to Adaptive Control", "Resources: Machining Force Control", "Self-check", "Commercially Available Software", "Resources: Manufacturing Process Control: Commonly Used Software", "Self-check", "Process Control Strategies"]}, {"title": "Future Directions in Advanced Machining", "description": " The purpose of this module is to introduce the background related to open architecture software systems to implement intelligent machining.", "video": ["Intelligent Machining and the Future", "Resources: Future Directions in Advanced Machining", "Self-check", "Tech Talk on Metrology", "Your 4.0 Roadmap to Success", "Your 4.0 Roadmap to Success -- Resources", "Your Roadmap Project: Step 5", "Your 4.0 Roadmap to Success in Digital Manufacturing and Design Technology", "Intelligent Machining- Key Takeaways", "Intelligent Machining- Course References", "Intelligent Machining- Future Directions "]}]}, {"title": "MBSE: Model-Based Systems Engineering ", "course_info": "About this course: This Model-Based Systems Engineering (MBSE) course and the Digital Thread courses featured earlier in this specialization bring together the concepts from across digital manufacturing and design, forming a vision in which the geometry of a product is just one way of describing it. MBSE is where the model resulting from the evolution of system requirements, design, analysis, verification and validation activities is the focus of design and manufacturing. Students will gain an understanding of systems engineering, the model-based approach to design and manufacturing, the Digital Twin, and a roadmap toward a model-based enterprise.\n\nStudents will be able to explain the value and expectations of systems engineering and model-based systems engineering, and the underlying motivations and opportunities represented by a model-based enterprise. They will develop the knowledge necessary to perform a baseline assessment of an organization’s potential to leverage MBSE. \n\nMain concepts of this course will be delivered through lectures, readings, discussions and various videos. \n\nThis is the ninth course in the Digital Manufacturing & Design Technology specialization that explores the many facets of manufacturing’s “Fourth Revolution,” and features a culminating project involving creation of a roadmap to achieve a self-established DMD-related professional goal.\n\nTo learn more about the Digital Manufacturing and Design Technology specialization, please watch the overview video by copying and pasting the following link into your web browser: https://youtu.be/r-VHiwsg_t0", "target_audience": "Who is this class for: This course is for anyone interested in how digital advances are changing the landscape and capabilities of manufacturing, from high school graduates exploring careers to operations managers and business owners hungry for an understanding of the newest manufacturing technologies.", "created_by": "University at Buffalo, The State University of New York", "teach_by": [{"name": "Ken English", "department": "Sustainable Manufacturing and Advanced Robotic Technologies Community of Excellence"}], "package_num": "9", "package_name": "Digital Manufacturing & Design Technology  Specialization ", "level": "Beginner", "rating": "4.7", "week_data": [{"title": "Systems Engineering", "description": "The purpose of this module is to establish a basic understanding of Systems Engineering and the role it plays in design and manufacturing. At the end of the module, learners will be able to explain a Systems Engineering process and discuss the advantages and disadvantages of the approach.", "video": ["Introduction: MBSE: Model-Based Systems Engineering", "Introduction to Systems Engineering", "Introduction to Systems Engineering (Part 2)", "Additional (optional) Resources:", "Self-check", "Acknowledgements", "Systems Engineering and the LifeCycle", "Reading: Additional (optional) Resources:", "Self-check", "Systems Engineering Process Overview", "Reading: Additional (optional) Resources:", "Self-check", "Business Impacts of Systems Engineering", "Reading: Additional (optional) Resources:", "Self-check", "MBSE: Model-Based Systems Engineering --Week 1 Quiz"]}, {"title": "Model-Based Systems Engineering ", "description": "The purpose of this module is to explain Model-Based Systems Engineering (MBSE) and its applications. Upon completion, learners will be able to assess a process for MBSE opportunities and develop an argument for implementation. The learners will also be able to develop a strategy on how to implement applications of MBSE.", "video": ["Model-Based Definition (MBD)", "Additional (optional) Resources", "Self-check", "Model-Based Systems Engineering Methodologies", "Additional (optional) Resources:", "Self-check", "Systems Modeling Language (SysML)", "Reading: Additional (optional) Resources:", "Self-check", "Model-Based Systems Engineering (MBSE) Application Strategies", "Additional (optional) Resources:", "Self-check", "Is there an elephant in the room?", "MBSE: Model-Based Systems Engineering --Week 2 Quiz"]}, {"title": "Applications of Model-Based Systems Engineering", "description": "Learners will develop an appreciation of the Model-Based Enterprise, including the benefits and barriers to  successful implementation. Learners will be able to identify potential opportunities for the adoption of a Model-Based Enterprise.", "video": ["The Model-Based Enterprise - Part 1", "The Model-Based Enterprise - Part 2", "Additional (optional) Resources:", "Self-check", "The Model-Based Enterprise and the Digital Thread", "Additional (optional) Resources:", "Self-check", "Business Aspects of the Model-Based Enterprise", "Additional (optional) Resources:", "Self-check", "Realizing a Model-Based Enterprise", "Additional (optional) Resources:", "Self-check", "MBSE: Model-Based Systems Engineering --Week 3 Quiz"]}, {"title": "Model-Based Enterprise", "description": "The purpose of this module is to develop an understanding of the MBE Self Assessment tools. At the end of the module, learners will be able to go through a tool to analyze MBE maturity.", "video": ["Model-Based Enterprise Self Assessment", "Additional (optional) Resources:", "Self-check", "Design Activities", "Additional (optional) Resources:", "Self-check", "Configuration Management and Document Management", "Additional (optional) Resources:", "Self-check", "Manufacturing Planning Activities", "Additional (optional) Resources:", "Self-check", "Quality Requirements and Quality Planning Activities", "Additional (optional) Resources:", "Self-check", "Enterprise Activities", "Additional (optional) Resources:", "Self-check", "Your 4.0 Roadmap to Success", "Your 4.0 Roadmap to Success -- Resources", "Your Roadmap Project: Step 9", "Your 4.0 Roadmap to Success in Digital Manufacturing and Design Technology", "MBSE: Model-Based Systems Engineering-- Key Takeaways", "Course References", "MBSE: Model-Based Systems Engineering --Week 4 Quiz"]}]}, {"title": "Advanced Manufacturing Process Analysis", "course_info": "About this course: Variability is a fact of life in manufacturing environments, impacting product quality and yield. Through this course, students will learn why performing advanced analysis of manufacturing processes is integral for diagnosing and correcting operational flaws in order to improve yields and reduce costs.   \n\nGain insights into the best ways to collect, prepare and analyze data, as well as computational platforms that can be leveraged to collect and process data over sustained periods of time. Become better prepared to participate as a member of an advanced analysis team and share valuable inputs on effective implementation.    \n\nMain concepts of this course will be delivered through lectures, readings, discussions and various videos. \n\nThis is the fourth course in the Digital Manufacturing & Design Technology specialization that explores the many facets of manufacturing’s “Fourth Revolution,” and features a culminating project involving creation of a roadmap to achieve a self-established DMD-related professional goal.\n\nTo learn more about the Digital Manufacturing and Design Technology specialization, please watch the overview video by copying and pasting the following link into your web browser: https://youtu.be/r-VHiwsg_t0", "target_audience": "Who is this class for: This course is for anyone interested in how digital advances are changing the landscape and capabilities of manufacturing, from high school graduates exploring careers to operations managers and business owners hungry for an understanding of the newest manufacturing technologies.", "created_by": "University at Buffalo, The State University of New York", "teach_by": [{"name": "Rahul Rai", "department": "Mechanical and Aerospace Engineering"}], "package_num": "4", "package_name": "Digital Manufacturing & Design Technology  Specialization ", "level": "Beginner", "rating": "4.3", "week_data": [{"title": "Introduction to Advanced Manufacturing Process Analysis", "description": "The purpose of this module is to introduce the concept of advanced analysis in improvement of manufacturing processes. Also, this module will help you to understand the difference between discrete manufacturing and continuous manufacturing.", "video": ["Introduction to Advanced Manufacturing Process Analysis", "Acknowledgements", "The Data Analysis Process", "Resources: Data Analysis: Value and Process", "Self-check", "Data Collection in Different Manufacturing Settings", "Resources: Manufacturing Settings and Data Collection", "DMD Dialogue 1: Discrete Part Manufacturing", "DMD Dialogue 2: Continuous Manufacturing", "Self-check", "Advanced Manufacturing Process Analysis- Week 1 Quiz"]}, {"title": "Data Collection", "description": "Storing big data is quite different from handling traditional data. This difference is explained in this module. The purpose of this module is to introduce various steps involved in data analysis. Data Collection, Data Storage, Data Organization and Data Pre-processing concepts are explained. ", "video": ["Big Data", "Resources: Traditional Data Sets versus Big Data", "Self-check", "Data Collection Considerations", "Resources: Data Collection", "Self-check", "Data Storage", "Resources: Data Storage and Organization", "Self-check", "Data Preprocessing", "Resources: Data Pre-processing", "Self-check", "Advanced Manufacturing Process Analysis- Week 2 Reflection", "Advanced Manufacturing Process Analysis- Week 2 Quiz"]}, {"title": "Data Analysis: Computational Techniques and Platforms", "description": "The purpose of this module is to introduce various techniques used in advanced analysis, like Determination of Significant Variables/Factors, Data Visualization, and Anomaly Detection. Also, this module will introduce various computational platforms (HPC, Cloud computing techniques) that exist for carrying out advanced analysis.", "video": ["Sensitivity Analysis", "Resources: Determination of Significant Variables/Factors", "Self-check", "Anomaly Detection", "Resources: Anomaly Detection", "Self-check", "The Computational Platform", "Resources: Computing Platform, Components, Categories, and Capabilities", "Self-check", "HPC and Cloud Computing", "Resources: High Performance and Cloud Computing", "Self-check", "Your 4.0 Roadmap to Success", "Your 4.0 Roadmap to Success -- Resources", "Your Roadmap Project: Step 4", "Your 4.0 Roadmap to Success in Digital Manufacturing and Design Technology", "Advanced Manufacturing Analysis -- Key Takeaways", "Advanced Manufacturing Process Analysis- Week 3 Quiz"]}]}, {"title": "Digital Thread: Components", "course_info": "About this course: This course will help you recognize how the \"digital thread\" is the backbone of the digital manufacturing and design (DM&D) transformation, turning manufacturing processes from paper-based to digital-based. You will have a working understanding of the digital thread – the stream that starts at product concept and continues to accumulate information and data throughout the product’s life cycle – and identify opportunities to leverage it. \n\nGain an understanding of how \"the right information, in the right place, at the right time\" should flow. This is one of the keys to unlocking the potential of a digital design process. Acknowledging this will enable you to be more involved in a product’s development cycle, and to help a company become more flexible. \n\nMain concepts of this course will be delivered through lectures, readings, discussions and various videos. \n\nThis is the second course in the Digital Manufacturing & Design Technology specialization that explores the many facets of manufacturing’s “Fourth Revolution,” and features a culminating project involving creation of a roadmap to achieve a self-established DMD-related professional goal.\n\nTo learn more about the Digital Manufacturing and Design Technology specialization, please watch the overview video by copying and pasting the following link into your web browser: https://youtu.be/r-VHiwsg_t0", "target_audience": "Who is this class for: This course is for anyone interested in how digital advances are changing the landscape and capabilities of manufacturing, from high school graduates exploring careers to operations managers and business owners hungry for an understanding of the newest manufacturing technologies.", "created_by": "University at Buffalo, The State University of New York", "teach_by": [{"name": "Ken English", "department": "Sustainable Manufacturing and Advanced Robotic Technologies Community of Excellence"}], "package_num": "2", "package_name": "Digital Manufacturing & Design Technology  Specialization ", "level": "Beginner", "rating": "4.5", "week_data": [{"title": "Digital Thread Defined", "description": "The purpose of this module is to introduce learners to the context and definition of the digital thread. Details of individual lessons in this module are provided below.", "video": ["Introduction to Digital Thread: Components", "Acknowledgements", "The Vision of Digital Manufacturing and Design", "Resources: Staying Relevant; Being a Player in DMD", "Self-check", "The Diffusion of Innovation", "Resources: Diffusion of Innovation", "Self-check", "Motivating Factors", "Resources: Why Digital Thread?", "Self-check", "Digital Thread", "Resources: Digital Thread Defined", "Self-check", "Business Systems", "Resources: Business Systems and the Digital Thread", "Self-check", "Why Digital Thread?", "Digital Thread: Components. Week 1 Quiz"]}, {"title": "Data Storage in the Digital Thread", "description": "The purpose of this module is to explore the different strategies and components affecting data storage in the enterprise.  Building on effective information technology practices, the module will develop learners' knowledge of well developed data storage strategies. Upon completion, students will be able to analyze an organization’s data storage strategy and make recommendations for improvement in performance and robustness. Details of individual lessons in this module are provided below.", "video": ["Data Storage", "Resources: Data Storage", "Self-check", "Data Singularity", "Resources: Data Singularity", "Self-check", "Version Control", "Resources: Dealing with Constant Change", "Self-check", "Data Security and Disaster Recovery", "Resources: Data Security and Disaster Recovery", "Self-check", "Digital Thread: Components. Week 2 Quiz"]}, {"title": "Data Sharing and The Digital Thread", "description": "The purpose of this module is to explain factors impacting the ability of organizations to share data (internally and externally).  Upon completion of the module, learners will be able to evaluate data sharing strategies and point out potential strengths and weaknesses of different approaches. Details of individual lessons in this module are provided below", "video": ["Data Sharing", "Resources: Data Sharing Strategies, Benefits, and Consequences", "Self-check", "Interoperability", "Resources: Interoperability and Data Formats", "Self-check", "Semantic Data", "Resources: Semantic Data", "Self-check", "Technical Data Packages", "Resources: Technical Data Packages", "Self-check", "Your 4.0 Roadmap to Success", "Your 4.0 Roadmap to Success-- Resources", "Your Roadmap Project: Step 2", "Your 4.0 Roadmap to Success in Digital Manufacturing and Design Technology ", "Digital Thread: Components -- Key Takeaways", "Digital Thread: Components -- Course References", "Digital Thread: Components. Week 3 Quiz"]}]}, {"title": "Digital Thread: Implementation", "course_info": "About this course: There are opportunities throughout the design process of any product to make significant changes, and ultimately impact the future of manufacturing, by embracing the digital thread. In this course, you will dig into the transformation taking place in how products are designed and manufactured throughout the world. It is the second of two courses that focuses on the \"digital thread\" – the stream that starts at the creation of a product concept and continues to accumulate information and data throughout the product life cycle.  \n\nHear about the realities of implementing the digital thread, directly from someone responsible for making it happen at a company. Learn how the digital thread can fit into product development processes in an office, on a shop floor, and even across an enterprise. Be prepared to talk about the benefits, and limitations, of enacting it.\n\nMain concepts of this course will be delivered through lectures, readings, discussions and various videos. \n\nThis is the third course in the Digital Manufacturing & Design Technology specialization that explores the many facets of manufacturing’s “Fourth Revolution,” and features a culminating project involving creation of a roadmap to achieve a self-established DMD-related professional goal.\n\nTo learn more about the Digital Manufacturing and Design Technology specialization, please watch the overview video by copying and pasting the following link into your web browser: https://youtu.be/r-VHiwsg_t0", "target_audience": "Who is this class for: This course is for anyone interested in how digital advances are changing the landscape and capabilities of manufacturing, from high school graduates exploring careers to operations managers and business owners hungry for an understanding of the newest manufacturing technologies.", "created_by": "University at Buffalo, The State University of New York", "teach_by": [{"name": "Ken English", "department": "Sustainable Manufacturing and Advanced Robotic Technologies Community of Excellence"}], "package_num": "3", "package_name": "Digital Manufacturing & Design Technology  Specialization ", "level": "Beginner", "rating": "4.6", "week_data": [{"title": "Strategic issues in implementing the digital thread", "description": "The purpose of this module is to outline the strategies, barriers, and business factors related to the implementation of a digital thread approach. Details of individual lessons in this module are provided below.", "video": ["Introduction to Digital Thread: Implementation", "Acknowledgements", "A Business Case for the Digital Thread", "Resources: A Business Case for the Digital Thread", "Self-check", "Transitioning to the Digital Thread", "Resources: Transitioning to the Digital Thread", "Self- check", "Challenges and Benefits of Implementing the Digital Thread", "Resources: Implementation of the Digital Thread", "Self-check", "Digital Thread: Implementation- Week 1 Quiz"]}, {"title": "Cyberinfrastructure Components of the Digital Thread", "description": "The purpose of this module is to introduce students to the Information Technology components supporting the digital thread. Details of individual lessons in this module are provided below.", "video": ["Information Technology Components", "Resources: Cyberinfrastructure", "Self-check", "Computing Resources", "Self-check", "Virtualization", "Self-check", "Resources for Cloud-based Computing", "Resources: Resources for Cloud Based Computing", "Self-Quiz", "Digital Thread: Implementation --Week 2 Reflection ", "Digital Thread: Implementation- Week 2 Quiz"]}, {"title": "Technologies used in the Design Process", "description": "The purpose of this module is to discuss individual digital analysis tools used in the design process. Details of individual lessons in this module are provided below.", "video": ["Design Process Technologies", "Resources: Computer Aided Drawing - CAD", "Self-check", "Finite Element Analysis", "Resources: Finite Element Analysis - FEA", "Self-check", "Computational Fluid Dynamics", "Self-check", "Mold Design", "Resources: Mold Design", "Self-check", "Verification and Validation", "Resources: Verification and Validation", "Self-check", "Digital Thread: Implementation- Week 3 Quiz"]}, {"title": "Digital Thread on the Shop Floor", "description": "The purpose of this module is to introduce the growing number of digital tools available to support manufacturing operations. Details of individual lessons in this module are provided below.", "video": ["The Production Process", "Self-check", "Additive Manufacturing", "Resources: 3D Printing/Additive Manufacturing", "Self-check", "Digital Work Instructions", "Resources: Digital Work Instructions", "Self-check", "Digital Documents and Records", "Resources: Digital Drawings and Revision Control", "Self-check", "Digital Metrology Approaches", "Resources: Digital Metrology Approaches", "Self-check", "Digital Thread: Implementation- Week 4 Quiz"]}, {"title": "Digital Thread and the Manufacturing Enterprise", "description": "The purpose of this module is to introduce how a digital thread implementation impacts the design and manufacturing enterprise. Details of individual lessons in this module are provided below.", "video": ["DMD Connections Throughout the Enterprise", "Resources: Introduction to the Digital Thread in the Manufacturing Enterprise", "Self-check", "The Industrial Internet of Things (IIOT)", "Resources: The Industrial Internet of Things", "Self-check", "Factory Simulation Tools", "Resources: Factory Simulation Tools", "Self-check", "MRP, ERP, MES", "Resources: MRP / ERP / MES", "Self-check", "Your 4.0 Roadmap to Success", "Your 4.0 Roadmap to Success-- Resources", "Your Roadmap Project: Step 3", "Your 4.0 Roadmap to Success in Digital Manufacturing and Design Technology", "Digital Thread: Implementation - Key Takeaways", "Digital Thread: Implementation - Course References", "Digital Thread: Implementation- Week 5 Quiz"]}]}, {"title": "Advanced Manufacturing Enterprise", "course_info": "About this course: Enterprises that seek to become proficient in advanced manufacturing must incorporate manufacturing management tools and integrate data throughout the supply chain to be successful. This course will make students aware of what a digitally connected enterprise is, as they learn about the operational complexity of enterprises, business process optimization and the concept of an integrated product-process-value chain. \n\nStudents will become acquainted with the available tools, technologies and techniques for aggregation and integration of data throughout the manufacturing supply chain and entire product life-cycle. They will receive foundational knowledge to assist in efforts to facilitate design, planning, and production scheduling of goods and services by applying product life cycle data.  \n\nMain concepts of this course will be delivered through lectures, readings, discussions and various videos. \n\nThis is the sixth course in the Digital Manufacturing & Design Technology specialization that explores the many facets of manufacturing’s “Fourth Revolution,” and features a culminating project involving creation of a roadmap to achieve a self-established DMD-related professional goal.\n\nTo learn more about the Digital Manufacturing and Design Technology specialization, please watch the overview video by copying and pasting the following link into your web browser: https://youtu.be/r-VHiwsg_t0", "target_audience": "Who is this class for: This course is for anyone interested in how digital advances are changing the landscape and capabilities of manufacturing, from high school graduates exploring careers to operations managers and business owners hungry for an understanding of the newest manufacturing technologies.", "created_by": "University at Buffalo, The State University of New York", "teach_by": [{"name": "Sara Behdad", "department": "Mechanical and Aerospace Engineering, Industrial and Systems Engineering"}], "package_num": "6", "package_name": "Digital Manufacturing & Design Technology  Specialization ", "level": "Beginner", "rating": "4.2", "week_data": [{"title": "The Concept of a Connected and Collaborative Enterprise ", "description": "The purpose of this module is to educate students on why a holistic approach is necessary for analyzing the impact of advanced manufacturing on the\nsuccess of an enterprise. ", "video": ["Introduction to Advanced Manufacturing Enterprise", "An Integrated Enterprise", "Resources: Definition of Resilient and Adaptable Enterprise", "Self-check", "Acknowledgements", "The Transparency of Product Life Cycle Data", "Resources: Understanding the Need for Change", "Self-check", "Advanced Manufacturing Defined", "Resources: Definition of Advanced Manufacturing", "Self-check", "Advanced Manufacturing: Levels of Approach", "Resources: Four Levels of Approach", "Self-check", "The Concept of a Connected and Collaborative Enterprise"]}, {"title": "How to Build a Digitally Connected Enterprise", "description": "The purpose of this module is to provide an overview of product lifecycle and describe the challenges and opportunities that organizations face in adoption of advanced manufacturing technologies. We will discuss the desire for collection of product lifecycle data as well as outline the required features for a highly connected enterprise. In addition, we will provide several examples of information-sharing infrastructures and will elaborate the concept of Product Lifecycle Management (PLM) system. Finally, we will discuss several examples of effective data collection technologies.", "video": ["Product Life Cycle", "Resources- Product Life Cycle", "Self-check", "Advanced Manufacturing Adoption", "Resources: Challenges and Opportunities In Advanced Manufacturing Adoption", "Self-check", "Information Sharing Infrastructures", "Resources: Examples of Information-Sharing Infrastructures", "Self-check", "Product Life Cycle Management (PLM)", "Resources: Product Lifecycle Management (PLM) System", "Self-check", "The Industrial Internet of Things (IIOT)", "Resources: Examples of Emerging Data Collection Technologies", "Self-check", "Adoption of advanced manufacturing technologies", "How to Build a Digitally Connected Enterprise"]}, {"title": "Introduction to a Set of Supply Chain Management Tools & Integrated Capabilities", "description": "In this module, we will introduce the current enterprise management tools (such as ERP, MRP, and MES) that are often employed to integrate capabilities of various entities through the supply chain. We will provide a broad overview of these tools, and will review the capabilities of each of them.", "video": ["Material Requirements Planning (MRP)", "Resources: Material Requirement Planning", "Self-check", "Manufacturing Process Management", "Resources: Manufacturing Process Management", "Self-check", "Manufacturing Execution Systems", "Resources: Manufacturing Execution Systems", "Self-check", "Enterprise Resource Planning (ERP)", "Resources: Enterprise Resource Planning (ERP)", "Self-check", "Introduction to a Set of Supply Chain Management Tools & Integrated Capabilities"]}, {"title": "Ensure a Robust Infrastructure ", "description": "In this module, we discuss the importance of measuring the performance of supply chains. We will also discuss decision analysis methods and techniques that facilitate decision making through the entire product lifecycle. ", "video": ["Infrastructure Performance", "Resources: Performance of Value Chains", "Self-check", "New Manufacturing Paradigms", "Resources: New Business Models Originated From Advanced Manufacturing", "Self-check", "Data Security: Concerns and Solutions", "Resources: Overview of Data Security Concerns", "Self-check", "Your 4.0 Roadmap to Success", "Your 4.0 Roadmap to Success -- Resources", "Your Roadmap Project: Step 6", "Your 4.0 Roadmap to Success in Digital Manufacturing and Design Technology", "Advanced Manufacturing Enterprise- Key Takeaways", "Ensure a Robust Infrastructure"]}]}, {"title": "Roadmap to Success in Digital Manufacturing & Design ", "course_info": "About this course: Learners will create a roadmap to achieve their own personal goals related to the digital manufacturing and design (DM&D) profession, which will help them leverage relevant opportunities. The culminating project provides a tangible element to include in their professional portfolios that showcases their knowledge of Industry 4.0.\n\nThis project is part of the Digital Manufacturing and Design Technology specialization. To learn more about the specialization and its courses, please watch the overview video by copying and pasting the following link into your web browser: https://youtu.be/r-VHiwsg_t0", "target_audience": "Who is this class for: This course is for anyone interested in how digital advances are changing the landscape and capabilities of manufacturing, from high school graduates exploring careers to operations managers and business owners hungry for an understanding of the newest manufacturing technologies.", "created_by": "University at Buffalo, The State University of New York", "teach_by": [{"name": "Amy Moore", "department": "University at Buffalo: The Center for Industrial Effectiveness (TCIE)"}], "package_num": "10", "package_name": "Digital Manufacturing & Design Technology  Specialization ", "level": "Beginner", "rating": null, "week_data": [{"title": "Project Definition", "description": "The purpose of this module is to introduce learners to the factors and trends motivating the transition from the current state of manufacturing to a Digital Manufacturing and Design (DMD) model. Learners will demonstrate critical thinking to define a personalized roadmap project relating to the transformation such that they can impact themselves and the future of DMD. Details of individual lessons in this module are provided below.", "video": ["Introduction: Roadmap to Success in Digital Manufacturing and Design", "Resources: Industry 4.0", "Grading Rubric", "Acknowledgements", "Project Definition", "Industry Opportunities", "Resources: Project Definition", "Roadmap to Success in DMD: Step 1", "Project Definition", "Traditional vs. Digital Manufacturing Roles", "Next Generation", "Resources: Traditional vs. Digital Manufacturing Roles", "Roadmap to Success in DMD: Step 2", "Project Charter", "Resources: Project Charter", "Roadmap to Success in DMD: Step 3", "Roadmap to Success in Digital Manufacturing & Design--Week 1"]}, {"title": "Self-Assessment", "description": "The purpose of this module is for learners to identify their current situation, perform a self-assessment, and create a personalized future goal within the Digital Manufacturing and Design paradigm. Details of individual lessons in this module are provided below.", "video": ["Self-Assessment: Strength, Weaknesses, Opportunities, and Threats (SWOT) Analysis", "Resources: Self-Assessment: Strength, Weaknesses, Opportunities, and Threats (SWOT) Analysis", "Roadmap to Success in DMD: Step 4", "Strength, Weaknesses, Opportunities, and Threats (SWOT) Analysis", "A Business Case for Digital Implementation", "Your Future in Digital Manufacturing and Design", "Resources: You and the Future of Digital Manufacturing and Design", "Roadmap to Success in DMD: Step 5", "You and the Future of Digital Manufacturing and Design", "Self-Marketing Tools", "Resources: Self-Marketing Tools", "Roadmap to Success in DMD: Step 6", "Roadmap to Success in Digital Manufacturing & Design--Week 2"]}, {"title": "Network Exploration", "description": "This module focuses on defining and acquiring resources to help learners grow their network to assist in attaining the future goal identified within the Digital Manufacturing and Design domain. Details of individual lessons in this module are provided below.", "video": ["Finding a Mentor", "Resources: Finding a Mentor", "Roadmap to Success in DMD: Step 7", "Network Expansion", "Resources: Expanding Your Network", "Roadmap to Success in DMD: Step 8", "Safeguard Your Online Image", "Resources: Safeguard Your Online Image", "Roadmap to Success in DMD: Step 9", "Creating an Elevator Pitch", "Resources: Create an Elevator Pitch", "Roadmap to Success in DMD: Step 10", "Roadmap to Success in Digital Manufacturing & Design--Week 3"]}, {"title": "Roadmap Execution", "description": "In this module, learners will created a realistic roadmap execution plan to transition from a current state to a future desired state in the Digital Manufacturing and Design paradigm, using concepts gleaned throughout the course and elsewhere. ", "video": ["Roadmap to Success in Digital Manufacturing and Design Execution Plan", "Resources: Portfolio: Artifacts and Attestations", "Grading Rubric", "Roadmap to Success in Digital Manufacturing & Design", "Roadmap to Success in Digital Manufacturing & Design--Week 4"]}, {"title": "Final Project Submission and Peer Review Evaluation", "description": "In this final module, learners will continue to complete final edits and submit personalized artifacts and attestations to support a transition from a current state to a future state in Digital Manufacturing and Design as a peer review. Learners will review and provide feedback of the work of classmates.", "video": ["Final Project Submission and Evaluation: Congratulations!", "Resources: Portfolio: Artifacts and Attestations", "Grading Rubric", "Roadmap to Success in Digital Manufacturing & Design"]}]}, {"title": "Cyber Security in Manufacturing  ", "course_info": "About this course: The nature of digital manufacturing and design (DM&D), and its heavy reliance on creating a digital thread of product and process data and information, makes it a prime target for hackers and counterfeiters. This course will introduce students to why creating a strong and secure infrastructure should be of paramount concern for anyone operating in the DM&D domain, and measures that can be employed to protect operational technologies, systems and resources. \n\nAcquire knowledge about security needs and the application of information security systems. Build the foundational skills needed in performing a risk assessment of operational and information technology assets. Gain valuable insights of implementing controls to mitigate identified risks.\n\nMain concepts of this course will be delivered through lectures, readings, discussions and various videos. \n\nThis is the eighth course in the Digital Manufacturing & Design Technology specialization that explores the many facets of manufacturing’s “Fourth Revolution,” and features a culminating project involving creation of a roadmap to achieve a self-established DMD-related professional goal.\n\nTo learn more about the Digital Manufacturing and Design Technology specialization, please watch the overview video by copying and pasting the following link into your web browser: https://youtu.be/r-VHiwsg_t0", "target_audience": "Who is this class for: This course is for anyone interested in how digital advances are changing the landscape and capabilities of manufacturing, from high school graduates exploring careers to operations managers and business owners hungry for an understanding of the newest manufacturing technologies.", "created_by": "University at Buffalo, The State University of New York", "teach_by": [{"name": "Shambhu Upadhyaya", "department": "Computer Science and Engineering"}], "package_num": "8", "package_name": "Digital Manufacturing & Design Technology  Specialization ", "level": "Beginner", "rating": "4.6", "week_data": [{"title": "Introduction to Digital Manufacturing Security", "description": "The purpose of this module is to introduce you to the information security need, framework and processes, as it applies to creating a strong and secure Digital Manufacturing and Design infrastructure.", "video": ["Course Introduction", "Digital Manufacturing Security Part 1", "Additional (optional) Resources: Background and Description of the need for Digital Manufacturing Security, Part 1", "Digital Manufacturing Security - Part 2", "Additional (optional) Resources: Background and Description of the need for Digital Manufacturing Security, Part 2", "Self-check", "Acknowledgements", "Information Security Framework - Part 1", "Additional (optional) Resources: Information Security Framework, Part 1", "Information Security Framework - Part 2", "Additional (optional) Resources: Information Security Framework, Part 2", "Self-check", "Operational Technology and Informational Technology", "Risk Management", "Self-check", "Application of Information Security - Part 1", "Additional (optional) Resources: Application of Information Security in Digital Manufacturing Overview, Part 1", "Application of Information Security - Part 2", "Additional (optional) Resources: Application of Information Security in Digital Manufacturing Overview, Part 2", "Self-check", "Cyber Security in Manufacturing- Week 1 Quiz"]}, {"title": "Guidance on Securing Digital Manufacturing Operations", "description": "The purpose of this module is to introduced you to the various components of the digital manufacturing operation and the basic security concepts that can be used to protect these components.", "video": ["Securing all Aspects of a Digital Manufacturing Operation", "Additional (optional) Resources: Virtualization, Computing, Data, AI, Robotics", "Self-check", "Human-Machine and M2M Interactions", "Additional (optional) Resources: Human-Machine and Machine to Machine Interactions", "Self-check", "Securing End to End Process via Security Development Life Cycle", "Additional (optional) Resources: Securing End-to-End Process via Security Development Life Cycle", "Self-check", "Software Security Flaws and Threats", "Additional (optional) Resources: Software Security and Secure Programming Practices", "Self-check", "Network Security and Authentication - Part 1", "Additional (optional) Resources: Network Security and Authentication, Part 1", "Network Security and Authentication - Part 2", "Additional (optional) Resources: Network Security and Authentication, Part 2", "Self-Check", "Software Security", "Cyber Security in Manufacturing- Week 2 Quiz"]}, {"title": "Protecting Operational Technologies and Intellectual Property", "description": "The purpose of this module is to describe how the various operational steps of digital manufacturing – that includes - supply chain, shipping process, mobile device usage and the associated communication – can be protected, along with the Intellectual Property (IP) items that arise during digital manufacturing and design.\n", "video": ["Protecting Operational Technologies and Intellectual Property - Part 1", "Additional (optional) Resources: Cyber Physical Systems (SCADA), Physical Security vs Cyber Security, Part 1", "Protecting Operational Technologies and Intellectual Property - Part 2", "Additional (optional) Resources: Cyber Physical Systems (SCADA), Physical Security vs Cyber Security, Part 2", "Self-check", "Supply Chain Security", "Additional (optional) Resources: Supply Chain Security (Hardware Security)", "Self-check", "Shipping, RFID tags, Mobile Device Security and Wireless Communication - Part 1", "Additional (optional) Resources: Shipping, RFID Tags, Mobile Device Security, Wireless Communication, Part 1", "Shipping, RFID tags, Mobile Device Security and Wireless Communication - Part 2", "Additional (optional) Resources: Shipping, RFID Tags, Mobile Device Security, Wireless Communication, Part 2", "Self-check", "Data/Applications and Cloud Security", "Additional (optional) Resources: Data/Applications and Cloud Security", "Self-check", "Intellectual Property Protection from Threats", "Additional (optional) Resources: Intellectual Property Protection from Threats - External and Internal", "Self-check", "Cyber Security in Manufacturing- Week 3 Quiz"]}, {"title": "Breach Response", "description": "The purpose of this module is to teach you how to respond to security breaches when they happen. We will start with the threat landscape and system failures and investigate the interplay between security and reliability, which are essential for building dependable systems. The mechanism of continuous monitoring to detect security breaches, and strategies for forensics, breach response, and recovery will also be described.", "video": ["Breach Response", "Additional (optional) Resources: Breach Response", "Self-check", "Reliability versus Security", "Additional (optional) Resources: Reliability vs Security, Challenges, and Solutions", "Self-check", "Intrusion Prevention Techniques and Data Leak Prevention Tools - Part 1", "Additional (optional) Resources: Intrusion Prevention Techniques and Data Leak Prevention Tools, Part 1", "Intrusion Prevention Techniques and Data Leak Prevention Tools - Part 2", "Additional (optional) Resources: Intrusion Prevention Techniques and Data Leak Prevention Tools, Part 2", "Self-check", "Monitoring, Intrusion Detection, and Network Hardening", "Additional (optional) Resources: Monitoring, Intrusion Detection, and Network Hardening", "Self-check", "Intrusion Response, Recovery, and Forensics", "Additional (optional) Resources: Intrusion Response, Recovery, and Forensics", "Self-check", "Your 4.0 Roadmap to Success", "Your 4.0 Roadmap to Success-- Resources", "Your Roadmap Project: Step 8", "Your 4.0 Roadmap to Success in Digital Manufacturing and Design Technology", "Cyber Security in Manufacturing -- Key Takeways", "Cyber Security in Manufacturing- Week 4 Quiz"]}]}, {"title": "Digital Manufacturing Commons (opendmc.org)", "course_info": "About this course: The Digital Manufacturing Commons (DMC) is an open, online space for companies of all sizes to collaborate and transform how they design and manufacture their products. This course explores how the DMC platform will support an online community of users who can share data, analytical models, simulations, industry best practices and more. \n\nStudents will be encouraged to participate in the open source community by gaining a basic understanding of the DMC – including the motivations and creation behind it – as well as its mission, goals, and major features. They will acquire fundamental concepts and tools to interact with the DMC platform and perform digital collaboration.\n\nMain concepts of this course will be delivered through lectures, readings, discussions and various videos. \n\nThis is the seventh course in the Digital Manufacturing & Design Technology specialization that explores the many facets of manufacturing’s “Fourth Revolution,” and features a culminating project involving creation of a roadmap to achieve a self-established DMD-related professional goal.\n\nTo learn more about the Digital Manufacturing and Design Technology specialization, please watch the overview video by copying and pasting the following link into your web browser: https://youtu.be/r-VHiwsg_t0", "target_audience": "Who is this class for: This course is for anyone interested in how digital advances are changing the landscape and capabilities of manufacturing, from high school graduates exploring careers to operations managers and business owners hungry for an understanding of the newest manufacturing technologies.", "created_by": "University at Buffalo, The State University of New York", "teach_by": [{"name": "Chi Zhou", "department": "Industrial and Systems Engineering"}], "package_num": "7", "package_name": "Digital Manufacturing & Design Technology  Specialization ", "level": "Beginner", "rating": "3.9", "week_data": [{"title": "Introduction to Digital Manufacturing Commons", "description": "", "video": ["Introduction to Digital Manufacturing Commons (opendmc.org)", "Digital Manufacturing Commons (DMC)", "Conversation: What is the DMC?", "Resources: Digital Manufacturing Commons (DMC)", "Self-check", "Acknowledgements", "Getting to Know the DMC", "Resources: Getting to know the DMC", "Self-check", "Getting Started with The DMC", "Resources: Getting started with DMC", "Self-check", "The value of DMC", "Resources: The Value", "Self-check", "DMC Features", "Digital Manufacturing Commons--  Week 1 Quiz"]}, {"title": "Digital Services", "description": "", "video": ["DMC: Understanding Digital Services", "Resources: Digital Services Introduction", "Self-check", "Using DMC Services", "Resources: Using DMC Digital Services", "Self-check", "A Conversation about the DMC as a Service", "Resources: DMC- A Digital Service", "Self-check", "A Conversation about the DMC as a Manufacturing Resource", "Self-check", "DMC Marketplace", "Digital Manufacturing Commons--  Week 2 Quiz"]}, {"title": "DMC Security and IP Management", "description": "", "video": ["Security & Intellectual Property (IP) Management", "Resources: Managing Organizations on the DMC", "Self-check", "Managing Workspaces and Access Permissions", "Managing the Workspaces on the DMC", "Self-check", "The DMC Security Framework", "Resources: DMC Security Framework", "Self-check", "A Conversation About DMC Security Management", "Resources: DMC Security Management", "Self-check", "ITAR Framework", "Digital Manufacturing Commons--  Week 3 Quiz"]}, {"title": "Building a Digital Service: the Basics", "description": "", "video": ["Creating a DMC Service Introduction", "Creating a Model in DOME", "Resources: Creating a DMC Service", "Self-check", "Publishing a Service in Marketplace", "Resources: Publishing a DMC Service", "Self-check", "Run an Application on DMC", "Resources: Running a DMC Service", "Self-check", "A Conversation about Pricing a Service", "Resources: Pricing a DMC Service", "Self-check", "Marketplace Services", "Your 4.0 Roadmap to Success", "Your Roadmap Project: Step 7", "Digital Manufacturing Commons-- Key Takeaways", "Resource: NIST Cloud Computing Reference Architecture", "Digital Manufacturing Commons--  Week 4 Quiz"]}]}, {"title": "Big Data Services: Capstone Project", "course_info": "About this course: Are you ready to close the loop on your Big Data skills? Do you want to apply all your knowledge you got from the previous courses in practice? Finally, in the Capstone project, you will integrate all the knowledge acquired earlier to build a real application leveraging the power of Big Data.\n\nYou will be given a task to combine data from different sources of different types (static distributed dataset, streaming data, SQL or NoSQL storage). Combined, this data will be used to build a predictive model for a financial market (as an example). First, you design a system from scratch and share it with your peers to get valuable feedback. Second, you can make it public, so get ready to receive the feedback from your service users. Real-world experience without any 3G-glasses or mock interviews.", "target_audience": null, "created_by": "Yandex", "teach_by": [{"name": "Alexey A. Dral", "department": "Algorithms and Programming Technologies dept. MIPT"}, {"name": "Ivan Puzyrevskiy", "department": null}], "package_num": "5", "package_name": "Big Data for Data Engineers Specialization ", "level": "Advanced", "rating": null, "week_data": []}, {"title": "Recommender Systems Capstone", "course_info": "About this course: This capstone project course for the Recommender Systems Specialization brings together everything you've learned about recommender systems algorithms and evaluation into a comprehensive recommender analysis and design project.  You will be given a case study to complete where you have to select and justify the design of a recommender system through analysis of recommender goals and algorithm performance.  \n\nLearners in the honors track will focus on experimental evaluation of the algorithms against medium sized datasets.  The standard track will include a mix of provided results and spreadsheet exploration.\n\nBoth groups will produce a capstone report documenting the analysis, the selected solution, and the justification for that solution.", "target_audience": null, "created_by": "University of Minnesota", "teach_by": [{"name": "Michael D. Ekstrand", "department": "Dept. of Computer Science, Boise State University"}, {"name": "Joseph A Konstan", "department": "Computer Science and Engineering"}], "package_num": "5", "package_name": "Recommender Systems Specialization ", "level": null, "rating": null, "week_data": [{"title": "Capstone Project", "description": "", "video": ["Capstone Course: Introduction", "Capstone Assignment (all versions combined)", "Capstone Wrap-Up", "Thank you!", "Capstone Project Parts I and II:  Design, Measure", "Capstone Project Parts III and IV:  Mix, Propose and Justify", "Certification for honors track"]}]}]